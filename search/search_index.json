{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"DSG-JIT","text":"<p>A JIT-compiled, differentiable 3D Dynamic Scene Graph engine for SLAM, neural fields, and world-modeling.</p> <p></p>"},{"location":"#what-is-dsg-jit","title":"What is DSG-JIT?","text":"<p>Modern spatial intelligence systems are fractured:</p> <ul> <li>SLAM handles metric consistency  </li> <li>Neural fields / Gaussians handle appearance &amp; dense geometry  </li> <li>Scene graphs handle semantic structure &amp; relationships  </li> <li>Optimizers handle consistency, often as a separate non-differentiable backend  </li> </ul> <p>DSG-JIT unifies all of these into one system:</p> <p>A JIT-compiled, differentiable engine that builds, optimizes, and reasons over a 3D world model in real time.</p> <p>This repository provides:</p> <ul> <li>A differentiable factor-graph core (SE3 + Euclidean)</li> <li>A SceneGraphWorld layer for poses, places, rooms, voxels</li> <li>Voxel grid with smoothness + observation factors</li> <li>Learnable parameters (odom, voxel obs, factor weights)</li> <li>JIT-compiled solvers (JAX Gauss\u2013Newton on manifolds)</li> <li>A full suite of tests, experiments, and benchmarks</li> </ul> <p>This forms the foundation for a future differentiable Dynamic Scene Graph world model.</p>"},{"location":"#high-level-architecture","title":"High-Level Architecture","text":"<p>DSG-JIT is organized into five conceptual layers:</p>"},{"location":"#1-sensor-frontend","title":"1. Sensor Frontend","text":"<p>Processes raw sensor data (RGB-D, LiDAR, IMU) into: - Depth / point clouds - Frame-to-frame motion - Optional semantics</p>"},{"location":"#2-jit-compiled-slam-backend","title":"2. JIT-Compiled SLAM Backend","text":"<p>A differentiable factor graph performing:</p> <ul> <li>Pose optimization on SE3 manifolds  </li> <li>Loop closure / chain constraints  </li> <li>Learnable factor-type weights  </li> <li>Fully JIT-compiled Gauss\u2013Newton  </li> </ul>"},{"location":"#3-neural-field-module-future-integration","title":"3. Neural Field Module (future integration)","text":"<p>To support:</p> <ul> <li>NeRF / Gaussian splatting  </li> <li>Photometric residuals  </li> <li>Dense geometry for segmentation  </li> </ul>"},{"location":"#4-dynamic-3d-scene-graph-layer","title":"4. Dynamic 3D Scene Graph Layer","text":"<p>SceneGraphWorld tracking:</p> <ul> <li>Poses, places, rooms, agents  </li> <li>Attachments and voxel embeddings  </li> <li>Geometry + semantics as a single structure  </li> </ul>"},{"location":"#5-global-optimization-reasoning","title":"5. Global Optimization &amp; Reasoning","text":"<p>Unified optimization across:</p> <ul> <li>Trajectories  </li> <li>Voxels  </li> <li>Scene graph structure  </li> <li>Learnable factors  </li> </ul> <p>For more detail, see the full architecture page: \u27a1\ufe0f <code>architecture.md</code></p>"},{"location":"#quickstart","title":"Quickstart","text":""},{"location":"#clone-and-install","title":"Clone and install","text":"<pre><code>git clone https://github.com/TannerTorrey3/DSG-JIT.git\ncd DSG-JIT\n\npython3 -m venv venv\nsource venv/bin/activate  # Windows: venv\\Scripts\\activate\n\npip install -r requirements.txt\n\nexport PYTHONPATH=src\n</code></pre>"},{"location":"#run-tests","title":"Run Tests","text":"<p>To verify your installation, run:</p> <pre><code>pytest -q\n</code></pre> <p>You should see all tests passing.</p>"},{"location":"#first-example","title":"First Example","text":"<p>Run a simple dynamic trajectory experiment:</p> <pre><code>python experiments/exp06_dynamic_trajectory.py\n</code></pre> <p>Additional examples are available in:</p> <p>\u27a1\ufe0f <code>examples.md</code></p>"},{"location":"#current-capabilities","title":"Current Capabilities","text":""},{"location":"#differentiable-factor-graph-engine","title":"\u2714 Differentiable Factor Graph Engine","text":"<ul> <li>SE3 manifolds  </li> <li>Euclidean variables  </li> <li>Priors, odometry, attachments  </li> <li>Voxel smoothness &amp; observation residuals  </li> </ul>"},{"location":"#jit-compiled-solvers","title":"\u2714 JIT-Compiled Solvers","text":"<ul> <li>Gauss\u2013Newton  </li> <li>Manifold-aware retractors  </li> <li>Significant runtime speedups  </li> </ul>"},{"location":"#scenegraphworld","title":"\u2714 SceneGraphWorld","text":"<ul> <li>Poses, places, rooms  </li> <li>Agents &amp; trajectories  </li> <li>Attachments  </li> <li>Voxel embedding layer  </li> </ul>"},{"location":"#learnable-components","title":"\u2714 Learnable Components","text":"<ul> <li>Odom measurements  </li> <li>Voxel observation points  </li> <li>Factor-type weights  </li> <li>Hybrid SE3 + voxel joint learning  </li> </ul>"},{"location":"#benchmarks","title":"\u2714 Benchmarks","text":"<ul> <li>SE3 chain (200 poses): 51 ms (JIT) vs 376,098 ms (no JIT) </li> <li>Voxel chain (500 voxels): 96 ms (JIT) vs 3,044 ms (no JIT) </li> <li>Hybrid SE3 + voxel (50 poses, 500 voxels): 149 ms (JIT) vs 97,500 ms (no JIT) </li> </ul> <p>Benchmarks available at: \u27a1\ufe0f <code>benchmarks.md</code></p>"},{"location":"#roadmap-overview","title":"Roadmap Overview","text":""},{"location":"#phase-1-core-framework","title":"Phase 1 \u2014 Core Framework \u2714","text":"<p>Types, manifolds, solvers</p>"},{"location":"#phase-2-se3-scene-graph-prototype","title":"Phase 2 \u2014 SE3 + Scene Graph Prototype \u2714","text":"<p>Pose chains, dynamic graph, places/rooms</p>"},{"location":"#phase-3-voxel-integration","title":"Phase 3 \u2014 Voxel Integration \u2714","text":"<p>Voxel grids, smoothness, observation learning</p>"},{"location":"#phase-4-unified-learning-engine","title":"Phase 4 \u2014 Unified Learning Engine \u2714","text":"<p>Factor-type weights, odom learning, hybrid experiments</p>"},{"location":"#phase-5-scaling-real-world-validation","title":"Phase 5 \u2014 Scaling &amp; Real-World Validation \ud83d\udea7","text":"<p>Benchmarks, documentation, dataset connectors</p> <p>Details: \u27a1\ufe0f <code>roadmap.md</code></p>"},{"location":"#project-structure","title":"Project Structure","text":"<pre><code>dsg-jit/\n  src/\n    core/            # FactorGraph, math3d, types\n    optimization/    # Solvers + JIT wrappers\n    slam/            # Residuals, manifolds, SE3 ops\n    scene_graph/     # Relations, entities\n    world/           # SceneGraphWorld, training, voxel grid\n  tests/             # 26 test files\n  experiments/       # Exp01\u2013Exp16 (hero experiments)\n  benchmarks/        # Performance comparisons\n  docs/              # MkDocs documentation\n  README.md\n</code></pre>"},{"location":"#who-is-dsg-jit-for","title":"Who Is DSG-JIT For?","text":"<ul> <li>Robotics &amp; SLAM researchers  </li> <li>3D scene graph / geometric reasoning labs  </li> <li>NeRF / Gaussian splatting researchers  </li> <li>Embodied AI teams building world models  </li> <li>Anyone who needs a differentiable 3D optimizer  </li> </ul>"},{"location":"#get-involved","title":"Get Involved","text":"<p>Contributions welcome! Open a PR or file an issue on GitHub.</p>"},{"location":"architecture/","title":"DSG-JIT Architecture","text":"<p>A unified, differentiable 3D Dynamic Scene Graph and SLAM engine \u2014 built on JAX, manifolds, and factor graphs.</p>"},{"location":"architecture/#overview","title":"Overview","text":"<p>DSG-JIT is built around one central idea:</p> <p>A 3D world model should be fully differentiable, jointly optimized, and JIT-compiled for real-time performance.</p> <p>To achieve this, the system is organized into five coordinated layers, each built on top of a general-purpose factor graph and SE3 manifold engine.</p> <p></p> <p>Each layer is optional, modular, and composable \u2014 enabling applications in classical SLAM, neural fields, robotics, and world-modeling.</p>"},{"location":"architecture/#1-core-layer-differentiable-factor-graph-engine","title":"1. Core Layer \u2014 Differentiable Factor Graph Engine","text":"<p>The core provides the primitive mathematical and structural building blocks:</p>"},{"location":"architecture/#core-responsibilities","title":"Core Responsibilities","text":"<ul> <li>Variable management (poses, voxels, arbitrary vectors), via a backend\u2011agnostic data structure.</li> <li>Factor definitions (priors, odometry, smoothness, observations).</li> <li>Differentiable residual registry (now owned by the WorldModel).</li> <li>Backend\u2011agnostic factor graph interface (supports pluggable backends).</li> <li>JIT\u2011compiled residual builders (vmap\u2011optimized for performance).</li> <li>Unified flat\u2011state storage and index maps for optimization.</li> <li>Automatic Jacobian computation (via JAX autodiff).</li> </ul>"},{"location":"architecture/#key-modules","title":"Key Modules","text":"Module Purpose <code>world.model</code> Central owner of variables, factors, residuals, and state packing <code>core.factor_graph</code> Lightweight backend factor graph used by WorldModel (pluggable) <code>core.types</code> Data structures (Variable, Factor, NodeId, FactorId) <code>core.math3d</code> Vector/rotation utilities, SE3 helpers <p>This layer is geometry-agnostic \u2014 it does not know about voxels, rooms, or trajectories. Everything above is built on these abstractions.</p>"},{"location":"architecture/#2-optimization-layer-jit-gaussnewton-on-manifolds","title":"2. Optimization Layer \u2014 JIT Gauss\u2013Newton on Manifolds","text":"<p>The optimization layer transforms the factor graph into a high-performance nonlinear solver.</p>"},{"location":"architecture/#features","title":"Features","text":"<ul> <li>Gauss\u2013Newton with line-search, fully JIT\u2011compiled.</li> <li>Manifold retractors for SE3 and Euclidean variables.</li> <li>Pure JAX solver loop with vmap\u2011accelerated residual evaluation.</li> <li>JIT\u2011compiled objective + residuals with caching of compiled solvers in WorldModel.</li> <li>Ultra\u2011low Python overhead \u2014 solver runs nearly entirely in XLA.</li> </ul>"},{"location":"architecture/#modules","title":"Modules","text":"Module Purpose <code>optimization.solvers</code> Gauss\u2013Newton, manifold-aware logic <code>optimization.jit_wrappers</code> One\u2011line JIT interfaces using the new WorldModel residual API <p>This layer is responsible for the 50\u20131000x performance boost seen in benchmarks.</p>"},{"location":"architecture/#3-slam-layer-residual-functions-manifolds","title":"3. SLAM Layer \u2014 Residual Functions &amp; Manifolds","text":"<p>This layer provides the differentiable measurements registered inside the WorldModel. These residuals implement the geometric logic of SE3 constraints, landmarks, voxel consistency, and smoothness. The factor graph simply stores variable/factor connectivity; the WorldModel owns the residual functions and packing logic.</p>"},{"location":"architecture/#supported-manifolds","title":"Supported Manifolds","text":"<ul> <li>SE3 poses</li> <li>3D Euclidean points</li> <li>Voxel nodes (R\u00b3)</li> </ul>"},{"location":"architecture/#provided-residuals","title":"Provided Residuals","text":"Residual Type Description <code>se3_geodesic</code> Pose\u2011to\u2011pose geodesic constraint <code>odom_se3</code> Learnable or fixed SE3 odometry factor <code>pose_landmark_relative</code> Relative landmark measurement <code>pose_voxel_point</code> Voxel observation constraint <code>voxel_smoothness</code> Grid regularization term <code>prior</code> Generic variable prior <p>All residuals are now registered with <code>WorldModel.register_residual</code>. The FactorGraph stores only structure \u2014 not residual logic.</p>"},{"location":"architecture/#modules_1","title":"Modules","text":"Module Purpose <code>slam.measurements</code> All differentiable SLAM residuals <code>slam.manifold</code> Manifold utilities (exp/log maps, Jacobian-safe ops) <p>This layer enables standard SLAM, learnable SLAM, and hybrid SLAM + voxel systems.</p>"},{"location":"architecture/#4-scene-graph-layer-3d-dynamic-scene-graph","title":"4. Scene Graph Layer \u2014 3D Dynamic Scene Graph","text":"<p>This layer introduces the structural and semantic relationships that turn raw geometry into a world model.</p>"},{"location":"architecture/#entities","title":"Entities","text":"<ul> <li>Poses  </li> <li>Places  </li> <li>Rooms  </li> <li>Agents  </li> <li>Voxels  </li> <li>Attachments  </li> <li>Trajectories  </li> </ul>"},{"location":"architecture/#relations","title":"Relations","text":"<ul> <li>Pose \u2192 Place membership  </li> <li>Agent \u2192 Pose trajectory  </li> <li>Room \u2192 Place grouping  </li> <li>Voxel \u2192 Place attachment  </li> </ul>"},{"location":"architecture/#modules_2","title":"Modules","text":"Module Purpose <code>scene_graph.entities</code> Node classes (PoseNode, PlaceNode, RoomNode, VoxelNode, etc.) <code>scene_graph.relations</code> Relations &amp; constraints that form the DSG"},{"location":"architecture/#features_1","title":"Features","text":"<ul> <li>Geometry + semantics in one structure</li> <li>Differentiable constraints between DSG entities</li> <li>Realtime graph growth (future)</li> </ul> <p>Future extensions allow the Scene Graph to store multi\u2011resolution geometric layers (voxels, meshes, raw points, NeRF latent fields). DSG\u2011JIT is designed so that future NeRF modules can attach object\u2011specific neural fields directly to DSG nodes while still participating in global optimization.</p> <p>The DSG operates as a high-level structural layer over the SLAM + voxel system.</p>"},{"location":"architecture/#5-world-layer-unified-world-model","title":"5. World Layer \u2014 Unified World Model","text":"<p>The world layer combines SLAM, voxels, and the scene graph into one coherent system.</p>"},{"location":"architecture/#scenegraphworld","title":"<code>SceneGraphWorld</code>","text":"<p><code>SceneGraphWorld</code> is the highest\u2011level API and the primary entry point for users. It manages:</p> <ul> <li>Variables and factors (via the underlying factor graph backend)</li> <li>The residual registry</li> <li>JIT\u2011compiled residual and solver construction</li> <li>Optimization of full DSG + voxel + SLAM systems</li> <li>Integration with differentiable learning pipelines</li> <li>Multi\u2011resolution storage formats (planned)</li> <li>Planned NeRF attachments for objects and rooms</li> </ul>"},{"location":"architecture/#worldmodel-responsibilities","title":"WorldModel Responsibilities","text":"<ul> <li>Owns variables, factors, manifold types, and residual functions.</li> <li>Provides unified <code>pack_state</code> / <code>unpack_state</code> logic.</li> <li>Builds JIT\u2011optimized residuals via <code>build_residual</code> and specialized builders.</li> <li>Groups factors by type and applies <code>vmap</code> for high\u2011throughput evaluation.</li> <li>Caches compiled solvers for real\u2011time re\u2011optimization.</li> <li>Supports backend\u2011pluggable FactorGraph implementations.</li> </ul>"},{"location":"architecture/#training-learning","title":"Training &amp; Learning","text":"<p>The world layer exposes the learnable parameters used in the experiments:</p> <ul> <li>Odom SE3 measurements  </li> <li>Voxel observation points  </li> <li>Factor-type weights  </li> <li>Joint hybrid SE3 + voxel models  </li> </ul>"},{"location":"architecture/#modules_3","title":"Modules","text":"Module Purpose <code>world.model</code> SceneGraphWorld implementation <code>world.voxel_grid</code> Voxel layers + smoothness <code>world.training</code> Trainer-style learning loop"},{"location":"architecture/#information-flow-between-layers","title":"Information Flow Between Layers","text":"<pre><code>Sensors \u2192 SLAM Residuals \u2192 WorldModel (variables + residuals + factor graph)  \n\u2192 JIT Solver (vmap\u2011optimized) \u2192 SceneGraphWorld \u2192 Applications\n</code></pre> <ol> <li>Sensors provide point clouds, images, IMU.  </li> <li>SLAM residuals convert observations to geometric factors.  </li> <li>WorldModel manages variables, residuals, and factor graph structure.  </li> <li>JIT solver (vmap\u2011optimized) optimizes the entire state.  </li> <li>SceneGraphWorld structures it into a semantic world.  </li> <li>Applications consume the optimized graph (robotics, NeRFs, planning, etc.).</li> </ol>"},{"location":"architecture/#why-this-design","title":"Why This Design?","text":""},{"location":"architecture/#1-performance","title":"1. Performance","text":"<ul> <li>JIT residuals + JIT Gauss\u2013Newton  </li> <li>SE3 on manifolds  </li> <li>Minimal Python overhead  </li> <li>50\u20131000\u00d7 faster than na\u00efve Python solvers  </li> <li>vmap grouping of factor types for large batching speedups</li> </ul>"},{"location":"architecture/#2-differentiability","title":"2. Differentiability","text":"<ul> <li>JAX grad through:</li> <li>Odom parameters  </li> <li>Voxel obs  </li> <li>Factor weights  </li> <li>Entire scene graph  </li> </ul>"},{"location":"architecture/#3-modularity","title":"3. Modularity","text":"<ul> <li>SLAM or NeRF-only systems  </li> <li>DSG-only semantic reasoning  </li> <li>Hybrid world models  </li> <li>Incremental or batch optimization  </li> <li>Supports pluggable factor\u2011graph backends (Python, Rust, C++) as long as they implement the FactorGraph Standard.</li> </ul>"},{"location":"architecture/#4-extensibility","title":"4. Extensibility","text":"<p>This architecture supports future additions:</p> <ul> <li>Photometric residuals  </li> <li>Neural field appearance models  </li> <li>Real-world robotics datasets  </li> <li>Differentiable planning &amp; policies  </li> <li>Joint SLAM + segmentation  </li> <li>NeRF\u2011augmented objects and rooms (future)</li> <li>Multi\u2011resolution geometric storage (voxels, meshes, point clouds)</li> </ul>"},{"location":"architecture/#the-modern-dsgjit-architecture-2025","title":"The Modern DSG\u2011JIT Architecture (2025+)","text":"<p>DSG\u2011JIT has evolved into a WorldModel\u2011centric system:</p> <ul> <li>The FactorGraph is a backend implementation detail.</li> <li>All differentiability, residuals, and packing logic live in the WorldModel.</li> <li>Solvers operate on JIT\u2011compiled, vmap\u2011batched functions.</li> <li>SceneGraphWorld provides a rich, extensible API that will support NeRFs, hierarchical geometry, and large\u2011scale world\u2011modeling.</li> </ul> <p>This architecture enables DSG\u2011JIT to function as a real\u2011time differentiable world model suitable for robotics, simulation, mapping, and neural field research.</p>"},{"location":"benchmarks/","title":"Benchmarks","text":"<p>This page presents reproducible performance benchmarks for DSG\u2011JIT, demonstrating the efficiency and scalability of our differentiable Scene Graph optimizer across SE(3) pose chains, voxel grids, and hybrid problems. All benchmarks were run on macOS (Apple Silicon) using JAX CPU back\u2011ends.</p>"},{"location":"benchmarks/#overview","title":"\ud83d\ude80 Overview","text":"<p>DSG\u2011JIT achieves 31-1000\u00d7 speedups over pure Python Gauss\u2011Newton solvers thanks to JAX vectorization, JIT compilation, and careful manifold\u2011aware optimization.</p> <p>Benchmarks included:</p> <ol> <li>SE3 Gauss\u2011Newton Chain Benchmark </li> <li>Voxel Chain Gauss\u2011Newton Benchmark </li> <li>Hybrid SE3 + Voxel Gauss\u2011Newton Benchmark</li> </ol>"},{"location":"benchmarks/#1-se3-gaussnewton-benchmark","title":"1. SE3 Gauss\u2011Newton Benchmark","text":"<p>Solves a chain of <code>num_poses</code> SE(3) variables connected by odometry constraints.</p>"},{"location":"benchmarks/#200pose-chain-jit-enabled","title":"200\u2011Pose Chain (JIT Enabled)","text":"<pre><code>Elapsed time: 51.802 ms\npose0 (opt):   [7.94e-06 4.59e-06 0 ...]\nposeN-1 (opt): [1.990e+02 5.88e-04 0 ...]\n</code></pre>"},{"location":"benchmarks/#200pose-chain-no-jit","title":"200\u2011Pose Chain (No JIT)","text":"<pre><code>Elapsed time: 376,098 ms   (~6.27 minutes)\n</code></pre> <p>Result: JIT is ~ 7250\u00d7 faster.</p>"},{"location":"benchmarks/#2-voxel-chain-gaussnewton-benchmark","title":"2. Voxel Chain Gauss\u2011Newton Benchmark","text":"<p>Solves a smooth\u2011regularized chain of voxel centers.</p>"},{"location":"benchmarks/#500voxel-chain-jit-enabled","title":"500\u2011Voxel Chain (JIT Enabled)","text":"<pre><code>Elapsed time: 96.192 ms\nvoxel0 (opt):   [0.1457 0.0425 0]\nvoxelN-1 (opt): [494.0813 0.018 0]\n</code></pre>"},{"location":"benchmarks/#500voxel-chain-no-jit","title":"500\u2011Voxel Chain (No JIT)","text":"<pre><code>Elapsed time: 3,044.991 ms\n</code></pre> <p>Result: JIT is ~ 31\u00d7 faster.</p>"},{"location":"benchmarks/#3-hybrid-se3-voxel-benchmark","title":"3. Hybrid SE3 + Voxel Benchmark","text":"<p>Solves both a 50\u2011pose SE(3) chain and a 500\u2011voxel chain simultaneously.</p>"},{"location":"benchmarks/#jit-enabled","title":"JIT Enabled","text":"<pre><code>Elapsed time: 149.832 ms\npose0:     [-4.19e-19 4.00e-10 0 ...]\nposeN-1:   [4.90e+01 1.28e-08 0 ...]\nvoxelM-1:  [4.989959e+02 -1.199e-03 0]\n</code></pre>"},{"location":"benchmarks/#no-jit","title":"No JIT","text":"<pre><code>Elapsed time: 97,500 ms\n</code></pre> <p>Result: JIT is ~ 650\u00d7 faster.</p>"},{"location":"benchmarks/#summary-table","title":"\ud83d\udcca Summary Table","text":"Benchmark JIT Time Non\u2011JIT Time Speedup SE3 Chain (200) 51.8 ms 376,098 ms ~7250\u00d7 Voxel Chain (500) 96 ms 3,045 ms ~31\u00d7 Hybrid SE3+Voxel 150 ms 97,500 ms ~650\u00d7"},{"location":"benchmarks/#how-to-run-benchmarks","title":"\ud83d\udce6 How to Run Benchmarks","text":"<p>From the project root:</p> <pre><code>python3 benchmarks/bench_gauss_newton_se3.py\npython3 benchmarks/bench_voxel_chain.py\npython3 benchmarks/bench_hybrid_se3_voxel.py\n</code></pre>"},{"location":"benchmarks/#notes","title":"\ud83d\udcdd Notes","text":"<ul> <li>The first JIT call includes compilation time (can take minutes for large graphs).  </li> <li>Timings reported above exclude compilation and measure cached execution.  </li> <li>Performance scales linearly with problem size once compiled.</li> </ul>"},{"location":"benchmarks/#reproducibility","title":"\ud83d\udd2c Reproducibility","text":"<p>To ensure consistent benchmarking:</p> <pre><code>export JAX_PLATFORM_NAME=cpu\nexport XLA_FLAGS=--xla_cpu_enable_fast_math=true\n</code></pre>"},{"location":"benchmarks/#conclusion","title":"\u2705 Conclusion","text":"<p>DSG\u2011JIT dramatically accelerates differentiable scene\u2011graph optimization, delivering up to 7000\u00d7 speedups on real\u2011world sized problems.</p> <p>These benchmarks confirm:</p> <ul> <li>JIT + vectorized Gauss\u2011Newton is extremely efficient  </li> <li>Hybrid problems remain fast and stable  </li> <li>DSG\u2011JIT is ready for large\u2011scale SLAM and differentiable graphics tasks  </li> </ul>"},{"location":"examples/","title":"Examples","text":""},{"location":"examples/#examples","title":"Examples","text":"<p>This page provides practical, end-to-end usage examples for DSG-JIT \u2014 from constructing simple factor graphs to running differentiable optimizers, voxel pipelines, scene graphs, and hybrid SE3\u2013voxel learning.</p> <p>Each example is designed to run as-is inside your project using:</p> <pre><code>PYTHONPATH=dsg-jit/src python your_script.py\n</code></pre>"},{"location":"examples/#1-minimal-example-se3-odom-chain","title":"1. Minimal Example: SE(3) Odom Chain","text":"<pre><code>import jax.numpy as jnp\nfrom core.types import Variable, Factor\nfrom core.factor_graph import FactorGraph\nfrom slam.measurements import se3_additive_residual\nfrom optimization.solvers import gauss_newton\n\nfg = FactorGraph()\nfg.register_residual(\"odom_se3_add\", se3_additive_residual)\n\nfor i in range(3):\n    fg.add_variable(Variable(id=f\"pose{i}\", value=jnp.zeros((6,), dtype=jnp.float32)))\n\nfg.add_factor(Factor(\n    id=\"f0\", type=\"odom_se3_add\",\n    var_ids=[\"pose0\", \"pose1\"],\n    params={\"measurement\": jnp.array([1., 0, 0, 0, 0, 0])},\n))\nfg.add_factor(Factor(\n    id=\"f1\", type=\"odom_se3_add\",\n    var_ids=[\"pose1\", \"pose2\"],\n    params={\"measurement\": jnp.array([1., 0, 0, 0, 0, 0])},\n))\n\nx0, index = fg.pack_state()\nobjective = fg.build_objective()\n\nx_opt = gauss_newton(objective, x0, max_iters=20)\nposes = fg.unpack_state(x_opt, index)\n\nprint(\"Optimized poses:\", poses)\n</code></pre>"},{"location":"examples/#2-voxel-chain-optimization","title":"2. Voxel Chain Optimization","text":"<pre><code>import jax.numpy as jnp\nfrom core.types import Variable, Factor\nfrom core.factor_graph import FactorGraph\nfrom slam.measurements import voxel_smoothness_residual\nfrom optimization.solvers import gauss_newton\n\nfg = FactorGraph()\nfg.register_residual(\"voxel_smooth\", voxel_smoothness_residual)\n\nN = 10\nfor i in range(N):\n    fg.add_variable(Variable(id=f\"v{i}\", value=jnp.array([float(i), 0., 0.])))\n\nfor i in range(N - 1):\n    fg.add_factor(Factor(\n        id=f\"s{i}\",\n        type=\"voxel_smooth\",\n        var_ids=[f\"v{i}\", f\"v{i+1}\"],\n        params={\"offset\": jnp.array([1., 0., 0.]), \"weight\": 1.0},\n    ))\n\nx0, index = fg.pack_state()\nobjective = fg.build_objective()\nx_opt = gauss_newton(objective, x0)\n\nvoxels = fg.unpack_state(x_opt, index)\nprint(voxels)\n</code></pre>"},{"location":"examples/#3-learnable-type-weights-log-scale-training","title":"3. Learnable Type Weights (log-scale training)","text":"<pre><code>import jax\nimport jax.numpy as jnp\nfrom world.training import DSGTrainer\n\ntrainer = DSGTrainer(fg)\nlog_scales = jnp.zeros((1,))\n\nloss_fn = trainer.build_type_weight_loss([\"odom_se3_add\"])\ngrad_fn = jax.grad(loss_fn, argnums=1)\n\nfor step in range(50):\n    loss = loss_fn(x, log_scales)\n    g = grad_fn(x, log_scales)\n    log_scales -= 0.01 * g\n</code></pre>"},{"location":"examples/#4-voxel-point-observation","title":"4. Voxel Point Observation","text":"<pre><code>from slam.measurements import voxel_point_observation_residual\n\nfg = FactorGraph()\nfg.register_residual(\"voxel_point_obs\", voxel_point_observation_residual)\n\nfg.add_variable(Variable(id=\"pose\", value=jnp.zeros((6,))))\nfg.add_variable(Variable(id=\"voxel\", value=jnp.array([0., 0., 0.])))\n\nfg.add_factor(Factor(\n    id=\"obs0\",\n    type=\"voxel_point_obs\",\n    var_ids=[\"pose\", \"voxel\"],\n    params={\"point_world\": jnp.array([0.9, 0., 0.]), \"weight\": 1.0},\n))\n</code></pre>"},{"location":"examples/#5-scene-graph-example","title":"5. Scene Graph Example","text":"<pre><code>from world.scene_graph import SceneGraph\nfrom optimization.solvers import gauss_newton\n\nsg = SceneGraph()\np0 = sg.add_pose(\"p0\", jnp.zeros((6,)))\np1 = sg.add_pose(\"p1\", jnp.zeros((6,)))\n\nsg.add_odom_se3_additive(p0, p1, dx=1.0)\nfg = sg.to_factor_graph()\n\nobjective = fg.build_objective()\nx0, index = fg.pack_state()\nx_opt = gauss_newton(objective, x0)\n</code></pre>"},{"location":"examples/#6-hybrid-se3-voxel-learning-dsgtrainer","title":"6. Hybrid SE3 + Voxel Learning (DSGTrainer)","text":"<pre><code>import jax\nimport jax.numpy as jnp\nfrom world.training import DSGTrainer\nfrom optimization.solvers import gauss_newton\n\ntrainer = DSGTrainer(fg)\ntheta = trainer.init_theta(fg)\n\nx0, index = fg.pack_state()\nloss_fn = trainer.build_joint_hybrid_loss()\ngrad_fn = jax.grad(loss_fn)\n\nfor epoch in range(30):\n    x0 = trainer.solve_state(x0, theta)\n    g = grad_fn(x0, theta)\n    theta = trainer.update_theta(theta, g)\n</code></pre>"},{"location":"examples/#7-simple-visualization-example","title":"7. Simple Visualization Example","text":"<pre><code>import matplotlib.pyplot as plt\n\nposes = [fg.unpack_state(x_opt, index)[f\"pose{i}\"][0] for i in range(N)]\nplt.plot(poses, marker=\"o\")\nplt.title(\"Optimized Trajectory\")\nplt.show()\n</code></pre>"},{"location":"examples/#8-full-pipeline-example","title":"8. Full Pipeline Example","text":"<pre><code>from world.scene_graph import SceneGraph\nfrom world.training import DSGTrainer\n\nsg = SceneGraph()\nposes, voxels = sg.add_hybrid_chain(num_poses=50, num_voxels=500)\nfg = sg.to_factor_graph()\n\ntrainer = DSGTrainer(fg)\ntheta = trainer.init_theta(fg)\nx0, index = fg.pack_state()\n\nfor epoch in range(30):\n    x0 = trainer.solve_state(x0, theta)\n    theta = trainer.update_theta(theta, trainer.grad_theta(x0, theta))\n</code></pre>"},{"location":"glossary/","title":"\ud83d\udcda Glossary &amp; Key Concepts (Alphabetical)","text":"<p>This glossary lists every DSG\u2011JIT term in strict alphabetical order for instant lookup.</p>"},{"location":"glossary/#a","title":"A","text":""},{"location":"glossary/#agent","title":"Agent","text":"<p>A time\u2011varying entity (robot/person) with a pose trajectory over time.</p>"},{"location":"glossary/#agent-pose-node","title":"Agent Pose Node","text":"<p>A pose node associated with a specific agent + timestamp in the DynamicSceneGraph.</p>"},{"location":"glossary/#b","title":"B","text":""},{"location":"glossary/#bearing","title":"Bearing","text":"<p>A unit\u2011direction vector from a sensor to a target (camera or LiDAR).</p>"},{"location":"glossary/#c","title":"C","text":""},{"location":"glossary/#calibration-extrinsics","title":"Calibration (Extrinsics)","text":"<p>Rigid transform from a sensor frame to the robot/base frame.</p>"},{"location":"glossary/#camera-intrinsics","title":"Camera Intrinsics","text":"<p>3\u00d73 calibration matrix mapping pixels \u2192 normalized rays.</p>"},{"location":"glossary/#camerameasurement","title":"CameraMeasurement","text":"<p>Typed camera measurement containing rays, image, timestamps, etc.</p>"},{"location":"glossary/#chain-residual-se3-chain","title":"Chain Residual (SE3 Chain)","text":"<p>Residual enforcing that a sequence of SE(3) poses matches integrated motion.</p>"},{"location":"glossary/#conversion-layer-sensor-conversion-layer","title":"Conversion Layer (Sensor Conversion Layer)","text":"<p>Converts raw sensor samples into typed measurements and measurement factors.</p>"},{"location":"glossary/#d","title":"D","text":""},{"location":"glossary/#dsg-dynamic-scene-graph","title":"DSG \u2014 Dynamic Scene Graph","text":"<p>A time\u2011varying scene graph combining geometry + semantics + temporal structure.</p>"},{"location":"glossary/#dsg-layer","title":"DSG Layer","text":"<p>A semantic layer (rooms, places, objects, agents, voxels, etc).</p>"},{"location":"glossary/#dsgtrainer","title":"DSGTrainer","text":"<p>Bi\u2011level optimization utility (inner GN, outer hyperparameter learning).</p>"},{"location":"glossary/#dynamicscenegraph","title":"DynamicSceneGraph","text":"<p>Holds time\u2011indexed agent poses &amp; temporal edges.</p>"},{"location":"glossary/#dynamic-voxel-field","title":"Dynamic Voxel Field","text":"<p>A voxel grid that changes over time (dynamic/deformable environments).</p>"},{"location":"glossary/#dataset-stream","title":"Dataset Stream","text":"<p>Any sensor input driven by FunctionStream or FileRangeStream.</p>"},{"location":"glossary/#e","title":"E","text":""},{"location":"glossary/#edge-scene-graph-edge","title":"Edge (Scene Graph Edge)","text":"<p>Relationship between two scene\u2011graph nodes (room\u2013place, place\u2013object, etc).</p>"},{"location":"glossary/#euclidean-variable","title":"Euclidean Variable","text":"<p>A variable in \u211d\u207f (e.g., landmark, voxel, calibration scalar).</p>"},{"location":"glossary/#f","title":"F","text":""},{"location":"glossary/#factor","title":"Factor","text":"<p>A residual constraint relating one or more variables.</p>"},{"location":"glossary/#factor-graph","title":"Factor Graph","text":"<p>Bipartite graph of variables \u2194 factors.</p>"},{"location":"glossary/#filerangestream","title":"FileRangeStream","text":"<p>Sensor stream reading structured samples from a text/log file.</p>"},{"location":"glossary/#functionstream","title":"FunctionStream","text":"<p>Sensor stream driven by a Python generator function.</p>"},{"location":"glossary/#g","title":"G","text":""},{"location":"glossary/#gaussnewton-optimization","title":"Gauss\u2013Newton Optimization","text":"<p>Nonlinear least\u2011squares solver implemented on manifolds in DSG\u2011JIT.</p>"},{"location":"glossary/#graph-export-scenegraph-export","title":"Graph Export (SceneGraph Export)","text":"<p>Converts graph nodes into VisNode/VisEdge for visualization.</p>"},{"location":"glossary/#h","title":"H","text":""},{"location":"glossary/#hybrid-factor-graph","title":"Hybrid Factor Graph","text":"<p>A factor graph mixing SE(3), Euclidean, and voxel variables in one optimization.</p>"},{"location":"glossary/#i","title":"I","text":""},{"location":"glossary/#imu-delta-integration-integrate-imu-delta","title":"IMU Delta Integration (Integrate IMU Delta)","text":"<p>Creates a small SE(3) increment from raw IMU samples.</p>"},{"location":"glossary/#inner-optimization-inner-gn-inner-gradient-descent","title":"Inner Optimization (Inner GN / Inner Gradient Descent)","text":"<p>Solves the factor graph while outer parameters are fixed.</p>"},{"location":"glossary/#j","title":"J","text":""},{"location":"glossary/#jacobian","title":"Jacobian","text":"<p>Matrix of partial derivatives of residuals wrt variable components.</p>"},{"location":"glossary/#jit-compilation","title":"JIT Compilation","text":"<p>JAX compilation of residual functions for high\u2011performance SLAM.</p>"},{"location":"glossary/#l","title":"L","text":""},{"location":"glossary/#landmark","title":"Landmark","text":"<p>A 3D point in the world (usually Euclidean).</p>"},{"location":"glossary/#landmark-prior","title":"Landmark Prior","text":"<p>Unary factor constraining a landmark near a specific 3D location.</p>"},{"location":"glossary/#layered-visualization","title":"Layered Visualization","text":"<p>Rendering style placing node types on separate z\u2011planes.</p>"},{"location":"glossary/#lidar-scan","title":"LiDAR Scan","text":"<p>List of ranges/angles or rays converted to LidarMeasurement.</p>"},{"location":"glossary/#lie-group","title":"Lie Group","text":"<p>Differentiable group structure for SE(3), SO(3), etc.</p>"},{"location":"glossary/#m","title":"M","text":""},{"location":"glossary/#manifold","title":"Manifold","text":"<p>Non\u2011Euclidean space (like SE(3)) requiring special update rules.</p>"},{"location":"glossary/#manifold-gaussnewton","title":"Manifold Gauss\u2013Newton","text":"<p>Lie\u2011group\u2011aware Gauss\u2013Newton with retract/exp/log operations.</p>"},{"location":"glossary/#manifold-metadata","title":"Manifold Metadata","text":"<p>Describes each variable\u2019s manifold type + slice in packed state vector.</p>"},{"location":"glossary/#measurement","title":"Measurement","text":"<p>Raw or typed sensor output (camera, lidar, imu, odom).</p>"},{"location":"glossary/#measurementfactor","title":"MeasurementFactor","text":"<p>Factor generated from a typed measurement.</p>"},{"location":"glossary/#n","title":"N","text":""},{"location":"glossary/#named-object","title":"Named Object","text":"<p>Scene\u2011graph object with semantic identifier (e.g. \u201cchair_1\u201d).</p>"},{"location":"glossary/#o","title":"O","text":""},{"location":"glossary/#object-node","title":"Object Node","text":"<p>A semantic object (chair/table/etc) connected to a place.</p>"},{"location":"glossary/#observation-model","title":"Observation Model","text":"<p>Predicts expected sensor measurement given state x.</p>"},{"location":"glossary/#odometry","title":"Odometry","text":"<p>Relative motion factor between two poses.</p>"},{"location":"glossary/#odom_tx","title":"Odom_tx","text":"<p>1D translation\u2011only odom helper for quick SE(3) edges.</p>"},{"location":"glossary/#outer-optimization","title":"Outer Optimization","text":"<p>Top\u2011level hyperparameter update loop above the inner GN solver.</p>"},{"location":"glossary/#p","title":"P","text":""},{"location":"glossary/#place","title":"Place","text":"<p>A mid\u2011level scene\u2011graph node (semantic waypoint, corridor, anchor).</p>"},{"location":"glossary/#place3d","title":"Place3D","text":"<p>3D spatial place node used in realistic indoor environments.</p>"},{"location":"glossary/#place-attachment","title":"Place Attachment","text":"<p>Semantic constraint linking an agent pose \u2192 place.</p>"},{"location":"glossary/#plot-functions","title":"Plot Functions","text":"<p>Graph/scene\u2011graph visualization utilities in world.visualization.</p>"},{"location":"glossary/#pose","title":"Pose","text":"<p>An SE(3) rigid transform.</p>"},{"location":"glossary/#r","title":"R","text":""},{"location":"glossary/#range","title":"Range","text":"<p>Scalar distance reading (LiDAR, UWB, depth).</p>"},{"location":"glossary/#range-observation","title":"Range Observation","text":"<p>Factor derived from a distance measurement.</p>"},{"location":"glossary/#residual","title":"Residual","text":"<p>Prediction error: r(x) = f(x) \u2212 z.</p>"},{"location":"glossary/#s","title":"S","text":""},{"location":"glossary/#scene-graph","title":"Scene Graph","text":"<p>Hierarchical structure representing geometry + semantics.</p>"},{"location":"glossary/#scenegraphworld","title":"SceneGraphWorld","text":"<p>High\u2011level API wrapping factor graph, semantic nodes, and helpers.</p>"},{"location":"glossary/#se3-special-euclidean-group","title":"SE(3) \u2014 Special Euclidean Group","text":"<p>Rigid\u2011body transform group for robot poses.</p>"},{"location":"glossary/#so3","title":"SO(3)","text":"<p>Rotation\u2011only Lie group.</p>"},{"location":"glossary/#semantic-edge","title":"Semantic Edge","text":"<p>High\u2011level symbolic edge between semantic nodes.</p>"},{"location":"glossary/#sensorfusionmanager","title":"SensorFusionManager","text":"<p>Polls sensors and delivers typed measurements + callbacks.</p>"},{"location":"glossary/#sensor-streams-functionstream-filerangestream","title":"Sensor Streams (FunctionStream / FileRangeStream)","text":"<p>Abstract data sources for camera/lidar/imu streams.</p>"},{"location":"glossary/#t","title":"T","text":""},{"location":"glossary/#temporal-factor","title":"Temporal Factor","text":"<p>Factor connecting time\u2011indexed nodes.</p>"},{"location":"glossary/#temporal-layer","title":"Temporal Layer","text":"<p>Dynamic layer storing agent trajectories and time relations.</p>"},{"location":"glossary/#trajectory-agent-trajectory","title":"Trajectory (Agent Trajectory)","text":"<p>Ordered sequence of time\u2011indexed SE(3) poses.</p>"},{"location":"glossary/#type-weights-learnable-weights","title":"Type Weights (Learnable Weights)","text":"<p>Learned weights for residual types in bi\u2011level training.</p>"},{"location":"glossary/#v","title":"V","text":""},{"location":"glossary/#variable","title":"Variable","text":"<p>Optimizable unknown in the factor graph.</p>"},{"location":"glossary/#visnode-visedge","title":"VisNode / VisEdge","text":"<p>Lightweight structures for 2D/3D visualization.</p>"},{"location":"glossary/#voxel","title":"Voxel","text":"<p>Volumetric grid cell.</p>"},{"location":"glossary/#voxel-grid","title":"Voxel Grid","text":"<p>3D grid of voxels for dense mapping experiments.</p>"},{"location":"glossary/#voxel-observation-model","title":"Voxel Observation Model","text":"<p>Residual connecting voxel center to observed 3D point.</p>"},{"location":"glossary/#voxel-smoothness-residual","title":"Voxel Smoothness Residual","text":"<p>Factor connecting adjacent voxels enforcing smooth geometry.</p>"},{"location":"glossary/#w","title":"W","text":""},{"location":"glossary/#world-model","title":"World Model","text":"<p>Top\u2011level container for factor graph, variables, and optimization.</p>"},{"location":"glossary/#z","title":"Z","text":""},{"location":"glossary/#zeromean-gaussian-noise","title":"Zero\u2011Mean Gaussian Noise","text":"<p>Standard additive noise assumption for measurements.</p>"},{"location":"roadmap/","title":"Project Roadmap","text":"<p>This roadmap outlines the upcoming milestones for DSG\u2011JIT, spanning stability, features, optimization, and long\u2011term research directions. It is divided into phases with clear goals, deliverables, and stretch objectives.</p>"},{"location":"roadmap/#phase-1-core-stabilization-completed","title":"\ud83d\ude80 Phase 1 \u2014 Core Stabilization (Completed)","text":"<p>Status: \u2714\ufe0f Summary: Completed foundational work on optimizer, SE(3) manifold, voxel grid operators, scene graph, residuals, and testing suite.</p> <p>Deliverables: - JIT\u2011friendly factor graph engine - Full SE(3) geodesic math and differentiable odometry - Voxel smoothness, point observation, and multi\u2011parameter wrappers - Unified Gauss\u2011Newton solver - 26/26 passing tests  </p>"},{"location":"roadmap/#phase-2-differentiable-scene-graph-completed","title":"\ud83d\udd27 Phase 2 \u2014 Differentiable Scene Graph (Completed)","text":"<p>Status: \u2714\ufe0f Introduced the world model, scene graph relations, entity system, and DSG\u2011based optimization hooks.</p> <p>Deliverables: - Relational scene graph (parent/child, rigid attachments, etc.) - Voxel + SE(3) hybrid factors - Differentiable world model component - Param\u2011learnable factors for odom &amp; voxel observations  </p>"},{"location":"roadmap/#phase-3-experiments-validation-completed","title":"\ud83e\uddea Phase 3 \u2014 Experiments &amp; Validation (Completed)","text":"<p>Status: \u2714\ufe0f All algorithmic experiments defined, executed, and reproduced: - Learnable type weights - Learnable odom measurements - Multi\u2011voxel observation learning - Hybrid SE3 + voxel joint learning (hero experiment)</p>"},{"location":"roadmap/#phase-4-benchmarks-performance-completed","title":"\ud83d\udcc8 Phase 4 \u2014 Benchmarks &amp; Performance (Completed)","text":"<p>Status: \u2714\ufe0f Three official benchmarks implemented: - Pure SE3 factor graph - Voxel grid smoothness chain - Hybrid SE3 + voxel chain  </p> <p>JIT speedups: 31\u20137000\u00d7 depending on graph size.</p>"},{"location":"roadmap/#phase-5-realworld-sensors-slam-integration-completed","title":"\ud83e\udd16 Phase 5 \u2014 Real\u2011World Sensors &amp; SLAM Integration (Completed)","text":"<p>Integration of DSG\u2011JIT into full robotics pipelines.</p> <p>Planned: - Real LIDAR factor - RGB\u2011D depth factor - Visual landmarks - Camera intrinsics/extrinsics calibration via DSG - Data loaders for KITTI / TUM RGB\u2011D  </p> <p>Stretch: - IMU pre\u2011integration - Multi\u2011robot DSG fusion  </p>"},{"location":"roadmap/#phase-6-public-documentation-completed","title":"\ud83d\udcda Phase 6 \u2014 Public Documentation (Completed)","text":"<p>Status: \ud83d\udfe1 DSG-JIT current development stage.</p> <p>Remaining tasks: - Polish docs (architecture, API, examples, benchmarks) - Generate gallery diagrams - Ensure docs build cleanly under GitHub Pages - Add narrative tutorial series  </p> <p>Stretch: - Animated diagrams showing optimization steps - Interactive code sandboxes  </p>"},{"location":"roadmap/#phase-7-packaging-distribution-completed","title":"\ud83e\udde9 Phase 7 \u2014 Packaging &amp; Distribution (Completed)","text":"<p>Status: \u23f3</p> <p>Planned deliverables: - <code>pip install dsg-jit</code> - Versioned releases + changelog - Improved import layout - Automated lint + format + test pipeline - Pre\u2011commit hooks - GitHub Actions for:   - type-check   - tests   - benchmark snapshot   - docs deploy - ROS2 wrapper package  </p> <p>Stretch: - Optional CUDA/XLA GPU acceleration - Wheels for Mac, Linux, Windows  </p>"},{"location":"roadmap/#phase-8-research-extensions-longterm","title":"\ud83e\uddec Phase 8 \u2014 Research Extensions (Long\u2011Term)","text":"<ul> <li>DSG\u2011based reinforcement learning  </li> <li>Learned Jacobian priors  </li> <li>Generative world\u2011model layers  </li> </ul> <p>Potential publications: - Differentiable Scene Graph Optimization via JIT Factor Graphs - Hybrid SE3\u2013Voxel Graphs for Dense Reconstruction - End\u2011to\u2011End Learnable SLAM via Multi\u2011Residual Differentiation</p>"},{"location":"roadmap/#phase-9-10-stable-release-future","title":"\ud83c\udfc1 Phase 9 \u2014 1.0 Stable Release (Future)","text":"<p>The first fully stable release of DSG\u2011JIT.</p> <p>Requirements: - Complete documentation - Full packaging - All critical benchmarks validated - Public examples + tutorials - Long\u2011term support policy - Optimization safety &amp; performance guarantees - Extensive DSG API for \"plug-and-play\" Scene Graph Rendering</p>"},{"location":"roadmap/#phase-7-advanced-dsl-autogeneration-planned","title":"\ud83c\udfd7\ufe0f Phase 7 \u2014 Advanced DSL &amp; Autogeneration (Planned)","text":"<p>A domain\u2011specific \"DSG Modeling Language\" for declarative factor-graph design.</p> <p>Features: - YAML/JSON graph definitions - Auto\u2011generated optimization graphs - Auto\u2011differentiated residual templates - Scenegraph compiler \u2192 JIT graph  </p> <p>Stretch: - Visual graph editor - Drag\u2011and\u2011drop factor construction UI - \"Graph debugger\" visualization  </p>"},{"location":"roadmap/#contributing","title":"Contributing","text":"<p>Contributions are welcome! Upcoming needs: - More tests - More factor types - Benchmark expansions - Doc improvements - Tutorials + examples  </p>"},{"location":"api/core/","title":"Core Modules","text":"<p>This section documents the foundational data structures and factor-graph engine used throughout DSG-JIT.</p>"},{"location":"api/core/#coretypes","title":"<code>core.types</code>","text":"<p>Core typed data structures for DSG-JIT.</p> <p>This module defines the lightweight container classes used throughout the differentiable factor graph system. These types are intentionally minimal: they store only structural information and initial values, while all numerical operations are performed by JAX-compiled functions in the optimization layer.</p>"},{"location":"api/core/#core.types--classes","title":"Classes","text":"<p>Variable     Represents a node in the factor graph. A variable contains:     - id: Unique identifier (string or int)     - value: Initial numeric state, typically a 1-D JAX array     - metadata: Optional dictionary for semantic/scene-graph information</p> <p>Factor     Represents a constraint between one or more variables. A factor contains:     - id: Unique identifier     - type: String key selecting a residual function     - var_ids: Ordered list of variable ids used by the residual     - params: Dictionary of parameters passed into the residual function               (e.g., weights, measurements, priors)</p>"},{"location":"api/core/#core.types--notes","title":"Notes","text":"<p>These objects are deliberately simple and mutable; they are not meant to be used directly inside JAX-compiled functions. During optimization, the FactorGraph packs variable values into a flat JAX array <code>x</code>, ensuring that JIT-compiled solvers operate on purely functional data.</p> <p>This module forms the backbone of DSG-JIT's dynamic scene graph architecture, enabling hybrid SE3, voxel, and semantic structures to be represented in a unified factor graph.</p>"},{"location":"api/core/#core.types.Factor","title":"<code>Factor(id, type, var_ids, params)</code>  <code>dataclass</code>","text":"<p>Abstract factor connecting one or more variables.</p> <p>A factor encodes a residual term in the overall objective, defined over an ordered tuple of variable ids and parameterized by a small dictionary of measurements, noise models, or other hyperparameters.</p> <p>:param id: Unique identifier for the factor. :type id: FactorId :param type: String key indicating the factor/residual type     (e.g., \"odom\", \"loop_closure\", \"object_prior\"). :type type: str :param var_ids: Ordered tuple of NodeIds that this factor connects. :type var_ids: tuple[NodeId, ...] :param params: Dictionary of parameters passed into the residual function,     such as measurements, noise weights, or prior means. :type params: Dict[str, Any]</p>"},{"location":"api/core/#core.types.Pose3","title":"<code>Pose3(x, y, z, roll, pitch, yaw)</code>  <code>dataclass</code>","text":"<p>Minimal 3D pose holder.</p> <p>This is a lightweight container for a 3D pose parameterized as (x, y, z, roll, pitch, yaw).</p> <p>:param x: Position along the x-axis in meters. :type x: float :param y: Position along the y-axis in meters. :type y: float :param z: Position along the z-axis in meters. :type z: float :param roll: Rotation around the x-axis in radians. :type roll: float :param pitch: Rotation around the y-axis in radians. :type pitch: float :param yaw: Rotation around the z-axis in radians. :type yaw: float</p>"},{"location":"api/core/#core.types.Variable","title":"<code>Variable(id, type, value)</code>  <code>dataclass</code>","text":"<p>Generic optimization variable node in the factor graph.</p> <p>Each variable represents a node in the factor graph and stores its identifier, semantic type string, and current numeric value.</p> <p>:param id: Unique identifier for the variable node. :type id: NodeId :param type: Semantic type of the variable (e.g., \"pose3\", \"landmark3d\"). :type type: str :param value: Initial or current numeric value for this variable, typically     a 1-D JAX array or other array-like object. :type value: Any</p>"},{"location":"api/core/#coremath3d","title":"<code>core.math3d</code>","text":"<p>SE3 and SO3 manifold operations for DSG-JIT.</p> <p>This module implements the minimal 3D Lie-group mathematics required for differentiable SLAM and scene-graph optimization:</p> <pre><code>\u2022 SO(3) exponential &amp; logarithm maps\n\u2022 SE(3) exponential &amp; logarithm maps\n\u2022 Composition and inversion\n\u2022 Small-angle approximations for stable Jacobians\n\u2022 Helper utilities for constructing transforms\n</code></pre> All functions are written in JAX and support <ul> <li>JIT compilation</li> <li>Automatic differentiation</li> <li>Batched operation</li> <li>Numerically stable behavior near zero-rotation limits</li> </ul>"},{"location":"api/core/#core.math3d--key-functions","title":"Key Functions","text":"<p>so3_exp(w)     Maps a 3-vector (axis-angle) to a 3\u00d73 rotation matrix.</p> <p>so3_log(R)     Maps a rotation matrix back to its axis-angle representation.</p> <p>se3_exp(xi)     Maps a 6-vector twist \u03be = (\u03c9, v) to a 4\u00d74 SE(3) transform matrix.</p> <p>se3_log(T)     Inverse of se3_exp; extracts a twist from an SE3 matrix.</p> <p>se3_inverse(T)     Computes the inverse of an SE3 transform.</p> <p>se3_compose(A, B)     Composes two SE3 transforms: A \u2218 B.</p>"},{"location":"api/core/#core.math3d--utilities","title":"Utilities","text":"<p>hat(\u03c9)     Converts a 3-vector to its skew-symmetric matrix.</p> <p>vee(\u03a9)     Converts a 3\u00d73 skew matrix back into a 3-vector.</p>"},{"location":"api/core/#core.math3d--notes","title":"Notes","text":"<p>These functions are heavily used throughout DSG-JIT:     \u2022 Odometry factors     \u2022 Loop-closure factors     \u2022 Pose-voxel alignment     \u2022 Deformation-graph updates     \u2022 Hybrid SE3 + voxel joint solvers</p> <p>Correctness of the global optimization engine critically depends on these Lie-group operations being differentiable, stable, and JIT-friendly.</p>"},{"location":"api/core/#core.math3d.compose_pose_se3","title":"<code>compose_pose_se3(a, b)</code>","text":"<p>Compose two SE(3) poses in 6D vector representation.</p> <p>:param a: 6D pose vector. :type a: jnp.ndarray :param b: 6D pose vector. :type b: jnp.ndarray :return: Composed pose <code>a \u2218 b</code> in 6D vector form. :rtype: jnp.ndarray</p> Source code in <code>dsg-jit/dsg_jit/core/math3d.py</code> <pre><code>def compose_pose_se3(a: jnp.ndarray, b: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"\n    Compose two SE(3) poses in 6D vector representation.\n\n    :param a: 6D pose vector.\n    :type a: jnp.ndarray\n    :param b: 6D pose vector.\n    :type b: jnp.ndarray\n    :return: Composed pose ``a \u2218 b`` in 6D vector form.\n    :rtype: jnp.ndarray\n    \"\"\"\n    ta, wa = pose_vec_to_rt(a)\n    tb, wb = pose_vec_to_rt(b)\n\n    Ra = so3_exp(wa)\n    Rb = so3_exp(wb)\n\n    R = Ra @ Rb\n    t = Ra @ tb + ta\n\n    w = so3_log(R)\n    return jnp.concatenate([t, w])\n</code></pre>"},{"location":"api/core/#core.math3d.hat","title":"<code>hat(v)</code>","text":"<p>Compute the so(3) hat operator.</p> <p>:param v: 3\u2011vector. :type v: jnp.ndarray :return: 3\u00d73 skew\u2011symmetric matrix such that <code>hat(v) @ w = v \u00d7 w</code>. :rtype: jnp.ndarray</p> Source code in <code>dsg-jit/dsg_jit/core/math3d.py</code> <pre><code>def hat(v: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"\n    Compute the so(3) hat operator.\n\n    :param v: 3\u2011vector.\n    :type v: jnp.ndarray\n    :return: 3\u00d73 skew\u2011symmetric matrix such that ``hat(v) @ w = v \u00d7 w``.\n    :rtype: jnp.ndarray\n    \"\"\"\n    x, y, z = v[0], v[1], v[2]\n    return jnp.array(\n        [\n            [0.0, -z, y],\n            [z, 0.0, -x],\n            [-y, x, 0.0],\n        ]\n    )\n</code></pre>"},{"location":"api/core/#core.math3d.pose_vec_to_rt","title":"<code>pose_vec_to_rt(v)</code>","text":"<p>Split a 6D pose vector into translation and rotation components.</p> <p>:param v: 6D pose vector <code>[tx, ty, tz, wx, wy, wz]</code>. :type v: jnp.ndarray :return: Tuple <code>(t, w)</code> where <code>t</code> is translation <code>(3,)</code> and <code>w</code> is axis-angle rotation <code>(3,)</code>. :rtype: tuple[jnp.ndarray, jnp.ndarray]</p> Source code in <code>dsg-jit/dsg_jit/core/math3d.py</code> <pre><code>def pose_vec_to_rt(v: jnp.ndarray) -&gt; tuple[jnp.ndarray, jnp.ndarray]:\n    \"\"\"\n    Split a 6D pose vector into translation and rotation components.\n\n    :param v: 6D pose vector ``[tx, ty, tz, wx, wy, wz]``.\n    :type v: jnp.ndarray\n    :return: Tuple ``(t, w)`` where ``t`` is translation ``(3,)`` and ``w`` is axis-angle rotation ``(3,)``.\n    :rtype: tuple[jnp.ndarray, jnp.ndarray]\n    \"\"\"\n    v = jnp.asarray(v)\n    t = v[0:3]\n    w = v[3:6]\n    return t, w\n</code></pre>"},{"location":"api/core/#core.math3d.relative_pose_se3","title":"<code>relative_pose_se3(a, b)</code>","text":"<p>Compute relative pose from <code>a</code> to <code>b</code> in 6D coordinates.</p> <p>:param a: First pose <code>(6,)</code>. :type a: jnp.ndarray :param b: Second pose <code>(6,)</code>. :type b: jnp.ndarray :return: Relative twist such that <code>Exp(xi) \u2248 T_a^{-1} T_b</code>. :rtype: jnp.ndarray</p> Source code in <code>dsg-jit/dsg_jit/core/math3d.py</code> <pre><code>def relative_pose_se3(a: jnp.ndarray, b: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"\n    Compute relative pose from ``a`` to ``b`` in 6D coordinates.\n\n    :param a: First pose ``(6,)``.\n    :type a: jnp.ndarray\n    :param b: Second pose ``(6,)``.\n    :type b: jnp.ndarray\n    :return: Relative twist such that ``Exp(xi) \u2248 T_a^{-1} T_b``.\n    :rtype: jnp.ndarray\n    \"\"\"\n    ta, wa = pose_vec_to_rt(a)\n    tb, wb = pose_vec_to_rt(b)\n\n    Ra = so3_exp(wa)\n    Rb = so3_exp(wb)\n\n    R_rel = Ra.T @ Rb\n    w_rel = so3_log(R_rel)\n    t_rel = Ra.T @ (tb - ta)\n\n    return jnp.concatenate([t_rel, w_rel])\n</code></pre>"},{"location":"api/core/#core.math3d.se3_exp","title":"<code>se3_exp(xi)</code>","text":"<p>Exponential map from se(3) to SE(3).</p> <p>:param xi: 6\u2011vector twist <code>[v_x, v_y, v_z, w_x, w_y, w_z]</code>. :type xi: jnp.ndarray :return: 4\u00d74 homogeneous SE(3) transform matrix. :rtype: jnp.ndarray</p> Source code in <code>dsg-jit/dsg_jit/core/math3d.py</code> <pre><code>def se3_exp(xi: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"\n    Exponential map from se(3) to SE(3).\n\n    :param xi: 6\u2011vector twist ``[v_x, v_y, v_z, w_x, w_y, w_z]``.\n    :type xi: jnp.ndarray\n    :return: 4\u00d74 homogeneous SE(3) transform matrix.\n    :rtype: jnp.ndarray\n    \"\"\"\n    v = xi[:3]\n    w = xi[3:]\n\n    theta = jnp.linalg.norm(w)\n    I = jnp.eye(3)\n\n    # Rotation\n    R = so3_exp(w)\n\n    # Small-angle approximations for Jacobian\n    def small_angle():\n        # For tiny rotation, J \u2248 I + 0.5 * W\n        W = hat(w)\n        return I + 0.5 * W\n\n    def normal_angle():\n        W = hat(w)\n        W2 = W @ W\n        A = jnp.sin(theta) / theta\n        B = (1 - jnp.cos(theta)) / (theta * theta)\n        return I + A * W + B * W2\n\n    J = jax.lax.cond(theta &lt; 1e-5, small_angle, normal_angle)\n\n    t = J @ v\n\n    # Build full SE(3) matrix\n    T = jnp.eye(4)\n    T = T.at[:3, :3].set(R)\n    T = T.at[:3, 3].set(t)\n\n    return T\n</code></pre>"},{"location":"api/core/#core.math3d.se3_identity","title":"<code>se3_identity()</code>","text":"<p>Return the identity SE(3) pose.</p> <p>:return: Zero 6\u2011vector representing identity rotation and translation. :rtype: jnp.ndarray</p> Source code in <code>dsg-jit/dsg_jit/core/math3d.py</code> <pre><code>def se3_identity() -&gt; jnp.ndarray:\n    \"\"\"\n    Return the identity SE(3) pose.\n\n    :return: Zero 6\u2011vector representing identity rotation and translation.\n    :rtype: jnp.ndarray\n    \"\"\"\n    return jnp.zeros(6, dtype=jnp.float32)\n</code></pre>"},{"location":"api/core/#core.math3d.se3_retract_left","title":"<code>se3_retract_left(pose, delta)</code>","text":"<p>Left\u2011multiplicative SE(3) retraction.</p> <p>:param pose: Base pose in 6D coordinates. :type pose: jnp.ndarray :param delta: Incremental twist in 6D. :type delta: jnp.ndarray :return: Updated pose <code>Exp(delta) * pose</code> in 6D vector form. :rtype: jnp.ndarray</p> Source code in <code>dsg-jit/dsg_jit/core/math3d.py</code> <pre><code>def se3_retract_left(pose: jnp.ndarray, delta: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"\n    Left\u2011multiplicative SE(3) retraction.\n\n    :param pose: Base pose in 6D coordinates.\n    :type pose: jnp.ndarray\n    :param delta: Incremental twist in 6D.\n    :type delta: jnp.ndarray\n    :return: Updated pose ``Exp(delta) * pose`` in 6D vector form.\n    :rtype: jnp.ndarray\n    \"\"\"\n    pose = jnp.asarray(pose)\n    delta = jnp.asarray(delta)\n\n    # Split into translation + rotation-vector\n    t, w = pose_vec_to_rt(pose)\n    dt, dw = pose_vec_to_rt(delta)\n\n    R = so3_exp(w)\n    R_d = so3_exp(dw)\n\n    # Apply left-multiplicative update\n    R_new = R_d @ R\n    t_new = R_d @ t + dt\n\n    w_new = so3_log(R_new)\n    return jnp.concatenate([t_new, w_new])\n</code></pre>"},{"location":"api/core/#core.math3d.so3_exp","title":"<code>so3_exp(w)</code>","text":"<p>Exponential map from so(3) to SO(3).</p> <p>:param w: Rotation vector in axis\u2011angle form <code>(3,)</code>. :type w: jnp.ndarray :return: Rotation matrix in SO(3) with shape <code>(3, 3)</code>. :rtype: jnp.ndarray</p> Source code in <code>dsg-jit/dsg_jit/core/math3d.py</code> <pre><code>def so3_exp(w: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"\n    Exponential map from so(3) to SO(3).\n\n    :param w: Rotation vector in axis\u2011angle form ``(3,)``.\n    :type w: jnp.ndarray\n    :return: Rotation matrix in SO(3) with shape ``(3, 3)``.\n    :rtype: jnp.ndarray\n    \"\"\"\n    w = jnp.asarray(w)\n    theta = jnp.linalg.norm(w)\n    I = jnp.eye(3)\n\n    def small_angle() -&gt; jnp.ndarray:\n        # First-order approximation for small angles\n        return I + hat(w)\n\n    def normal_angle() -&gt; jnp.ndarray:\n        k = w / theta\n        K = hat(k)\n        return I + jnp.sin(theta) * K + (1.0 - jnp.cos(theta)) * (K @ K)\n\n    return jax.lax.cond(theta &lt; 1e-5, small_angle, normal_angle)\n</code></pre>"},{"location":"api/core/#core.math3d.so3_log","title":"<code>so3_log(R)</code>","text":"<p>Logarithm map from SO(3) to so(3).</p> <p>:param R: Rotation matrix in SO(3) with shape <code>(3, 3)</code>. :type R: jnp.ndarray :return: Rotation vector <code>(3,)</code> in axis\u2011angle form. :rtype: jnp.ndarray</p> Source code in <code>dsg-jit/dsg_jit/core/math3d.py</code> <pre><code>def so3_log(R: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"\n    Logarithm map from SO(3) to so(3).\n\n    :param R: Rotation matrix in SO(3) with shape ``(3, 3)``.\n    :type R: jnp.ndarray\n    :return: Rotation vector ``(3,)`` in axis\u2011angle form.\n    :rtype: jnp.ndarray\n    \"\"\"\n    R = jnp.asarray(R)\n    # Compute cos(theta) with clamping\n    trace = jnp.trace(R)\n    cos_theta = (trace - 1.0) / 2.0\n\n    # Clamp to valid domain for arccos\n    cos_theta = jnp.clip(cos_theta, -1.0, 1.0)\n    theta = jnp.arccos(cos_theta)\n\n    # Small-angle threshold\n    eps = 1e-5\n\n    def small_angle_case(_) -&gt; jnp.ndarray:\n        # For very small angles, R ~ I + hat(w), so:\n        # hat(w) ~ R - I  =&gt; w ~ vee(R - I)\n        w_skew = R - jnp.eye(3, dtype=R.dtype)\n        return vee(w_skew)\n\n    def general_case(_) -&gt; jnp.ndarray:\n        # Standard formula:\n        #   w^ = (theta / (2 sin(theta))) * (R - R^T)\n        #   w  = vee(w^)\n        w_skew = R - R.T\n        # Safe denominator\n        denom = 2.0 * jnp.sin(theta)\n        factor = theta / (denom + 1e-12)\n        w = factor * vee(w_skew)\n        return w\n\n    w = jax.lax.cond(\n        theta &lt; eps,\n        small_angle_case,\n        general_case,\n        operand=None,\n    )\n\n    return w\n</code></pre>"},{"location":"api/core/#core.math3d.vee","title":"<code>vee(R)</code>","text":"<p>Inverse of the hat operator.</p> <p>:param R: 3\u00d73 skew\u2011symmetric matrix. :type R: jnp.ndarray :return: Corresponding 3\u2011vector. :rtype: jnp.ndarray</p> Source code in <code>dsg-jit/dsg_jit/core/math3d.py</code> <pre><code>def vee(R: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"\n    Inverse of the hat operator.\n\n    :param R: 3\u00d73 skew\u2011symmetric matrix.\n    :type R: jnp.ndarray\n    :return: Corresponding 3\u2011vector.\n    :rtype: jnp.ndarray\n    \"\"\"\n    return jnp.array([\n        R[2, 1] - R[1, 2],\n        R[0, 2] - R[2, 0],\n        R[1, 0] - R[0, 1],\n    ]) / 2.0\n</code></pre>"},{"location":"api/core/#corefactor_graph","title":"<code>core.factor_graph</code>","text":"<p>Core factor graph data structure for DSG-JIT.</p> <p>This module implements a minimal, backend-agnostic factor graph. It stores variables and factors and provides basic helpers for managing the graph structure, but it does not contain any JAX, residual, or JIT-specific logic. All residual construction, vmap batching, and solver orchestration are handled by higher-level components such as :class:<code>dsg_jit.world.model.WorldModel</code>.</p> The FactorGraph stores <ul> <li>Variables (nodes in the optimization graph)</li> <li>Factors (constraints between variables)</li> </ul>"},{"location":"api/core/#core.factor_graph--design-philosophy","title":"Design Philosophy","text":"<ul> <li>Keep this layer small and generic so it can serve as a stable backend   for multiple front-ends (WorldModel, alternative world models, or   external bindings).</li> <li>Do not depend on JAX or expose residual-building APIs here; instead,   expose only structural information (variables, factors, IDs).</li> <li>Allow higher layers to interpret variables and factors however they   like (e.g., as poses, voxels, semantic objects) without baking that   interpretation into the core graph.</li> </ul>"},{"location":"api/core/#core.factor_graph--typical-usage","title":"Typical Usage","text":"<ul> <li><code>add_variable</code> / <code>add_factor</code>: Build up the factor graph structure.</li> <li>Higher-level code (e.g., :mod:<code>dsg_jit.world.model</code>) inspects   :attr:<code>variables</code> and :attr:<code>factors</code> to construct residual functions   and objectives suitable for Gauss\u2013Newton or gradient-based solvers.</li> </ul>"},{"location":"api/core/#core.factor_graph.FactorGraph","title":"<code>FactorGraph(variables=dict(), factors=dict())</code>  <code>dataclass</code>","text":"<p>Abstract factor graph for DSG-JIT.</p> <p>This class stores variables and factors and exposes simple helpers to register them. All residual-building and optimization logic is delegated to higher-level components such as :class:<code>WorldModel</code>.</p>"},{"location":"api/core/#core.factor_graph.FactorGraph.add_factor","title":"<code>add_factor(factor)</code>","text":"<p>Register a new factor in the factor graph.</p> <p>The factor must only reference variables that already exist in :attr:<code>variables</code>.</p> <p>:param factor: Factor to add to the graph. Its <code>id</code> must be unique. :type factor: Factor</p> Source code in <code>dsg-jit/dsg_jit/core/factor_graph.py</code> <pre><code>def add_factor(self, factor: Factor) -&gt; None:\n    \"\"\"Register a new factor in the factor graph.\n\n    The factor must only reference variables that already exist in\n    :attr:`variables`.\n\n    :param factor: Factor to add to the graph. Its ``id`` must be unique.\n    :type factor: Factor\n    \"\"\"\n    assert factor.id not in self.factors\n    self.factors[factor.id] = factor\n</code></pre>"},{"location":"api/core/#core.factor_graph.FactorGraph.add_variable","title":"<code>add_variable(var)</code>","text":"<p>Register a new variable in the factor graph.</p> <p>This does not modify any existing factors; it simply makes the variable available to be referenced by factors.</p> <p>:param var: Variable to add to the graph. Its <code>id</code> must be unique. :type var: Variable</p> Source code in <code>dsg-jit/dsg_jit/core/factor_graph.py</code> <pre><code>def add_variable(self, var: Variable) -&gt; None:\n    \"\"\"Register a new variable in the factor graph.\n\n    This does *not* modify any existing factors; it simply makes the\n    variable available to be referenced by factors.\n\n    :param var: Variable to add to the graph. Its ``id`` must be unique.\n    :type var: Variable\n    \"\"\"\n    assert var.id not in self.variables\n    self.variables[var.id] = var\n</code></pre>"},{"location":"api/datasets/","title":"Datasets","text":"<p>DSG-JIT includes light-weight loaders for common SLAM / VO datasets so you can quickly hook real sequences into the sensor stack, factor graph, and dynamic scene graph.</p> <p>The goal is:</p> <ul> <li>No heavy dependencies (no OpenCV required just to list frames).</li> <li>Simple dataclasses with timestamps + file paths.</li> <li>Easy integration with <code>sensors.*</code> streams and <code>world.*</code> components.</li> </ul> <p>Currently supported:</p> <ul> <li>TUM RGB-D</li> <li>KITTI Odometry</li> </ul>"},{"location":"api/datasets/#datasetstum_rgbd","title":"<code>datasets.tum_rgbd</code>","text":""},{"location":"api/datasets/#datasets.tum_rgbd.TumRgbdFrame","title":"<code>TumRgbdFrame(t, rgb_path, depth_path=None, pose_quat=None)</code>  <code>dataclass</code>","text":"<p>Single RGB-D frame from a TUM RGB-D sequence.</p> <p>This dataclass stores only light-weight metadata: timestamps and relative file paths. Consumers are responsible for actually loading images/depth (e.g., via OpenCV or Pillow) if desired.</p> <p>:param t:     Timestamp in seconds (as parsed from the TUM text files). :type t: float</p> <p>:param rgb_path:     Relative or absolute path to the RGB image file corresponding to this     frame. Typically something like <code>\"rgb/1341847980.722988.png\"</code>. :type rgb_path: str</p> <p>:param depth_path:     Optional path to the depth image associated with this frame. May be     <code>None</code> if depth is not available or <code>use_depth=False</code> was passed     to the loader. :type depth_path: Optional[str]</p> <p>:param pose_quat:     Optional ground-truth pose as a 7-tuple     <code>(tx, ty, tz, qx, qy, qz, qw)</code> in TUM convention. May be <code>None</code>     if ground truth is unavailable or alignment was disabled. :type pose_quat: Optional[Tuple[float, float, float, float, float, float, float]]</p>"},{"location":"api/datasets/#datasets.tum_rgbd.load_tum_rgbd_sequence","title":"<code>load_tum_rgbd_sequence(root, use_depth=True, use_groundtruth=False, max_frames=None, max_time_diff=0.02)</code>","text":"<p>Load a TUM RGB-D sequence directory into a list of frames.</p> <p>The directory is expected to contain standard TUM files such as <code>rgb.txt</code>, <code>depth.txt</code>, and optionally <code>groundtruth.txt</code>. This loader parses metadata and returns a list of :class:<code>TumRgbdFrame</code> instances, but does not actually load images or depth maps.</p> <p>:param root:     Path to the TUM sequence root directory. :type root: Union[str, os.PathLike]</p> <p>:param use_depth:     Whether to attempt to associate depth frames from <code>depth.txt</code> with     each RGB frame. :type use_depth: bool</p> <p>:param use_groundtruth:     Whether to attempt to associate ground-truth poses from     <code>groundtruth.txt</code> with each RGB frame. :type use_groundtruth: bool</p> <p>:param max_frames:     Optional maximum number of frames to return. If <code>None</code>, the full     sequence is loaded. :type max_frames: Optional[int]</p> <p>:param max_time_diff:     Maximum allowed absolute difference in timestamps (seconds) when     associating RGB with depth and ground truth. :type max_time_diff: float</p> <p>:return:     A list of TUM RGB-D frames with timestamps, file paths, and optionally     ground-truth poses. :rtype: List[TumRgbdFrame]</p> Source code in <code>dsg-jit/dsg_jit/datasets/tum_rgbd.py</code> <pre><code>def load_tum_rgbd_sequence(\n    root: str | os.PathLike,\n    use_depth: bool = True,\n    use_groundtruth: bool = False,\n    max_frames: Optional[int] = None,\n    max_time_diff: float = 0.02,\n) -&gt; List[TumRgbdFrame]:\n    \"\"\"\n    Load a TUM RGB-D sequence directory into a list of frames.\n\n    The directory is expected to contain standard TUM files such as\n    ``rgb.txt``, ``depth.txt``, and optionally ``groundtruth.txt``. This\n    loader parses metadata and returns a list of :class:`TumRgbdFrame`\n    instances, but does not actually load images or depth maps.\n\n    :param root:\n        Path to the TUM sequence root directory.\n    :type root: Union[str, os.PathLike]\n\n    :param use_depth:\n        Whether to attempt to associate depth frames from ``depth.txt`` with\n        each RGB frame.\n    :type use_depth: bool\n\n    :param use_groundtruth:\n        Whether to attempt to associate ground-truth poses from\n        ``groundtruth.txt`` with each RGB frame.\n    :type use_groundtruth: bool\n\n    :param max_frames:\n        Optional maximum number of frames to return. If ``None``, the full\n        sequence is loaded.\n    :type max_frames: Optional[int]\n\n    :param max_time_diff:\n        Maximum allowed absolute difference in timestamps (seconds) when\n        associating RGB with depth and ground truth.\n    :type max_time_diff: float\n\n    :return:\n        A list of TUM RGB-D frames with timestamps, file paths, and optionally\n        ground-truth poses.\n    :rtype: List[TumRgbdFrame]\n    \"\"\"\n    root_path = Path(root)\n\n    rgb_entries = _parse_tum_list_file(root_path / \"rgb.txt\")\n\n    depth_entries: List[Tuple[float, str]] = []\n    if use_depth and (root_path / \"depth.txt\").exists():\n        depth_entries = _parse_tum_list_file(root_path / \"depth.txt\")\n\n    gt_entries: List[Tuple[float, Tuple[float, float, float, float, float, float, float]]] = []\n    if use_groundtruth and (root_path / \"groundtruth.txt\").exists():\n        gt_entries = _parse_tum_groundtruth(root_path / \"groundtruth.txt\")\n\n    depth_assoc: Dict[int, Optional[int]] = {}\n    gt_assoc: Dict[int, Optional[int]] = {}\n\n    if depth_entries:\n        depth_assoc = _associate_by_timestamp(rgb_entries, depth_entries, max_diff=max_time_diff)\n\n    if gt_entries:\n        # Convert to (t, dummy_path) to reuse association logic\n        gt_ts_paths = [(t, \"\") for (t, _pose) in gt_entries]\n        gt_assoc = _associate_by_timestamp(rgb_entries, gt_ts_paths, max_diff=max_time_diff)\n\n    frames: List[TumRgbdFrame] = []\n\n    for i, (t_rgb, rgb_rel) in enumerate(rgb_entries):\n        depth_rel: Optional[str] = None\n        pose_quat: Optional[Tuple[float, float, float, float, float, float, float]] = None\n\n        if depth_entries and i in depth_assoc and depth_assoc[i] is not None:\n            depth_rel = depth_entries[depth_assoc[i]][1]\n\n        if gt_entries and i in gt_assoc and gt_assoc[i] is not None:\n            pose_quat = gt_entries[gt_assoc[i]][1]\n\n        frames.append(\n            TumRgbdFrame(\n                t=t_rgb,\n                rgb_path=str(root_path / rgb_rel),\n                depth_path=str(root_path / depth_rel) if depth_rel is not None else None,\n                pose_quat=pose_quat,\n            )\n        )\n\n        if max_frames is not None and len(frames) &gt;= max_frames:\n            break\n\n    return frames\n</code></pre>"},{"location":"api/datasets/#datasetskitti_odometry","title":"<code>datasets.kitti_odometry</code>","text":""},{"location":"api/datasets/#datasets.kitti_odometry.KittiOdomFrame","title":"<code>KittiOdomFrame(seq, idx, t, left_path, right_path=None, velo_path=None, T_w_cam0=None)</code>  <code>dataclass</code>","text":"<p>Single frame from the KITTI Odometry dataset.</p> <p>This dataclass provides file paths and optional ground-truth pose for a particular frame index in a given sequence.</p> <p>:param seq:     KITTI odometry sequence ID (e.g. <code>\"00\"</code>, <code>\"05\"</code>). :type seq: str</p> <p>:param idx:     Integer frame index within the sequence. :type idx: int</p> <p>:param t:     Approximate timestamp in seconds. Many downstream pipelines assume     KITTI odometry runs at 10 Hz, so a common convention is     <code>t = idx / 10.0</code>. :type t: float</p> <p>:param left_path:     Path to the left camera image (<code>image_0</code>) for this frame. :type left_path: str</p> <p>:param right_path:     Optional path to the right camera image (<code>image_1</code>). May be <code>None</code>     if not available or desired. :type right_path: Optional[str]</p> <p>:param velo_path:     Optional path to the LiDAR point cloud (<code>velodyne</code>). May be <code>None</code>     if not available or desired. :type velo_path: Optional[str]</p> <p>:param T_w_cam0:     Optional 4x4 homogeneous transform from camera-0 to world frame as a     flattened 16-element tuple in row-major order. This is derived from     the official <code>poses/&lt;seq&gt;.txt</code> file if available. :type T_w_cam0: Optional[Tuple[float, ...]]</p>"},{"location":"api/datasets/#datasets.kitti_odometry.load_kitti_odometry_sequence","title":"<code>load_kitti_odometry_sequence(root, seq, load_right=True, load_velodyne=False, with_poses=True, max_frames=None)</code>","text":"<p>Load a KITTI Odometry sequence into a list of frames.</p> <p>This helper assumes the standard KITTI directory structure:</p> <p>.. code-block::</p> <pre><code>root/\n  sequences/\n    00/\n      image_0/\n      image_1/\n      velodyne/\n      calib.txt\n  poses/\n    00.txt\n</code></pre> <p>Only metadata (paths and ground-truth transforms) is loaded; images and point clouds are not read into memory.</p> <p>:param root:     Path to the KITTI odometry dataset root directory. :type root: Union[str, os.PathLike]</p> <p>:param seq:     Sequence ID string (e.g. <code>\"00\"</code>, <code>\"01\"</code>). :type seq: str</p> <p>:param load_right:     Whether to populate <code>right_path</code> pointing to <code>image_1</code>. If <code>False</code>,     the field will always be <code>None</code>. :type load_right: bool</p> <p>:param load_velodyne:     Whether to populate <code>velo_path</code> pointing to <code>velodyne</code> scans. If     <code>False</code>, the field will always be <code>None</code>. :type load_velodyne: bool</p> <p>:param with_poses:     Whether to attempt to load ground-truth poses from <code>poses/&lt;seq&gt;.txt</code>. :type with_poses: bool</p> <p>:param max_frames:     Optional maximum number of frames to return. If <code>None</code>, all available     frames in the left camera directory are used. :type max_frames: Optional[int]</p> <p>:return:     List of :class:<code>KittiOdomFrame</code> entries with timestamps, paths, and     optionally ground-truth transforms. :rtype: List[KittiOdomFrame]</p> Source code in <code>dsg-jit/dsg_jit/datasets/kitti_odometry.py</code> <pre><code>def load_kitti_odometry_sequence(\n    root: str | os.PathLike,\n    seq: str,\n    load_right: bool = True,\n    load_velodyne: bool = False,\n    with_poses: bool = True,\n    max_frames: Optional[int] = None,\n) -&gt; List[KittiOdomFrame]:\n    \"\"\"\n    Load a KITTI Odometry sequence into a list of frames.\n\n    This helper assumes the standard KITTI directory structure:\n\n    .. code-block::\n\n        root/\n          sequences/\n            00/\n              image_0/\n              image_1/\n              velodyne/\n              calib.txt\n          poses/\n            00.txt\n\n    Only metadata (paths and ground-truth transforms) is loaded; images and\n    point clouds are not read into memory.\n\n    :param root:\n        Path to the KITTI odometry dataset root directory.\n    :type root: Union[str, os.PathLike]\n\n    :param seq:\n        Sequence ID string (e.g. ``\"00\"``, ``\"01\"``).\n    :type seq: str\n\n    :param load_right:\n        Whether to populate ``right_path`` pointing to ``image_1``. If ``False``,\n        the field will always be ``None``.\n    :type load_right: bool\n\n    :param load_velodyne:\n        Whether to populate ``velo_path`` pointing to ``velodyne`` scans. If\n        ``False``, the field will always be ``None``.\n    :type load_velodyne: bool\n\n    :param with_poses:\n        Whether to attempt to load ground-truth poses from ``poses/&lt;seq&gt;.txt``.\n    :type with_poses: bool\n\n    :param max_frames:\n        Optional maximum number of frames to return. If ``None``, all available\n        frames in the left camera directory are used.\n    :type max_frames: Optional[int]\n\n    :return:\n        List of :class:`KittiOdomFrame` entries with timestamps, paths, and\n        optionally ground-truth transforms.\n    :rtype: List[KittiOdomFrame]\n    \"\"\"\n    root_path = Path(root)\n    seq_str = f\"{int(seq):02d}\"  # normalize \"0\" -&gt; \"00\"\n\n    seq_dir = root_path / \"sequences\" / seq_str\n    left_dir = seq_dir / \"image_0\"\n    right_dir = seq_dir / \"image_1\"\n    velo_dir = seq_dir / \"velodyne\"\n\n    if not left_dir.exists():\n        raise FileNotFoundError(f\"Left image directory not found: {left_dir}\")\n\n    # Determine frame indices from left camera images\n    left_files = sorted(left_dir.glob(\"*.png\"))\n    if not left_files:\n        raise FileNotFoundError(f\"No left images found in {left_dir}\")\n\n    # Optional poses\n    poses: List[Tuple[float, ...]] = []\n    if with_poses:\n        poses_path = root_path / \"poses\" / f\"{seq_str}.txt\"\n        poses = _load_kitti_poses(poses_path)\n\n    frames: List[KittiOdomFrame] = []\n\n    for idx, left_path in enumerate(left_files):\n        t = idx / 10.0  # KITTI odometry is ~10 Hz; good enough for indexing.\n\n        right_path: Optional[str] = None\n        velo_path: Optional[str] = None\n        T_w_cam0: Optional[Tuple[float, ...]] = None\n\n        if load_right:\n            candidate = right_dir / left_path.name\n            if candidate.exists():\n                right_path = str(candidate)\n\n        if load_velodyne:\n            # KITTI velodyne uses \"*.bin\" with same numeric frame index\n            stem = left_path.stem  # e.g. \"000000\"\n            candidate = velo_dir / f\"{stem}.bin\"\n            if candidate.exists():\n                velo_path = str(candidate)\n\n        if with_poses and idx &lt; len(poses):\n            T_w_cam0 = poses[idx]\n\n        frames.append(\n            KittiOdomFrame(\n                seq=seq_str,\n                idx=idx,\n                t=t,\n                left_path=str(left_path),\n                right_path=right_path,\n                velo_path=velo_path,\n                T_w_cam0=T_w_cam0,\n            )\n        )\n\n        if max_frames is not None and len(frames) &gt;= max_frames:\n            break\n\n    return frames\n</code></pre>"},{"location":"api/optimization/","title":"Optimization Modules","text":"<p>This section documents the JIT-compiled Gauss\u2013Newton solvers and wrappers used inside DSG-JIT.</p>"},{"location":"api/optimization/#optimizationsolvers","title":"<code>optimization.solvers</code>","text":"<p>Nonlinear optimization solvers for DSG-JIT.</p> <p>This module implements the core iterative solvers used throughout the system, with a focus on JAX-friendly, JIT-compilable routines that operate on flat state vectors and manifold-aware blocks (e.g., SE(3) poses).</p> <p>The solvers are designed to work with residual functions produced by <code>core.factor_graph.FactorGraph</code>, and are used in:</p> <pre><code>\u2022 Pure SE3 SLAM chains\n\u2022 Voxel grid smoothness / observation problems\n\u2022 Hybrid SE3 + voxel joint optimization\n\u2022 Differentiable experiments where measurements or weights are learned\n</code></pre>"},{"location":"api/optimization/#optimization.solvers--key-concepts","title":"Key Concepts","text":"<p>GNConfig     Dataclass holding configuration for Gauss\u2013Newton:     - max_iters: maximum number of GN iterations     - damping: Levenberg\u2013Marquardt-style damping     - max_step_norm: optional clamp on update step size     - verbose / debug flags (if enabled)</p> <p>gauss_newton(residual_fn, x0, cfg)     Classic Gauss\u2013Newton on a flat Euclidean state:     - residual_fn: r(x) -&gt; (m,) JAX array     - x0: initial state     - cfg: GNConfig</p> <pre><code>Computes updates using normal equations:\n    J\u1d40 J \u0394x = -J\u1d40 r\nand returns the optimized state.\n</code></pre> <p>gauss_newton_manifold(residual_fn, x0, block_slices, manifold_types, cfg)     Manifold-aware Gauss\u2013Newton:     - residual_fn: r(x) -&gt; (m,)     - x0: initial flat state vector     - block_slices: NodeId -&gt; slice in x     - manifold_types: NodeId -&gt; {\"se3\", \"euclidean\", ...}     - cfg: GNConfig</p> <pre><code>For SE3 blocks:\n    \u2022 The update is computed in the tangent space (se(3))\n    \u2022 Applied via retract / exponential map\n    \u2022 Ensures updates stay on the manifold\n\nFor Euclidean blocks:\n    \u2022 Updates are applied additively.\n</code></pre>"},{"location":"api/optimization/#optimization.solvers--design-goals","title":"Design Goals","text":"<p>\u2022 Fully JAX-compatible:     All heavy operations are written in terms of JAX primitives so that     solvers can be JIT-compiled and differentiated through when needed.</p> <p>\u2022 Stable and controlled:     Optional damping and step-norm clamping help avoid NaNs and divergence     in difficult configurations (e.g., bad initialization or large residuals).</p> <p>\u2022 Reusable:     Experiments and higher-level training loops (e.g., in <code>experiments/</code>     and <code>optimization/jit_wrappers.py</code>) call into these solvers as the     core iterative engine for DSG-JIT.</p>"},{"location":"api/optimization/#optimization.solvers--notes","title":"Notes","text":"<p>These solvers are intentionally minimal and generic. They do not know anything about SE3 or voxels directly; instead, they rely on the factor graph and manifold metadata to interpret the state vector correctly.</p> <p>If you add new manifold types (e.g., quaternions or higher-dimensional poses), extend the manifold handling logic in the manifold-aware solver.</p>"},{"location":"api/optimization/#optimization.solvers.damped_newton","title":"<code>damped_newton(objective, x0, cfg)</code>","text":"<p>Damped Newton optimizer for small problems.</p> <p>Uses a Levenberg\u2013Marquardt-style update::</p> <pre><code>(H + \u03bb I) \\delta = abla f(x)\nx_{k+1} = x_k - \\delta\n</code></pre> <p>where <code>H</code> is the Hessian of the objective and <code>\u03bb</code> is a damping factor.</p> <p>:param objective: Objective function <code>f(x)</code> that maps a state vector to a scalar loss. :type objective: Callable[[jnp.ndarray], jnp.ndarray] :param x0: Initial state vector. :type x0: jnp.ndarray :param cfg: Newton solver configuration (number of iterations and damping). :type cfg: NewtonConfig :return: Optimized state vector after damped Newton iterations. :rtype: jnp.ndarray</p> Source code in <code>dsg-jit/dsg_jit/optimization/solvers.py</code> <pre><code>def damped_newton(objective: ObjectiveFn, x0: jnp.ndarray, cfg: NewtonConfig) -&gt; jnp.ndarray:\n    \"\"\"Damped Newton optimizer for small problems.\n\n    Uses a Levenberg\u2013Marquardt-style update::\n\n        (H + \u03bb I) \\\\delta = abla f(x)\n        x_{k+1} = x_k - \\\\delta\n\n    where ``H`` is the Hessian of the objective and ``\u03bb`` is a damping factor.\n\n    :param objective: Objective function ``f(x)`` that maps a state vector to a scalar loss.\n    :type objective: Callable[[jnp.ndarray], jnp.ndarray]\n    :param x0: Initial state vector.\n    :type x0: jnp.ndarray\n    :param cfg: Newton solver configuration (number of iterations and damping).\n    :type cfg: NewtonConfig\n    :return: Optimized state vector after damped Newton iterations.\n    :rtype: jnp.ndarray\n    \"\"\"\n    grad_fn = jax.grad(objective)\n    hess_fn = jax.hessian(objective)\n\n    x = x0\n    for _ in range(cfg.max_iters):\n        g = grad_fn(x)\n        H = hess_fn(x)\n\n        n = x.shape[0]\n        H_damped = H + cfg.damping * jnp.eye(n)\n\n        # Solve H_damped * delta = g\n        delta = jnp.linalg.solve(H_damped, g)\n\n        x = x - delta\n\n    return x\n</code></pre>"},{"location":"api/optimization/#optimization.solvers.gauss_newton","title":"<code>gauss_newton(residual_fn, x0, cfg)</code>","text":"<p>Gauss\u2013Newton on a residual function <code>r(x): R^n -&gt; R^m</code>.</p> <p>The algorithm forms the normal equations::</p> <pre><code>J^T J \\delta = J^T r\nx_{k+1} = x_k - \\delta\n</code></pre> <p>with optional diagonal damping and step-size clamping for stability.</p> <p>:param residual_fn: Residual function <code>r(x)</code> returning a 1D array of shape <code>(m,)</code>. :type residual_fn: Callable[[jnp.ndarray], jnp.ndarray] :param x0: Initial state vector of shape <code>(n,)</code>. :type x0: jnp.ndarray :param cfg: Gauss\u2013Newton configuration (iterations, damping, step-norm clamp). :type cfg: GNConfig :return: Optimized state vector after Gauss\u2013Newton iterations. :rtype: jnp.ndarray</p> Source code in <code>dsg-jit/dsg_jit/optimization/solvers.py</code> <pre><code>def gauss_newton(residual_fn: ObjectiveFn, x0: jnp.ndarray, cfg: GNConfig) -&gt; jnp.ndarray:\n    \"\"\"Gauss\u2013Newton on a residual function ``r(x): R^n -&gt; R^m``.\n\n    The algorithm forms the normal equations::\n\n        J^T J \\\\delta = J^T r\n        x_{k+1} = x_k - \\\\delta\n\n    with optional diagonal damping and step-size clamping for stability.\n\n    :param residual_fn: Residual function ``r(x)`` returning a 1D array of shape ``(m,)``.\n    :type residual_fn: Callable[[jnp.ndarray], jnp.ndarray]\n    :param x0: Initial state vector of shape ``(n,)``.\n    :type x0: jnp.ndarray\n    :param cfg: Gauss\u2013Newton configuration (iterations, damping, step-norm clamp).\n    :type cfg: GNConfig\n    :return: Optimized state vector after Gauss\u2013Newton iterations.\n    :rtype: jnp.ndarray\n    \"\"\"\n    J_fn = jax.jacobian(residual_fn)  # J: (m, n)\n\n    def step(x: jnp.ndarray) -&gt; jnp.ndarray:\n        r = residual_fn(x)    # (m,)\n        J = J_fn(x)           # (m, n)\n\n        H = J.T @ J           # (n, n)\n        g = J.T @ r           # (n,)\n\n        n = x.shape[0]\n        H_damped = H + cfg.damping * jnp.eye(n)\n\n        delta = jnp.linalg.solve(H_damped, g)  # (n,)\n\n        # Optional step-size clamp to avoid huge jumps\n        step_norm = jnp.linalg.norm(delta)\n        scale = jnp.minimum(1.0, cfg.max_step_norm / (step_norm + 1e-9))\n\n        return x - scale * delta\n\n    x = x0\n    for _ in range(cfg.max_iters):\n        x = step(x)\n    return x\n</code></pre>"},{"location":"api/optimization/#optimization.solvers.gauss_newton_manifold","title":"<code>gauss_newton_manifold(residual_fn, x0, block_slices, manifold_types, cfg)</code>","text":"<p>Manifold-aware Gauss\u2013Newton solver.</p> <p>This variant still solves in a flat parameter space, but applies updates block-wise using the appropriate manifold retraction. In particular:</p> <ul> <li>Blocks marked as <code>\"se3\"</code> are updated via <code>se3_retract_left</code> in the   Lie algebra <code>se(3)</code>.</li> <li>Blocks marked as <code>\"euclidean\"</code> are updated additively.</li> </ul> <p>:param residual_fn: Residual function <code>r(x)</code> returning a 1D array of shape <code>(m,)</code>. :type residual_fn: Callable[[jnp.ndarray], jnp.ndarray] :param x0: Initial flat state vector of shape <code>(n,)</code>. :type x0: jnp.ndarray :param block_slices: Mapping from node identifier to slice in <code>x</code> defining that variable's block.                      May be a dict or a sequence of (node_id, slice) pairs. :type block_slices: Union[Mapping[Any, slice], Sequence[Tuple[Any, slice]]] :param manifold_types: Mapping from node identifier to manifold label (e.g. <code>\"se3\"</code> or <code>\"euclidean\"</code>).                        May be a dict or a sequence of (node_id, manifold_type) pairs. :type manifold_types: Union[Mapping[Any, str], Sequence[Tuple[Any, str]]] :param cfg: Gauss\u2013Newton configuration (iterations, damping, step-norm clamp). :type cfg: GNConfig :return: Optimized state vector after manifold-aware Gauss\u2013Newton iterations. :rtype: jnp.ndarray</p> Source code in <code>dsg-jit/dsg_jit/optimization/solvers.py</code> <pre><code>def gauss_newton_manifold(\n    residual_fn: ObjectiveFn,\n    x0: jnp.ndarray,\n    block_slices: Union[Mapping[Any, slice], Sequence[Tuple[Any, slice]]],\n    manifold_types: Union[Mapping[Any, str], Sequence[Tuple[Any, str]]],\n    cfg: GNConfig,\n) -&gt; jnp.ndarray:\n    \"\"\"Manifold-aware Gauss\u2013Newton solver.\n\n    This variant still solves in a flat parameter space, but applies updates\n    block-wise using the appropriate manifold retraction. In particular:\n\n    * Blocks marked as ``\"se3\"`` are updated via ``se3_retract_left`` in the\n      Lie algebra ``se(3)``.\n    * Blocks marked as ``\"euclidean\"`` are updated additively.\n\n    :param residual_fn: Residual function ``r(x)`` returning a 1D array of shape ``(m,)``.\n    :type residual_fn: Callable[[jnp.ndarray], jnp.ndarray]\n    :param x0: Initial flat state vector of shape ``(n,)``.\n    :type x0: jnp.ndarray\n    :param block_slices: Mapping from node identifier to slice in ``x`` defining that variable's block.\n                         May be a dict or a sequence of (node_id, slice) pairs.\n    :type block_slices: Union[Mapping[Any, slice], Sequence[Tuple[Any, slice]]]\n    :param manifold_types: Mapping from node identifier to manifold label (e.g. ``\"se3\"`` or ``\"euclidean\"``).\n                           May be a dict or a sequence of (node_id, manifold_type) pairs.\n    :type manifold_types: Union[Mapping[Any, str], Sequence[Tuple[Any, str]]]\n    :param cfg: Gauss\u2013Newton configuration (iterations, damping, step-norm clamp).\n    :type cfg: GNConfig\n    :return: Optimized state vector after manifold-aware Gauss\u2013Newton iterations.\n    :rtype: jnp.ndarray\n    \"\"\"\n    # J: (m, n), r: (m,)\n    J_fn = jax.jacobian(residual_fn)\n\n    x = x0\n\n    for _ in range(cfg.max_iters):\n        r = residual_fn(x)       # (m,)\n        J = J_fn(x)              # (m, n)\n\n        H = J.T @ J              # (n, n)\n        g = J.T @ r              # (n,)\n\n        n = x.shape[0]\n        H_damped = H + cfg.damping * jnp.eye(n)\n\n        delta = jnp.linalg.solve(H_damped, g)  # (n,)\n\n        # Step size clamp\n        step_norm = jnp.linalg.norm(delta)\n        scale = jnp.minimum(1.0, cfg.max_step_norm / (step_norm + 1e-9))\n        delta_scaled = scale * delta\n\n        x_new = x\n\n        if isinstance(block_slices, Mapping) and isinstance(manifold_types, Mapping):\n            # Legacy path: dict lookups.\n            for nid, sl in block_slices.items():\n                d_i = delta_scaled[sl]\n                x_i = x[sl]\n                mtype = manifold_types.get(nid, \"euclidean\")\n\n                if mtype == \"se3\":\n                    # Interpret d_i as a twist in se(3) and apply left retraction\n                    x_i_new = se3_retract_left(x_i, -d_i)\n                else:\n                    # Euclidean update\n                    x_i_new = x_i - d_i\n\n                x_new = x_new.at[sl].set(x_i_new)\n        else:\n            # JAX-friendly path: iterate in lockstep over (nid, slice) and (nid, mtype)\n            # without dict indexing. `block_slices` and `manifold_types` are expected\n            # to be aligned and ordered consistently.\n            for (nid, sl), (_, mtype) in zip(block_slices, manifold_types):\n                d_i = delta_scaled[sl]\n                x_i = x[sl]\n\n                if mtype == \"se3\":\n                    x_i_new = se3_retract_left(x_i, -d_i)\n                else:\n                    x_i_new = x_i - d_i\n\n                x_new = x_new.at[sl].set(x_i_new)\n\n        x = x_new\n\n    return x\n</code></pre>"},{"location":"api/optimization/#optimization.solvers.gradient_descent","title":"<code>gradient_descent(objective, x0, cfg)</code>","text":"<p>Simple gradient descent optimizer.</p> <pre><code>Performs iterative updates of the form::\n\n    x_{k+1} = x_k - learning_rate *\n</code></pre> <p>abla f(x_k)</p> <pre><code>until ``max_iters`` is reached.\n\n:param objective: Objective function ``f(x)`` that maps a state vector to a scalar loss.\n:type objective: Callable[[jnp.ndarray], jnp.ndarray]\n:param x0: Initial state vector.\n:type x0: jnp.ndarray\n:param cfg: Gradient-descent configuration (learning rate and number of iterations).\n:type cfg: GDConfig\n:return: Optimized state vector after gradient descent.\n:rtype: jnp.ndarray\n</code></pre> Source code in <code>dsg-jit/dsg_jit/optimization/solvers.py</code> <pre><code>def gradient_descent(objective: ObjectiveFn, x0: jnp.ndarray, cfg: GDConfig) -&gt; jnp.ndarray:\n    \"\"\"Simple gradient descent optimizer.\n\n    Performs iterative updates of the form::\n\n        x_{k+1} = x_k - learning_rate * \nabla f(x_k)\n\n    until ``max_iters`` is reached.\n\n    :param objective: Objective function ``f(x)`` that maps a state vector to a scalar loss.\n    :type objective: Callable[[jnp.ndarray], jnp.ndarray]\n    :param x0: Initial state vector.\n    :type x0: jnp.ndarray\n    :param cfg: Gradient-descent configuration (learning rate and number of iterations).\n    :type cfg: GDConfig\n    :return: Optimized state vector after gradient descent.\n    :rtype: jnp.ndarray\n    \"\"\"\n    grad_fn = jax.grad(objective)\n\n    x = x0\n    for _ in range(cfg.max_iters):\n        g = grad_fn(x)\n        x = x - cfg.learning_rate * g\n    return x\n</code></pre>"},{"location":"api/optimization/#optimizationjit_wrappers","title":"<code>optimization.jit_wrappers</code>","text":"<p>JIT-friendly optimization wrappers and training utilities for DSG-JIT.</p> <p>This module provides higher-level utilities that sit on top of the core solvers in <code>optimization.solvers</code>. They are responsible for:</p> <pre><code>\u2022 Building JIT-compiled solve functions for a fixed world model-backed\n  factor graph\n\u2022 Wrapping Gauss\u2013Newton in a functional interface (solve(x0) -&gt; x_opt)\n\u2022 Supporting differentiable inner loops for meta-learning experiments\n\u2022 Implementing simple trainer-style loops used in Phase 4 experiments\n</code></pre>"},{"location":"api/optimization/#optimization.jit_wrappers--typical-usage","title":"Typical Usage","text":"<p>The experiments in <code>experiments/</code> use this module to:</p> <pre><code>\u2022 Construct a `WorldModel`-backed factor graph (SE3, voxels, hybrid)\n\u2022 Get a JIT-compiled residual or objective from the world model\n  (e.g., via :meth:`WorldModel.build_residual`, which internally groups\n  factors by type and shape and uses :func:`jax.vmap` for efficiency)\n\u2022 Build a `solve_once(x0)` function using Gauss\u2013Newton\n\u2022 Use `jax.grad` or `jax.value_and_grad` over an outer loss that depends\n  on the optimized state\n</code></pre> <p>Example patterns include:</p> <pre><code>\u2022 Learning SE3 odometry measurements by backpropagating through the\n  inner Gauss\u2013Newton solve\n\u2022 Learning voxel observation points that make a grid consistent with\n  known ground-truth centers\n\u2022 Learning factor-type weights (log-scales) for odometry vs. observations\n  via supervised losses on final poses/voxels\n</code></pre>"},{"location":"api/optimization/#optimization.jit_wrappers--key-utilities-typical-contents","title":"Key Utilities (typical contents)","text":"<p>build_jit_gauss_newton(...)     Given a WorldModel and a GNConfig, returns a JIT-compiled function:         solve_once(x0) -&gt; x_opt</p> <p>build_param_residual(...)     Wraps a residual function so that it depends both on the state <code>x</code> and     on learnable parameters <code>theta</code> (e.g., measurements, observation points).</p> <p>DSGTrainer (if present)     A lightweight helper class implementing:         - inner_solve(theta): run Gauss\u2013Newton or GD on the graph         - loss(theta): compute a supervised loss on the optimized state         - step(theta): one gradient step on theta</p>"},{"location":"api/optimization/#optimization.jit_wrappers--design-goals","title":"Design Goals","text":"<p>\u2022 Separate concerns:     The low-level solver logic lives in <code>solvers.py</code>, while experiment-     specific JIT wiring and training loops live here.</p> <p>\u2022 Encourage functional patterns:     All wrappers aim to expose pure functions that JAX can JIT and     differentiate, avoiding hidden state and side effects.</p> <p>\u2022 Make research experiments easy:     This is the layer where new meta-learning or differentiable-graph     experiments should be prototyped before they are promoted into a     more general API.</p>"},{"location":"api/optimization/#optimization.jit_wrappers--notes","title":"Notes","text":"<p>Because these wrappers are tailored to DSG-JIT\u2019s factor graph structure, they assume:</p> <pre><code>\u2022 Residual functions derived from :class:`WorldModel`, e.g.\n  :meth:`WorldModel.build_residual` and its hyper-parameterized\n  variants\n\u2022 State vectors packed/unpacked via the world model\u2019s core graph\n  machinery (``WorldModel.pack_state`` / ``WorldModel.unpack_state``)\n</code></pre> <p>When modifying or extending this module, take care to preserve JIT and grad-friendliness: avoid Python-side mutation inside jitted functions and keep logic purely functional wherever possible.</p>"},{"location":"api/optimization/#optimization.jit_wrappers.JittedGN","title":"<code>JittedGN(fn, cfg)</code>  <code>dataclass</code>","text":"<p>JIT-compiled Gauss\u2013Newton solver for a fixed world model-backed factor graph.</p>"},{"location":"api/optimization/#optimization.jit_wrappers.JittedGN--note","title":"Note","text":"<p>This wrapper targets the Euclidean solver :func:<code>gauss_newton</code>. For SE(3)/manifold problems use :class:<code>JittedGNManifold</code> instead.</p> <p>This lightweight wrapper stores a jitted solve function and the configuration used to build it. Typical usage:</p> <pre><code>residual_fn = wm.build_residual()  # vmap-optimized residual\ncfg = GNConfig(...)\njgn = JittedGN.from_residual(residual_fn, cfg)\nx_opt = jgn(x0)\n</code></pre> <p>:param fn: JIT-compiled function that maps an initial state            vector <code>x0</code> to an optimized state <code>x_opt</code>. :param cfg: Gauss\u2013Newton configuration used when building             the jitted solver.</p>"},{"location":"api/optimization/#optimization.jit_wrappers.JittedGN.__call__","title":"<code>__call__(x0)</code>","text":"<p>Run the jitted Gauss\u2013Newton solve on an initial state.</p> <p>:param x0: Initial flat state vector to optimize. :return: Optimized state vector after running Gauss\u2013Newton.</p> Source code in <code>dsg-jit/dsg_jit/optimization/jit_wrappers.py</code> <pre><code>def __call__(self, x0: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"Run the jitted Gauss\u2013Newton solve on an initial state.\n\n    :param x0: Initial flat state vector to optimize.\n    :return: Optimized state vector after running Gauss\u2013Newton.\n    \"\"\"\n    return self.fn(x0)\n</code></pre>"},{"location":"api/optimization/#optimization.jit_wrappers.JittedGN.from_residual","title":"<code>from_residual(residual_fn, cfg)</code>  <code>staticmethod</code>","text":"<p>Construct a :class:<code>JittedGN</code> from a residual function.</p> <p>This wraps :func:<code>gauss_newton</code> with the provided configuration and JIT-compiles the resulting <code>solve(x0)</code> function.</p> <p>:param residual_fn: Residual function <code>r(x)</code> returning the stacked                     residual vector for a fixed factor graph. :param cfg: Gauss\u2013Newton configuration (step limits, damping, etc.). :return: A :class:<code>JittedGN</code> instance whose <code>__call__</code> method          runs the jitted Gauss\u2013Newton solve.</p> Source code in <code>dsg-jit/dsg_jit/optimization/jit_wrappers.py</code> <pre><code>@staticmethod\ndef from_residual(\n    residual_fn: Callable[[jnp.ndarray], jnp.ndarray],\n    cfg: GNConfig,\n) -&gt; \"JittedGN\":\n    \"\"\"Construct a :class:`JittedGN` from a residual function.\n\n    This wraps :func:`gauss_newton` with the provided configuration\n    and JIT-compiles the resulting ``solve(x0)`` function.\n\n    :param residual_fn: Residual function ``r(x)`` returning the stacked\n                        residual vector for a fixed factor graph.\n    :param cfg: Gauss\u2013Newton configuration (step limits, damping, etc.).\n    :return: A :class:`JittedGN` instance whose ``__call__`` method\n             runs the jitted Gauss\u2013Newton solve.\n    \"\"\"\n    # Wrap existing gauss_newton. cfg is closed over and treated as static.\n    def solve(x0: jnp.ndarray) -&gt; jnp.ndarray:\n        return gauss_newton(residual_fn, x0, cfg)\n\n    # jit the whole solve for this graph\n    jitted = jax.jit(solve)\n    return JittedGN(fn=jitted, cfg=cfg)\n</code></pre>"},{"location":"api/optimization/#optimization.jit_wrappers.JittedGN.from_world_model","title":"<code>from_world_model(wm, cfg)</code>  <code>staticmethod</code>","text":"<p>Construct a :class:<code>JittedGN</code> directly from a :class:<code>WorldModel</code>.</p> <p>This helper calls :meth:<code>WorldModel.build_residual</code> to obtain the vmap-optimized residual function for the current world, and then wraps it in a jitted Gauss\u2013Newton solve.</p> <p>Typical usage::</p> <pre><code>wm = WorldModel()\n# ... add variables, factors, register residuals ...\njgn = JittedGN.from_world_model(wm, GNConfig(max_iters=20))\nx0, _ = wm.pack_state()\nx_opt = jgn(x0)\n</code></pre> <p>:param wm: World model whose factor graph defines the optimization            problem. Its :meth:<code>build_residual</code> method is used to            obtain the residual function. :param cfg: Gauss\u2013Newton configuration (step limits, damping, etc.). :return: A :class:<code>JittedGN</code> instance whose <code>__call__</code> method          runs the jitted Gauss\u2013Newton solve using the world model\u2019s          vmap-optimized residual.</p> Source code in <code>dsg-jit/dsg_jit/optimization/jit_wrappers.py</code> <pre><code>@staticmethod\ndef from_world_model(\n    wm: \"WorldModel\",\n    cfg: GNConfig,\n) -&gt; \"JittedGN\":\n    \"\"\"Construct a :class:`JittedGN` directly from a :class:`WorldModel`.\n\n    This helper calls :meth:`WorldModel.build_residual` to obtain the\n    vmap-optimized residual function for the current world, and then\n    wraps it in a jitted Gauss\u2013Newton solve.\n\n    Typical usage::\n\n        wm = WorldModel()\n        # ... add variables, factors, register residuals ...\n        jgn = JittedGN.from_world_model(wm, GNConfig(max_iters=20))\n        x0, _ = wm.pack_state()\n        x_opt = jgn(x0)\n\n    :param wm: World model whose factor graph defines the optimization\n               problem. Its :meth:`build_residual` method is used to\n               obtain the residual function.\n    :param cfg: Gauss\u2013Newton configuration (step limits, damping, etc.).\n    :return: A :class:`JittedGN` instance whose ``__call__`` method\n             runs the jitted Gauss\u2013Newton solve using the world model\u2019s\n             vmap-optimized residual.\n    \"\"\"\n    residual_fn = wm.build_residual()\n    return JittedGN.from_residual(residual_fn, cfg)\n</code></pre>"},{"location":"api/optimization/#optimization.jit_wrappers.JittedGNManifold","title":"<code>JittedGNManifold(fn, cfg)</code>  <code>dataclass</code>","text":"<p>JIT-compiled manifold Gauss\u2013Newton solver for a fixed graph.</p> <p>This wrapper is intended for SLAM-style problems where the packed state vector is a concatenation of manifold variables (e.g., SE(3) poses and R^3 landmarks). It closes over the residual function and manifold metadata and returns a single jitted solve function.</p> <p>Typical usage::</p> <pre><code>residual_fn = wm.build_residual()\nmanifold_types, block_slices = build_manifold_metadata(...)\ncfg = GNConfig(max_iters=1)\njgn = JittedGNManifold.from_residual(residual_fn, manifold_types, block_slices, cfg)\nx_opt = jgn(x0)\n</code></pre> IMPORTANT <p>To avoid repeated compilation, construct this once and reuse it for every incremental step. Ensure the shapes/dtypes of <code>x0</code> and the residual output remain constant across steps (template mode).</p> <p>:param fn: JIT-compiled function mapping <code>x0</code> -&gt; <code>x_opt</code>. :param cfg: Gauss\u2013Newton configuration.</p>"},{"location":"api/optimization/#optimization.jit_wrappers.JittedGNManifold.__call__","title":"<code>__call__(x0)</code>","text":"<p>Run the jitted manifold Gauss\u2013Newton solve.</p> Source code in <code>dsg-jit/dsg_jit/optimization/jit_wrappers.py</code> <pre><code>def __call__(self, x0: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"Run the jitted manifold Gauss\u2013Newton solve.\"\"\"\n    return self.fn(x0)\n</code></pre>"},{"location":"api/optimization/#optimization.jit_wrappers.JittedGNManifold.from_residual","title":"<code>from_residual(residual_fn, manifold_types, block_slices, cfg)</code>  <code>staticmethod</code>","text":"<p>Construct a :class:<code>JittedGNManifold</code> from residual + metadata.</p> <p>:param residual_fn: Residual function <code>r(x)</code>. :param manifold_types: Per-block manifold type strings. :param block_slices: Per-block slices into the packed vector. :param cfg: Solver configuration. :return: A reusable, jitted solver.</p> Source code in <code>dsg-jit/dsg_jit/optimization/jit_wrappers.py</code> <pre><code>@staticmethod\ndef from_residual(\n    residual_fn: Callable[[jnp.ndarray], jnp.ndarray],\n    manifold_types: Any,\n    block_slices: Any,\n    cfg: GNConfig,\n) -&gt; \"JittedGNManifold\":\n    \"\"\"Construct a :class:`JittedGNManifold` from residual + metadata.\n\n    :param residual_fn: Residual function ``r(x)``.\n    :param manifold_types: Per-block manifold type strings.\n    :param block_slices: Per-block slices into the packed vector.\n    :param cfg: Solver configuration.\n    :return: A reusable, jitted solver.\n    \"\"\"\n\n    def solve(x0: jnp.ndarray) -&gt; jnp.ndarray:\n        return gauss_newton_manifold(\n            residual_fn=residual_fn,\n            x0=x0,\n            manifold_types=manifold_types,\n            block_slices=block_slices,\n            cfg=cfg,\n        )\n\n    # JIT the whole solve; cfg/manifold metadata are closed over.\n    jitted = jax.jit(solve)\n    return JittedGNManifold(fn=jitted, cfg=cfg)\n</code></pre>"},{"location":"api/optimization/#optimization.jit_wrappers.JittedGNManifold.from_world_model","title":"<code>from_world_model(wm, manifold_types, block_slices, cfg)</code>  <code>staticmethod</code>","text":"<p>Construct a manifold GN solver directly from a :class:<code>WorldModel</code>.</p> <p>This helper obtains the residual via :meth:<code>WorldModel.build_residual</code>.</p> <p>:param wm: World model. :param manifold_types: Per-block manifold types. :param block_slices: Per-block slices. :param cfg: Solver configuration. :return: A reusable, jitted solver.</p> Source code in <code>dsg-jit/dsg_jit/optimization/jit_wrappers.py</code> <pre><code>@staticmethod\ndef from_world_model(\n    wm: \"WorldModel\",\n    manifold_types: list[str],\n    block_slices: list[slice],\n    cfg: GNConfig,\n) -&gt; \"JittedGNManifold\":\n    \"\"\"Construct a manifold GN solver directly from a :class:`WorldModel`.\n\n    This helper obtains the residual via :meth:`WorldModel.build_residual`.\n\n    :param wm: World model.\n    :param manifold_types: Per-block manifold types.\n    :param block_slices: Per-block slices.\n    :param cfg: Solver configuration.\n    :return: A reusable, jitted solver.\n    \"\"\"\n    residual_fn = wm.build_residual()\n    return JittedGNManifold.from_residual(residual_fn=residual_fn, manifold_types=manifold_types, block_slices=block_slices, cfg=cfg)\n</code></pre>"},{"location":"api/scene_graph/","title":"Scene Graph Modules","text":"<p>This section documents entity definitions and relational structures used to build differentiable dynamic scene graphs.</p>"},{"location":"api/scene_graph/#scene_graphentities","title":"<code>scene_graph.entities</code>","text":"<p>Entity definitions for the Dynamic Scene Graph.</p> <p>This module defines the core node types stored in the DSG-JIT scene graph, such as:</p> <pre><code>\u2022 Poses / agents (SE3 trajectories)\n\u2022 Places (topological nodes)\n\u2022 Rooms / regions\n\u2022 Objects\n\u2022 Voxel cells or volumetric primitives (if represented as entities)\n</code></pre> <p>Each entity is typically a lightweight data structure that carries:</p> <pre><code>\u2022 A unique identifier\n\u2022 A semantic type (e.g., \"agent\", \"object\", \"place\", \"room\")\n\u2022 Optional metric information (pose, position, bounding volume)\n\u2022 Optional attributes (class labels, instance ids, timestamps, etc.)\n</code></pre> <p>These entities form the nodes of the scene graph; edges and semantic relations between them are defined in <code>scene_graph.relations</code>.</p>"},{"location":"api/scene_graph/#scene_graph.entities--typical-contents","title":"Typical Contents","text":"<p>Common patterns in this module include:</p> <pre><code>\u2022 Data classes for:\n    - BaseEntity: minimal base type for all nodes\n    - AgentEntity: for robots / people with SE3 pose trajectories\n    - ObjectEntity: for movable / manipulable objects\n    - PlaceEntity: for nodes in the topological graph\n    - RoomEntity: for higher-level spatial regions\n\n\u2022 Utility functions for:\n    - Creating entities from raw SLAM / perception outputs\n    - Updating metric fields (e.g., pose) after optimization\n    - Serializing / deserializing entity metadata\n</code></pre>"},{"location":"api/scene_graph/#scene_graph.entities--integration-with-dsg-jit","title":"Integration with DSG-JIT","text":"<p>The entity layer is tightly coupled to:</p> <pre><code>\u2022 `world.scene_graph.SceneGraphWorld`:\n    which stores entities, relations, and their mapping to variables\n    in the factor graph.\n\n\u2022 `core.factor_graph.FactorGraph`:\n    entities that carry metric state (e.g., poses, voxel centers)\n    are typically tied to variables in the factor graph so they can\n    be optimized along with the rest of the world model.\n\n\u2022 `slam.measurements`:\n    certain measurements (e.g., pose attachments, voxel observations)\n    operate directly on entity-linked variables.\n</code></pre>"},{"location":"api/scene_graph/#scene_graph.entities--design-goals","title":"Design Goals","text":"<p>\u2022 Thin, explicit data model:     Entities should be simple, well-typed containers that are easy to     reason about and manipulate in experiments.</p> <p>\u2022 Bridging symbolic and geometric worlds:     Entities provide the anchor points where semantic structure (object,     room, agent, place) meets metric state (pose, voxel position, etc.).</p> <p>\u2022 Extendable for research:     New entity types (e.g., semantic regions, affordance nodes, learned     latent entities) can be added without changing the core optimization     backend, as long as they are mapped to appropriate variable types.</p>"},{"location":"api/scene_graph/#scene_graph.entities.ObjectNode","title":"<code>ObjectNode(id, position)</code>  <code>dataclass</code>","text":"<p>Scene graph object node with a 3D position.</p> <p>:param id: Integer identifier for this object node. :param position: 3D position of the object as a JAX array of shape (3,).</p>"},{"location":"api/scene_graph/#scene_graph.entities.RoomNode","title":"<code>RoomNode(id, position)</code>  <code>dataclass</code>","text":"<p>Scene graph room centroid represented as a 3D point.</p> <p>:param id: Integer identifier for this room node. :param position: 3D position of the room centroid as a JAX array of shape (3,).</p>"},{"location":"api/scene_graph/#scene_graphrelations","title":"<code>scene_graph.relations</code>","text":"<p>Semantic and topological relations for the Dynamic Scene Graph.</p> <p>This module defines the core relation types and utilities used to connect entities in the DSG-JIT scene graph, such as:</p> <pre><code>\u2022 Place \u2194 Place (topological connectivity)\n\u2022 Room \u2194 Room (adjacency, containment)\n\u2022 Object \u2194 Place / Room (support, inside, on, near)\n\u2022 Agent \u2194 Object / Place (interaction, visibility, reachability)\n</code></pre> <p>The goal is to provide a lightweight, JAX-friendly representation of edges and relation labels that can be used both for:</p> <pre><code>\u2022 Pure graph reasoning (e.g., \"what objects are on this table?\")\n\u2022 Differentiable optimization (e.g., factors that enforce relational\n  consistency between metric poses and symbolic structure)\n</code></pre>"},{"location":"api/scene_graph/#scene_graph.relations--typical-contents","title":"Typical Contents","text":"<p>Although the exact API may evolve, this module usually contains:</p> <pre><code>\u2022 Enumerations or string constants for relation types\n  (e.g., \"on\", \"inside\", \"adjacent\", \"connected_to\", \"observes\")\n\n\u2022 Simple data classes / containers for relations:\n    - relation id\n    - source entity id\n    - target entity id\n    - relation type\n    - optional attributes (weights, confidences, timestamps)\n\n\u2022 Helper functions for:\n    - Adding / removing relations in a `SceneGraphWorld`\n    - Querying neighbors by relation type\n    - Converting relations into factor-graph constraints when needed\n</code></pre>"},{"location":"api/scene_graph/#scene_graph.relations--design-goals","title":"Design Goals","text":"<p>\u2022 Separation of concerns:     Geometry (poses, voxels) is stored elsewhere; this module only     cares about relationships between entities.</p> <p>\u2022 Compatibility with optimization:     When relations induce constraints (e.g., \"object is on a surface\"),     these can be translated into factors in the world model or SLAM layer.</p> <p>\u2022 Extensibility:     New relation types or attributes should be easy to add without     breaking the core graph structure.</p>"},{"location":"api/scene_graph/#scene_graph.relations--notes","title":"Notes","text":"<p>The scene graph can be used in both non-differentiable and differentiable modes. In the differentiable setting, certain relations may correspond to factors whose residuals live in <code>slam.measurements</code>. This module provides the symbolic layer that those factors are grounded in.</p>"},{"location":"api/scene_graph/#scene_graph.relations.pose_place_attachment_residual","title":"<code>pose_place_attachment_residual(x, params)</code>","text":"<p>Residual tying a place's position to a pose's translation component.</p> <p>The input state vector <code>x</code> is assumed to be the concatenation of a pose vector and a place vector::</p> <pre><code>x = [pose_vec, place_vec]\n</code></pre> <p>By default, the pose is represented in <code>se(3)</code> as a 6D vector <code>[tx, ty, tz, rx, ry, rz]</code> and the place is a 1D scalar.</p> <p>The constraint enforces that the place coordinate tracks one component of the pose translation plus an optional offset::</p> <pre><code>pose_val     = pose_vec[pose_coord_index]\ntarget_place = pose_val + offset\nr            = place_vec - target_place\n</code></pre> <p>:param x: Flat state vector containing the pose and place variables,           <code>[pose_vec, place_vec]</code>. The first <code>pose_dim</code> entries are the           pose, followed by <code>place_dim</code> entries for the place. :param params: Dictionary of parameters controlling the attachment:                <code>\"pose_dim\"</code> (int, default <code>6</code>), the dimension of the                pose vector; <code>\"place_dim\"</code> (int, default <code>1</code>), the                dimension of the place vector; <code>\"pose_coord_index\"</code> (int,                default <code>0</code>), index of the pose component used to attach                the place; <code>\"offset\"</code> (array-like of shape <code>(place_dim,)</code>,                optional), additive offset applied to the selected pose                component before comparison. :return: Residual vector <code>r</code> with shape <code>(place_dim,)</code> enforcing the          attachment between pose and place. :rtype: jax.numpy.ndarray</p> Source code in <code>dsg-jit/dsg_jit/scene_graph/relations.py</code> <pre><code>def pose_place_attachment_residual(x: jnp.ndarray, params: Dict[str, jnp.ndarray]) -&gt; jnp.ndarray:\n    \"\"\"\n    Residual tying a place's position to a pose's translation component.\n\n    The input state vector ``x`` is assumed to be the concatenation of a pose\n    vector and a place vector::\n\n        x = [pose_vec, place_vec]\n\n    By default, the pose is represented in ``se(3)`` as a 6D vector\n    ``[tx, ty, tz, rx, ry, rz]`` and the place is a 1D scalar.\n\n    The constraint enforces that the place coordinate tracks one component of the\n    pose translation plus an optional offset::\n\n        pose_val     = pose_vec[pose_coord_index]\n        target_place = pose_val + offset\n        r            = place_vec - target_place\n\n    :param x: Flat state vector containing the pose and place variables,\n              ``[pose_vec, place_vec]``. The first ``pose_dim`` entries are the\n              pose, followed by ``place_dim`` entries for the place.\n    :param params: Dictionary of parameters controlling the attachment:\n                   ``\"pose_dim\"`` (int, default ``6``), the dimension of the\n                   pose vector; ``\"place_dim\"`` (int, default ``1``), the\n                   dimension of the place vector; ``\"pose_coord_index\"`` (int,\n                   default ``0``), index of the pose component used to attach\n                   the place; ``\"offset\"`` (array-like of shape ``(place_dim,)``,\n                   optional), additive offset applied to the selected pose\n                   component before comparison.\n    :return: Residual vector ``r`` with shape ``(place_dim,)`` enforcing the\n             attachment between pose and place.\n    :rtype: jax.numpy.ndarray\n    \"\"\"\n    pose_dim = int(params.get(\"pose_dim\", 6))\n    place_dim = int(params.get(\"place_dim\", 1))\n    coord_idx = int(params.get(\"pose_coord_index\", 0))\n\n    pose_vec = x[:pose_dim]\n    place_vec = x[pose_dim:pose_dim + place_dim]\n\n    offset = params.get(\"offset\", jnp.zeros(place_dim))\n\n    # For 1D, pose_coord_index picks one scalar from pose_vec\n    pose_val = pose_vec[coord_idx]\n    target = pose_val + offset  # broadcast if place_dim &gt; 1\n    # Make target same shape as place_vec\n    target_vec = jnp.ones_like(place_vec) * target\n\n    return place_vec - target_vec\n</code></pre>"},{"location":"api/scene_graph/#scene_graph.relations.room_centroid_residual","title":"<code>room_centroid_residual(x, params)</code>","text":"<p>Compute a residual enforcing that a room's position matches the centroid of its member places.</p> <p>The input state vector <code>x</code> is assumed to contain a concatenation of the room position followed by the positions of its member places::</p> <pre><code>x = [room_pos, place0_pos, place1_pos, ..., placeN_pos]\n</code></pre> <p>All positions live in :math:<code>\\mathbb{R}^d</code>, and <code>d</code> is provided via <code>params[\"dim\"]</code>.</p> <p>The residual is defined as::</p> <pre><code>r = room_pos - mean(place_positions)\n</code></pre> <p>If no member places are provided, the residual is a zero vector of the same shape as <code>room_pos</code>.</p> <p>:param x: Flat state vector containing the room position followed by the           positions of its member places. Shape <code>(dim * (N + 1),)</code> where           <code>dim</code> is the position dimension and <code>N</code> is the number of           member places. :param params: Dictionary of parameters. Must contain:                <code>\"dim\"</code> (int or scalar array) indicating the dimension                of each position vector. :return: Residual vector <code>r</code> with shape <code>(dim,)</code> enforcing that the room          lies at the centroid of its member places. :rtype: jax.numpy.ndarray</p> Source code in <code>dsg-jit/dsg_jit/scene_graph/relations.py</code> <pre><code>def room_centroid_residual(x: jnp.ndarray, params: Dict[str, jnp.ndarray]) -&gt; jnp.ndarray:\n    \"\"\"\n    Compute a residual enforcing that a room's position matches the centroid of its member places.\n\n    The input state vector ``x`` is assumed to contain a concatenation of the room\n    position followed by the positions of its member places::\n\n        x = [room_pos, place0_pos, place1_pos, ..., placeN_pos]\n\n    All positions live in :math:`\\\\mathbb{R}^d`, and ``d`` is provided via\n    ``params[\"dim\"]``.\n\n    The residual is defined as::\n\n        r = room_pos - mean(place_positions)\n\n    If no member places are provided, the residual is a zero vector of the same\n    shape as ``room_pos``.\n\n    :param x: Flat state vector containing the room position followed by the\n              positions of its member places. Shape ``(dim * (N + 1),)`` where\n              ``dim`` is the position dimension and ``N`` is the number of\n              member places.\n    :param params: Dictionary of parameters. Must contain:\n                   ``\"dim\"`` (int or scalar array) indicating the dimension\n                   of each position vector.\n    :return: Residual vector ``r`` with shape ``(dim,)`` enforcing that the room\n             lies at the centroid of its member places.\n    :rtype: jax.numpy.ndarray\n    \"\"\"\n\n    dim = int(params[\"dim\"])  # e.g. 1 or 3\n\n    # room position is first `dim` entries\n    room = x[:dim]\n\n    # remaining entries are stacked member positions\n    members_flat = x[dim:]\n    if members_flat.size == 0:\n        # No members -&gt; no constraint, residual 0\n        return jnp.zeros_like(room)\n\n    members = members_flat.reshape(-1, dim)  # shape (num_members, dim)\n    centroid = jnp.mean(members, axis=0)\n\n    return room - centroid\n</code></pre>"},{"location":"api/sensors/","title":"Sensor Modules","text":"<p>High-level sensor support for DSG-JIT. This package provides:</p> <ul> <li>Lightweight measurement containers: camera, LiDAR, IMU.</li> <li>Streaming abstractions (<code>sensors.streams</code>) for synthetic or file-based data.</li> <li>Conversion utilities (<code>sensors.conversion</code>) from raw samples \u2192 DSG-JIT measurements.</li> <li>Sensor fusion manager (<code>sensors.fusion.SensorFusionManager</code>) that:</li> <li>Polls one or more sensor streams.</li> <li>Converts them into measurements.</li> <li>Optionally forwards them to <code>WorldModel</code> / <code>SceneGraphWorld</code> helpers.</li> </ul>"},{"location":"api/sensors/#sensorsbase","title":"<code>sensors.base</code>","text":"<p>Abstract base classes and shared interfaces for DSG-JIT sensor modules.</p> <p>This module defines the foundational API that all sensor types in DSG-JIT (IMU, LiDAR, RGB cameras, range sensors, etc.) are expected to implement. By unifying the contract between sensor objects and the rest of the system, DSG-JIT enables plug-and-play multi-sensor integration without requiring special-case logic for each modality.</p> <p>The goal of this module is to answer a simple question:</p> <pre><code>\u201cWhat does it mean to be a sensor in DSG-JIT?\u201d\n</code></pre>"},{"location":"api/sensors/#sensors.base--core-components","title":"Core Components","text":"<p>BaseSensor     The abstract parent class for all sensors. It typically defines:</p> <pre><code>  - ``initialize()``  \u2014 optional setup before streaming begins  \n  - ``read()``        \u2014 return a *single typed measurement*  \n  - ``close()``       \u2014 release hardware or simulation resources\n\nSubclasses (e.g., ``IMUSensor``, ``LiDARSensor``, ``CameraSensor``)\nimplement their own measurement-specific logic, but all present\na consistent surface to the rest of DSG-JIT.\n</code></pre> <p>BaseMeasurement     A typed container for the output of a sensor.     Every measurement has:</p> <pre><code>  - ``timestamp``  \n  - device-specific payload (e.g., accelerations, images, point clouds)\n\nThe purpose of this common type is to make downstream modules\u2014\nfactor graphs, dynamic scene graphs, training loops, logging tools\u2014\ntreat all measurements uniformly.\n</code></pre>"},{"location":"api/sensors/#sensors.base--design-goals","title":"Design Goals","text":"<ol> <li> <p>Unified sensor API    All sensors behave the same from the perspective of DSG-JIT\u2019s    world model, optimization routines, and streaming helpers.</p> </li> <li> <p>Compatibility with synchronous &amp; asynchronous streams    The interfaces defined here are intentionally minimal so that    <code>streams.py</code> can wrap any sensor using either Python loops or    asyncio-based background tasks.</p> </li> <li> <p>Future-proof extensibility    The goal is for users to implement custom sensors (GPS, UWB, RADAR,    event cameras, tactile sensors, etc.) by subclassing    <code>BaseSensor</code> and returning custom <code>BaseMeasurement</code> types.</p> </li> <li> <p>Separation of concerns    This module defines contracts, not implementation logic.    Sensor-specific math, calibration, conversion, or projection    live in their respective modules (e.g., <code>lidar.py</code>, <code>camera.py</code>).</p> </li> </ol>"},{"location":"api/sensors/#sensors.base--summary","title":"Summary","text":"<p>The <code>base</code> module provides the essential abstraction layer required for building robust, modular, multi-sensor dynamic scene graphs. It ensures that all data entering DSG-JIT\u2014regardless of modality\u2014flows through a consistent, well-structured interface suitable for high-frequency SLAM, perception, and future real-time scene generation.</p>"},{"location":"api/sensors/#sensors.base.BaseMeasurement","title":"<code>BaseMeasurement(t, source, data, meta=None)</code>  <code>dataclass</code>","text":"<p>Generic typed measurement used by all DSG-JIT sensor backends.</p> <p>This class represents a single sensor sample emitted by a device or by a stream wrapper. All concrete sensor measurement types (e.g., :class:<code>CameraMeasurement</code>, :class:<code>LidarMeasurement</code>, :class:<code>IMUMeasurement</code>) should inherit from this class.</p> <p>:param t: Discrete timestamp or frame index associated with the sample. :type t: int :param source: Name of the sensor that produced this measurement     (e.g., <code>\"front_cam\"</code>, <code>\"lidar_0\"</code>, <code>\"imu_main\"</code>). :type source: str :param data: Raw modality-specific payload. Subclasses may refine this type.     For example, a camera may store an ndarray, LiDAR may store a point cloud,     and IMU may store (accel, gyro) tuples. :type data: Any :param meta: Optional metadata, such as exposure time, pose hints, or flags. :type meta: dict or None</p>"},{"location":"api/sensors/#sensors.base.Sensor","title":"<code>Sensor(name, agent_id)</code>","text":"<p>Abstract base class for all DSG-JIT sensors.</p> <p>Concrete subclasses implement :meth:<code>build_factors</code> to turn a :class:<code>SensorReading</code> into one or more :class:<code>core.types.Factor</code> instances, which can then be added to a :class:<code>world.model.WorldModel</code>.</p> <p>Sensors are intended to be stateless with respect to optimization: they describe how to map readings into factors, but do not own any variables themselves.</p> <p>Typical usage pattern::</p> <pre><code>sensor = SomeSensor(agent_id=\"robot0\", ...)\nreading = SensorReading(t=3, data=raw_measurement)\nfactors = sensor.build_factors(world_model, dsg, reading)\nfor f in factors:\n    world_model.fg.add_factor(f)\n</code></pre> <p>:param name: Human-readable name for this sensor instance. :type name: str :param agent_id: Identifier of the agent this sensor is mounted on,     e.g. <code>\"robot0\"</code>. Used to resolve pose nodes in the DSG. :type agent_id: str</p> Source code in <code>dsg-jit/dsg_jit/sensors/base.py</code> <pre><code>def __init__(self, name: str, agent_id: str) -&gt; None:\n    self.name = name\n    self.agent_id = agent_id\n</code></pre>"},{"location":"api/sensors/#sensors.base.Sensor.build_factors","title":"<code>build_factors(wm, dsg, reading)</code>","text":"<p>Convert a sensor reading into factor(s) to be added to the world.</p> <p>Subclasses must implement this to return a list of :class:<code>core.types.Factor</code> objects whose <code>var_ids</code> and <code>params</code> are consistent with the residuals registered in the world's factor graph.</p> <p>:param wm: World model into which new factors will be added. :type wm: world.model.WorldModel :param dsg: Dynamic scene graph providing access to pose node ids     for this sensor's agent at the requested time index. :type dsg: world.dynamic_scene_graph.DynamicSceneGraph :param reading: Sensor reading to convert. :type reading: SensorReading :return: List of factor objects ready to be added to     :attr:<code>wm.fg</code>. :rtype: list[core.types.Factor]</p> Source code in <code>dsg-jit/dsg_jit/sensors/base.py</code> <pre><code>def build_factors(\n    self,\n    wm: WorldModel,\n    dsg: DynamicSceneGraph,\n    reading: SensorReading,\n) -&gt; List[Factor]:\n    \"\"\"\n    Convert a sensor reading into factor(s) to be added to the world.\n\n    Subclasses must implement this to return a list of\n    :class:`core.types.Factor` objects whose ``var_ids`` and\n    ``params`` are consistent with the residuals registered in the\n    world's factor graph.\n\n    :param wm: World model into which new factors will be added.\n    :type wm: world.model.WorldModel\n    :param dsg: Dynamic scene graph providing access to pose node ids\n        for this sensor's agent at the requested time index.\n    :type dsg: world.dynamic_scene_graph.DynamicSceneGraph\n    :param reading: Sensor reading to convert.\n    :type reading: SensorReading\n    :return: List of factor objects ready to be added to\n        :attr:`wm.fg`.\n    :rtype: list[core.types.Factor]\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/sensors/#sensors.base.SensorReading","title":"<code>SensorReading(t, data)</code>  <code>dataclass</code>","text":"<p>Lightweight container for a single sensor measurement.</p> <p>:param t: Discrete time index or timestamp at which the reading was     taken. For now this is typically an integer matching the DSG's     time index. :type t: int :param data: Raw or minimally processed sensor payload. The exact     structure depends on the sensor type (e.g. a scalar range,     a 3D point, an image array, etc.). :type data: Any</p>"},{"location":"api/sensors/#sensorscamera","title":"<code>sensors.camera</code>","text":"<p>Camera sensor abstractions and utilities for DSG-JIT.</p> <p>This module defines lightweight, JAX-friendly camera interfaces that can be plugged into dynamic scene graph (DSG) pipelines. The goal is to provide a clean separation between:</p> <ul> <li>Raw image acquisition (e.g., from a hardware driver, simulator, or     prerecorded dataset), and</li> <li>Downstream SLAM / DSG consumers that only need structured frames     (RGB or grayscale) with timestamps and metadata.</li> </ul> <p>The module typically exposes:</p> <ul> <li> <p><code>CameraFrame</code>:       A simple dataclass-like structure representing a single image frame.       It usually stores image data (RGB or grayscale), optional depth, and       a timestamp or frame index.</p> </li> <li> <p><code>CameraSensor</code>:       A wrapper around an arbitrary user-provided capture function. The       capture function may return NumPy arrays or JAX arrays; the wrapper       normalizes these and provides a consistent interface for reading       frames in synchronous loops or via the generic sensor streams.</p> </li> <li> <p>Optional utilities for:</p> <ul> <li>Converting RGB frames to grayscale.</li> <li>Normalizing/typing images for consumption by JAX or downstream     vision modules.</li> <li>Integrating with the generic sensor streaming API (synchronous or     asynchronous).</li> </ul> </li> </ul> <p>These camera abstractions are intentionally minimal and do not perform full visual odometry or object detection. Instead, they are designed as building blocks for higher-level modules (e.g., visual SLAM, semantic DSG layers) that can interpret camera data and inject new nodes and factors into the scene graph or factor graph.</p> <p>The design philosophy is:</p> <ul> <li>Keep camera handling stateless where possible.</li> <li>Make it easy to wrap any existing camera source (OpenCV, ROS, custom     simulator, etc.) behind a small capture function.</li> <li>Ensure that integration with DSG-JIT remains explicit and composable,     so users can swap cameras or add multiple sensors without changing     core SLAM logic.</li> </ul>"},{"location":"api/sensors/#sensors.camera.AsyncCamera","title":"<code>AsyncCamera(intrinsics, aiter_fn, color_space='rgb')</code>  <code>dataclass</code>","text":"<p>Asynchronous camera source.</p> <p>:param intrinsics: Camera intrinsics. :param aiter_fn: Callable that returns an async iterator yielding images as numpy arrays. :param color_space: Color space of the images produced by aiter_fn, default is \"rgb\".</p>"},{"location":"api/sensors/#sensors.camera.AsyncCamera.frames","title":"<code>frames()</code>  <code>async</code>","text":"<p>Asynchronously iterate over frames from the camera.</p> <p>:returns: An async iterator yielding CameraFrame objects with current timestamp, no frame_id, and the configured color_space.</p> Source code in <code>dsg-jit/dsg_jit/sensors/camera.py</code> <pre><code>async def frames(self) -&gt; AsyncIterator[CameraFrame]:\n    \"\"\"\n    Asynchronously iterate over frames from the camera.\n\n    :returns: An async iterator yielding CameraFrame objects with current timestamp, no frame_id, and the configured color_space.\n    \"\"\"\n    async for img in self.aiter_fn():\n        yield CameraFrame(\n            image=img,\n            timestamp=time.time(),\n            frame_id=None,\n            color_space=self.color_space\n        )\n</code></pre>"},{"location":"api/sensors/#sensors.camera.CameraFrame","title":"<code>CameraFrame(image, timestamp, frame_id, color_space)</code>  <code>dataclass</code>","text":"<p>A single camera frame.</p> <p>:param image: The image array. :param timestamp: Timestamp of the frame capture. :param frame_id: Optional frame identifier. :param color_space: Color space of the image, either \"rgb\" or \"gray\".</p>"},{"location":"api/sensors/#sensors.camera.CameraIntrinsics","title":"<code>CameraIntrinsics(width, height, fx, fy, cx, cy)</code>  <code>dataclass</code>","text":"<p>Pinhole camera intrinsics.</p> <p>:param width: Image width in pixels. :param height: Image height in pixels. :param fx: Focal length in x direction. :param fy: Focal length in y direction. :param cx: Principal point x coordinate. :param cy: Principal point y coordinate.</p>"},{"location":"api/sensors/#sensors.camera.CameraMeasurement","title":"<code>CameraMeasurement(frame, sensor_id='cam0', T_cam_body=None, seq=None, metadata=None)</code>  <code>dataclass</code>","text":"<p>High-level camera measurement suitable for feeding into SLAM / DSG layers.</p> <p>This wraps a low-level :class:<code>CameraFrame</code> with additional metadata such as sensor ID, extrinsics, and an optional sequence index. It is intentionally minimal and can be extended by applications as needed.</p> <p>:param frame:     The underlying camera frame (image, timestamp, color space, etc.). :param sensor_id:     Identifier for the camera (e.g., <code>\"cam0\"</code>). Useful when multiple     cameras are present. :param T_cam_body:     Optional 4x4 homogeneous transform from body frame to camera frame.     If omitted, downstream consumers may assume an identity transform or     use a configured default. :param seq:     Optional sequence index (e.g., frame counter) for convenience. :param metadata:     Optional free-form dictionary for extra information     (exposure, gain, rolling-shutter parameters, etc.).</p>"},{"location":"api/sensors/#sensors.camera.SyncCamera","title":"<code>SyncCamera(intrinsics, read_fn, color_space='rgb')</code>  <code>dataclass</code>","text":"<p>Synchronous camera source.</p> <p>:param intrinsics: Camera intrinsics. :param read_fn: Callable that returns an image as a numpy array. :param color_space: Color space of the images produced by read_fn, default is \"rgb\".</p>"},{"location":"api/sensors/#sensors.camera.SyncCamera.read","title":"<code>read()</code>","text":"<p>Read a single frame from the camera.</p> <p>:returns: A CameraFrame containing the image, current timestamp, no frame_id, and the configured color_space.</p> Source code in <code>dsg-jit/dsg_jit/sensors/camera.py</code> <pre><code>def read(self) -&gt; CameraFrame:\n    \"\"\"\n    Read a single frame from the camera.\n\n    :returns: A CameraFrame containing the image, current timestamp, no frame_id, and the configured color_space.\n    \"\"\"\n    img = self.read_fn()\n    return CameraFrame(\n        image=img,\n        timestamp=time.time(),\n        frame_id=None,\n        color_space=self.color_space\n    )\n</code></pre>"},{"location":"api/sensors/#sensors.camera.is_gray","title":"<code>is_gray(frame)</code>","text":"<p>Check if the frame is in grayscale color space.</p> <p>:param frame: The camera frame to check. :returns: True if the frame's color space is one of \"gray\", \"grey\", or \"grayscale\" (case-insensitive), False otherwise.</p> Source code in <code>dsg-jit/dsg_jit/sensors/camera.py</code> <pre><code>def is_gray(frame: CameraFrame) -&gt; bool:\n    \"\"\"\n    Check if the frame is in grayscale color space.\n\n    :param frame: The camera frame to check.\n    :returns: True if the frame's color space is one of \"gray\", \"grey\", or \"grayscale\" (case-insensitive), False otherwise.\n    \"\"\"\n    return frame.color_space.lower() in (\"gray\", \"grey\", \"grayscale\")\n</code></pre>"},{"location":"api/sensors/#sensors.camera.is_rgb","title":"<code>is_rgb(frame)</code>","text":"<p>Check if the frame is in RGB color space.</p> <p>:param frame: The camera frame to check. :returns: True if the frame's color space is \"rgb\" (case-insensitive), False otherwise.</p> Source code in <code>dsg-jit/dsg_jit/sensors/camera.py</code> <pre><code>def is_rgb(frame: CameraFrame) -&gt; bool:\n    \"\"\"\n    Check if the frame is in RGB color space.\n\n    :param frame: The camera frame to check.\n    :returns: True if the frame's color space is \"rgb\" (case-insensitive), False otherwise.\n    \"\"\"\n    return frame.color_space.lower() == \"rgb\"\n</code></pre>"},{"location":"api/sensors/#sensors.camera.to_grayscale","title":"<code>to_grayscale(frame)</code>","text":"<p>Convert an RGB frame to grayscale. If the frame is already grayscale, returns it unchanged.</p> <p>For RGB frames, assumes image shape is (H, W, 3) and applies standard luminance weights [0.299, 0.587, 0.114] to convert to grayscale with shape (H, W). The returned image is float32 in [0, 1] if the input was uint8.</p> <p>:param frame: The input camera frame. :returns: A new CameraFrame in grayscale color space with the same timestamp and frame_id.</p> Source code in <code>dsg-jit/dsg_jit/sensors/camera.py</code> <pre><code>def to_grayscale(frame: CameraFrame) -&gt; CameraFrame:\n    \"\"\"\n    Convert an RGB frame to grayscale. If the frame is already grayscale, returns it unchanged.\n\n    For RGB frames, assumes image shape is (H, W, 3) and applies standard luminance weights [0.299, 0.587, 0.114]\n    to convert to grayscale with shape (H, W). The returned image is float32 in [0, 1] if the input was uint8.\n\n    :param frame: The input camera frame.\n    :returns: A new CameraFrame in grayscale color space with the same timestamp and frame_id.\n    \"\"\"\n    if is_gray(frame):\n        return frame\n    img = np.asarray(frame.image)\n    if img.dtype == np.uint8:\n        img = img.astype(np.float32) / 255.0\n    gray_img = np.dot(img[..., :3], [0.299, 0.587, 0.114])\n    return CameraFrame(\n        image=gray_img,\n        timestamp=frame.timestamp,\n        frame_id=frame.frame_id,\n        color_space=\"gray\"\n    )\n</code></pre>"},{"location":"api/sensors/#sensors.camera.to_rgb","title":"<code>to_rgb(frame)</code>","text":"<p>Convert a grayscale frame to RGB by stacking the gray channel three times along the last axis. If the frame is already RGB, returns it unchanged.</p> <p>:param frame: The input camera frame. :returns: A new CameraFrame in RGB color space with the same timestamp and frame_id.</p> Source code in <code>dsg-jit/dsg_jit/sensors/camera.py</code> <pre><code>def to_rgb(frame: CameraFrame) -&gt; CameraFrame:\n    \"\"\"\n    Convert a grayscale frame to RGB by stacking the gray channel three times along the last axis.\n    If the frame is already RGB, returns it unchanged.\n\n    :param frame: The input camera frame.\n    :returns: A new CameraFrame in RGB color space with the same timestamp and frame_id.\n    \"\"\"\n    if is_rgb(frame):\n        return frame\n    img = np.asarray(frame.image)\n    if img.ndim == 2:\n        rgb_img = np.stack([img, img, img], axis=-1)\n    else:\n        rgb_img = img\n    return CameraFrame(\n        image=rgb_img,\n        timestamp=frame.timestamp,\n        frame_id=frame.frame_id,\n        color_space=\"rgb\"\n    )\n</code></pre>"},{"location":"api/sensors/#sensorsconversion","title":"<code>sensors.conversion</code>","text":"<p>Conversion utilities from sensor measurements to factor-graph factors.</p> <p>This module implements the \"measurement conversion layer\" for DSG-JIT: given typed sensor measurements (IMU, LiDAR, cameras, simple range sensors, etc.), it produces factor descriptions that can be attached to the core :class:<code>core.factor_graph.FactorGraph</code> or to higher-level world/scene-graph abstractions.</p> <p>The core idea is to keep sensor-facing code and factor-graph-facing code decoupled:</p> <ul> <li>Sensor modules (<code>sensors.camera</code>, <code>sensors.imu</code>, <code>sensors.lidar</code>,   <code>sensors.streams</code>, \u2026) produce strongly-typed measurement objects.</li> <li> <p>This module converts those measurements into small   :class:<code>MeasurementFactor</code> records describing:</p> <ul> <li><code>factor_type</code> (string key for the residual)</li> <li><code>var_ids</code> (tuple of variable node ids to connect)</li> <li><code>params</code> (dictionary passed into the residual function)</li> </ul> </li> </ul> <p>Downstream code can then:</p> <ul> <li>Construct :class:<code>core.types.Factor</code> objects from these records.</li> <li>Call :meth:<code>core.factor_graph.FactorGraph.add_factor</code>.</li> <li>Or wrap them in higher-level helpers in :mod:<code>world.scene_graph</code>.</li> </ul> <p>This keeps sensor integration \"plug-and-play\" while preserving a clean, minimal interface for the optimization engine.</p>"},{"location":"api/sensors/#sensors.conversion.MeasurementFactor","title":"<code>MeasurementFactor(factor_type, var_ids, params)</code>  <code>dataclass</code>","text":"<p>Lightweight description of a factor generated from a sensor measurement.</p> <p>This is intentionally decoupled from :class:<code>core.types.Factor</code> so that the conversion layer does not depend on internal factor-graph details. Call :func:<code>measurement_factors_to_graph_factors</code> to turn these into concrete :class:<code>Factor</code> instances, or use :func:<code>apply_measurement_factors</code> to add them directly to a :class:<code>FactorGraph</code>.</p> <p>:param factor_type: String key for the residual function     (e.g. <code>\"range_1d\"</code>, <code>\"pose_landmark_bearing\"</code>,     <code>\"voxel_point_obs\"</code>, etc.). This must correspond to a type     previously registered via     :meth:<code>core.factor_graph.FactorGraph.register_residual</code>. :type factor_type: str :param var_ids: Tuple of variable node ids that this factor connects,     in the order expected by the residual function. :type var_ids: tuple[int, ...] :param params: Parameter dictionary passed into the residual function.     Entries are typically NumPy/JAX arrays or scalar floats     (e.g. <code>{\"measurement\": ..., \"sigma\": ...}</code>). :type params: dict[str, Any]</p>"},{"location":"api/sensors/#sensors.conversion.RangeMeasurement","title":"<code>RangeMeasurement(distance, ray_dir)</code>  <code>dataclass</code>","text":"<p>Simple 1D range measurement along a known unit ray.</p> <p>:param distance: Measured distance along the ray, in meters. :param ray_dir: Unit direction vector in the sensor frame, shape (3,).</p>"},{"location":"api/sensors/#sensors.conversion.apply_measurement_factors","title":"<code>apply_measurement_factors(fg, meas_factors)</code>","text":"<p>Add a sequence of measurement-derived factors to a factor graph.</p> <p>This is a thin convenience wrapper around :func:<code>measurement_factors_to_graph_factors</code> and :meth:<code>core.factor_graph.FactorGraph.add_factor</code>.</p> <p>:param fg: The factor graph to which the new factors should be added. :type fg: FactorGraph :param meas_factors: Iterable of :class:<code>MeasurementFactor</code> objects. :type meas_factors: Iterable[MeasurementFactor] :return: This function has no return value; it mutates <code>fg</code> in-place     by adding new factors. :rtype: None</p> Source code in <code>dsg-jit/dsg_jit/sensors/conversion.py</code> <pre><code>def apply_measurement_factors(\n    fg: FactorGraph,\n    meas_factors: Iterable[MeasurementFactor],\n) -&gt; None:\n    \"\"\"\n    Add a sequence of measurement-derived factors to a factor graph.\n\n    This is a thin convenience wrapper around\n    :func:`measurement_factors_to_graph_factors` and\n    :meth:`core.factor_graph.FactorGraph.add_factor`.\n\n    :param fg: The factor graph to which the new factors should be added.\n    :type fg: FactorGraph\n    :param meas_factors: Iterable of :class:`MeasurementFactor` objects.\n    :type meas_factors: Iterable[MeasurementFactor]\n    :return: This function has no return value; it mutates ``fg`` in-place\n        by adding new factors.\n    :rtype: None\n    \"\"\"\n    for factor in measurement_factors_to_graph_factors(meas_factors):\n        fg.add_factor(factor)\n</code></pre>"},{"location":"api/sensors/#sensors.conversion.bearing_to_factor","title":"<code>bearing_to_factor(pose_id, landmark_id, bearing_vec, sigma=0.01, factor_type='pose_landmark_bearing')</code>","text":"<p>Convert a bearing vector to a factor description.</p> <p>This is suitable for camera-like observations where you have a unit bearing vector from the camera pose to a landmark in either camera or world coordinates, and a residual function that enforces angular consistency between the predicted bearing and the measured one.</p> <p>:param pose_id: Node id of the camera/pose variable. :type pose_id: int :param landmark_id: Node id of the landmark/point variable. :type landmark_id: int :param bearing_vec: Measured bearing direction as a vector. This     should typically be normalized (unit length) and have shape     <code>(2,)</code> or <code>(3,)</code>, depending on the residual implementation. :type bearing_vec: jax.numpy.ndarray :param sigma: Measurement noise standard deviation in angular units     (radians or an equivalent bearing metric). :type sigma: float :param factor_type: String key for the residual function (e.g.     <code>\"pose_landmark_bearing\"</code>). Must match a registered factor     type in the :class:<code>FactorGraph</code>. :type factor_type: str :return: A :class:<code>MeasurementFactor</code> describing the bearing     constraint. :rtype: MeasurementFactor</p> Source code in <code>dsg-jit/dsg_jit/sensors/conversion.py</code> <pre><code>def bearing_to_factor(\n    pose_id: int,\n    landmark_id: int,\n    bearing_vec: jnp.ndarray,\n    sigma: float = 0.01,\n    factor_type: str = \"pose_landmark_bearing\",\n) -&gt; MeasurementFactor:\n    \"\"\"\n    Convert a bearing vector to a factor description.\n\n    This is suitable for camera-like observations where you have a unit\n    bearing vector from the camera pose to a landmark in either camera\n    or world coordinates, and a residual function that enforces angular\n    consistency between the predicted bearing and the measured one.\n\n    :param pose_id: Node id of the camera/pose variable.\n    :type pose_id: int\n    :param landmark_id: Node id of the landmark/point variable.\n    :type landmark_id: int\n    :param bearing_vec: Measured bearing direction as a vector. This\n        should typically be normalized (unit length) and have shape\n        ``(2,)`` or ``(3,)``, depending on the residual implementation.\n    :type bearing_vec: jax.numpy.ndarray\n    :param sigma: Measurement noise standard deviation in angular units\n        (radians or an equivalent bearing metric).\n    :type sigma: float\n    :param factor_type: String key for the residual function (e.g.\n        ``\"pose_landmark_bearing\"``). Must match a registered factor\n        type in the :class:`FactorGraph`.\n    :type factor_type: str\n    :return: A :class:`MeasurementFactor` describing the bearing\n        constraint.\n    :rtype: MeasurementFactor\n    \"\"\"\n    bearing_vec = jnp.asarray(bearing_vec, dtype=jnp.float32)\n    params: Dict[str, Any] = {\n        \"bearing_meas\": bearing_vec,\n        \"sigma\": float(sigma),\n    }\n    return MeasurementFactor(\n        factor_type=factor_type,\n        var_ids=(pose_id, landmark_id),\n        params=params,\n    )\n</code></pre>"},{"location":"api/sensors/#sensors.conversion.camera_bearings_to_factors","title":"<code>camera_bearings_to_factors(pose_id, landmark_ids, measurement, sigma=0.01, factor_type='pose_landmark_bearing')</code>","text":"<p>Convert a :class:<code>sensors.camera.CameraMeasurement</code> containing bearing directions into a list of measurement factors.</p> <p>This helper assumes that the camera front-end has already extracted unit bearing vectors from image data (e.g. via feature detection and calibration), and that these bearings have been associated with a set of landmark ids. For each <code>landmark_id</code> and corresponding row in <code>measurement.bearings</code>, we construct a bearing factor using :func:<code>bearing_to_factor</code>.</p> <p>:param pose_id: Node id of the camera/pose variable in the factor graph. :type pose_id: int :param landmark_ids: Sequence of landmark node ids, one per bearing     vector in <code>measurement.bearings</code>. :type landmark_ids: Sequence[int] :param measurement: Camera measurement containing an array of bearing     vectors in <code>measurement.bearings</code> with shape <code>(N, D)</code> where     <code>D</code> is typically 2 or 3. :type measurement: CameraMeasurement :param sigma: Bearing noise standard deviation passed through to     :func:<code>bearing_to_factor</code>. :type sigma: float :param factor_type: Factor type string for the bearing residual,     usually <code>\"pose_landmark_bearing\"</code>. :type factor_type: str :return: List of :class:<code>MeasurementFactor</code> objects, one per     (pose, landmark) bearing observation. :rtype: list[MeasurementFactor] :raises ValueError: If the number of landmark ids does not match the     number of bearing vectors stored in the measurement.</p> Source code in <code>dsg-jit/dsg_jit/sensors/conversion.py</code> <pre><code>def camera_bearings_to_factors(\n    pose_id: int,\n    landmark_ids: Sequence[int],\n    measurement: CameraMeasurement,\n    sigma: float = 0.01,\n    factor_type: str = \"pose_landmark_bearing\",\n) -&gt; List[MeasurementFactor]:\n    \"\"\"\n    Convert a :class:`sensors.camera.CameraMeasurement` containing bearing\n    directions into a list of measurement factors.\n\n    This helper assumes that the camera front-end has already extracted\n    unit bearing vectors from image data (e.g. via feature detection and\n    calibration), and that these bearings have been associated with a set\n    of landmark ids. For each ``landmark_id`` and corresponding row in\n    ``measurement.bearings``, we construct a bearing factor using\n    :func:`bearing_to_factor`.\n\n    :param pose_id: Node id of the camera/pose variable in the factor graph.\n    :type pose_id: int\n    :param landmark_ids: Sequence of landmark node ids, one per bearing\n        vector in ``measurement.bearings``.\n    :type landmark_ids: Sequence[int]\n    :param measurement: Camera measurement containing an array of bearing\n        vectors in ``measurement.bearings`` with shape ``(N, D)`` where\n        ``D`` is typically 2 or 3.\n    :type measurement: CameraMeasurement\n    :param sigma: Bearing noise standard deviation passed through to\n        :func:`bearing_to_factor`.\n    :type sigma: float\n    :param factor_type: Factor type string for the bearing residual,\n        usually ``\"pose_landmark_bearing\"``.\n    :type factor_type: str\n    :return: List of :class:`MeasurementFactor` objects, one per\n        (pose, landmark) bearing observation.\n    :rtype: list[MeasurementFactor]\n    :raises ValueError: If the number of landmark ids does not match the\n        number of bearing vectors stored in the measurement.\n    \"\"\"\n    bearings = jnp.asarray(measurement.bearings, dtype=jnp.float32)\n    if bearings.ndim != 2:\n        raise ValueError(\n            f\"measurement.bearings must have shape (N, D), got {bearings.shape}\"\n        )\n    if len(landmark_ids) != bearings.shape[0]:\n        raise ValueError(\n            f\"len(landmark_ids)={len(landmark_ids)} does not match \"\n            f\"measurement.bearings.shape[0]={bearings.shape[0]}\"\n        )\n\n    factors: List[MeasurementFactor] = []\n    for lid, b in zip(landmark_ids, bearings):\n        factors.append(\n            bearing_to_factor(\n                pose_id=pose_id,\n                landmark_id=int(lid),\n                bearing_vec=b,\n                sigma=sigma,\n                factor_type=factor_type,\n            )\n        )\n    return factors\n</code></pre>"},{"location":"api/sensors/#sensors.conversion.camera_depth_to_points_sensor","title":"<code>camera_depth_to_points_sensor(cam, depth)</code>","text":"<p>Convert a depth image into a 3D point cloud in the camera frame.</p> <p>The depth image is assumed to have the same width/height as specified by the camera intrinsics. For each pixel <code>(u, v)</code> with depth <code>d</code>, we compute a ray via :func:<code>pixel_to_ray_camera</code> and place the point at <code>d * ray</code>.</p> <p>:param cam: Camera measurement with intrinsics. :param depth: Depth map of shape <code>(H, W)</code> in meters. :returns: Array of points of shape <code>(H*W, 3)</code> in the camera frame.     Invalid or zero depths are skipped.</p> Source code in <code>dsg-jit/dsg_jit/sensors/conversion.py</code> <pre><code>def camera_depth_to_points_sensor(\n    cam: CameraMeasurement,\n    depth: jnp.ndarray,\n) -&gt; jnp.ndarray:\n    \"\"\"\n    Convert a depth image into a 3D point cloud in the camera frame.\n\n    The depth image is assumed to have the same width/height as specified\n    by the camera intrinsics. For each pixel ``(u, v)`` with depth ``d``,\n    we compute a ray via :func:`pixel_to_ray_camera` and place the point\n    at ``d * ray``.\n\n    :param cam: Camera measurement with intrinsics.\n    :param depth: Depth map of shape ``(H, W)`` in meters.\n    :returns: Array of points of shape ``(H*W, 3)`` in the camera frame.\n        Invalid or zero depths are skipped.\n    \"\"\"\n    H, W = depth.shape\n    points = []\n\n    for v in range(H):\n        for u in range(W):\n            d = float(depth[v, u])\n            if d &lt;= 0.0:\n                continue\n            ray = pixel_to_ray_camera(cam, float(u), float(v))\n            p = d * ray\n            points.append(p)\n\n    if not points:\n        return jnp.zeros((0, 3), dtype=jnp.float32)\n\n    return jnp.stack(points, axis=0)\n</code></pre>"},{"location":"api/sensors/#sensors.conversion.imu_to_factors_placeholder","title":"<code>imu_to_factors_placeholder(pose_ids, imu_meas)</code>","text":"<p>Placeholder conversion from IMU measurement to factor descriptions.</p> <p>In a full SLAM system, IMU data is typically handled via preintegration over multiple high-rate samples to produce a single inertial factor between two poses. That logic is non-trivial and highly application specific, so this function serves as a placeholder and example.</p> <p>For now, it returns an empty list and is intended to be replaced with a proper preintegration pipeline in future work.</p> <p>:param pose_ids: Sequence of pose node ids between which an IMU factor     would be created (e.g. previous pose id and current pose id). :type pose_ids: Sequence[int] :param imu_meas: A single IMU measurement containing accelerometer and     gyroscope readings along with a timestamp. :type imu_meas: IMUMeasurement :return: An empty list. Replace with application-specific IMU factor     generation as needed. :rtype: list[MeasurementFactor]</p> Source code in <code>dsg-jit/dsg_jit/sensors/conversion.py</code> <pre><code>def imu_to_factors_placeholder(\n    pose_ids: Sequence[int],\n    imu_meas: IMUMeasurement,\n) -&gt; List[MeasurementFactor]:\n    \"\"\"\n    Placeholder conversion from IMU measurement to factor descriptions.\n\n    In a full SLAM system, IMU data is typically handled via *preintegration*\n    over multiple high-rate samples to produce a single inertial factor\n    between two poses. That logic is non-trivial and highly application\n    specific, so this function serves as a placeholder and example.\n\n    For now, it returns an empty list and is intended to be replaced with\n    a proper preintegration pipeline in future work.\n\n    :param pose_ids: Sequence of pose node ids between which an IMU factor\n        would be created (e.g. previous pose id and current pose id).\n    :type pose_ids: Sequence[int]\n    :param imu_meas: A single IMU measurement containing accelerometer and\n        gyroscope readings along with a timestamp.\n    :type imu_meas: IMUMeasurement\n    :return: An empty list. Replace with application-specific IMU factor\n        generation as needed.\n    :rtype: list[MeasurementFactor]\n    \"\"\"\n    _ = pose_ids, imu_meas  # avoid unused variable warnings\n    return []\n</code></pre>"},{"location":"api/sensors/#sensors.conversion.integrate_imu_delta","title":"<code>integrate_imu_delta(imu, dt, gravity=None)</code>","text":"<p>Integrate a single IMU sample into a small SE(3) increment (se(3) vector).</p> <p>This is a very simple, single-step integrator meant as a starting point / placeholder. For real applications, a proper preintegration scheme or filter should be used instead.</p> <p>The returned 6D vector is in the form::</p> <pre><code>[dtx, dty, dtz, drx, dry, drz]\n</code></pre> <p>where <code>dt*</code> is the approximate translational displacement in the IMU frame and <code>dr*</code> is a small-angle approximation for the rotation.</p> <p>:param imu: IMU measurement containing linear acceleration and angular     velocity in the sensor frame. :param dt: Time step in seconds between this sample and the previous one. :param gravity: Optional gravity vector (in sensor frame). If provided,     it is subtracted from the measured acceleration before integration.     If <code>None</code>, no gravity compensation is performed. :returns: A length-6 JAX array representing a small SE(3) increment in     the IMU frame.</p> Source code in <code>dsg-jit/dsg_jit/sensors/conversion.py</code> <pre><code>def integrate_imu_delta(\n    imu: IMUMeasurement,\n    dt: float,\n    gravity: jnp.ndarray | None = None,\n) -&gt; jnp.ndarray:\n    \"\"\"\n    Integrate a single IMU sample into a small SE(3) increment (se(3) vector).\n\n    This is a **very** simple, single-step integrator meant as a starting\n    point / placeholder. For real applications, a proper preintegration\n    scheme or filter should be used instead.\n\n    The returned 6D vector is in the form::\n\n        [dtx, dty, dtz, drx, dry, drz]\n\n    where ``dt*`` is the approximate translational displacement in the IMU\n    frame and ``dr*`` is a small-angle approximation for the rotation.\n\n    :param imu: IMU measurement containing linear acceleration and angular\n        velocity in the sensor frame.\n    :param dt: Time step in seconds between this sample and the previous one.\n    :param gravity: Optional gravity vector (in sensor frame). If provided,\n        it is subtracted from the measured acceleration before integration.\n        If ``None``, no gravity compensation is performed.\n    :returns: A length-6 JAX array representing a small SE(3) increment in\n        the IMU frame.\n    \"\"\"\n    acc = jnp.asarray(imu.accel, dtype=jnp.float32)\n    gyro = jnp.asarray(imu.gyro, dtype=jnp.float32)\n\n    if gravity is not None:\n        gravity = jnp.asarray(gravity, dtype=jnp.float32)\n        acc = acc - gravity\n\n    # Very crude single-step integration:\n    #   v \u2248 a * dt\n    #   p \u2248 0.5 * a * dt^2\n    #   \u03b8 \u2248 \u03c9 * dt\n    dp = 0.5 * acc * (dt ** 2)\n    dtheta = gyro * dt\n\n    return jnp.concatenate([dp, dtheta], axis=0)\n</code></pre>"},{"location":"api/sensors/#sensors.conversion.lidar_measurement_to_voxel_factors","title":"<code>lidar_measurement_to_voxel_factors(measurement, sigma=0.05, factor_type='voxel_point_obs')</code>","text":"<p>Convert a :class:<code>sensors.lidar.LidarMeasurement</code> into voxel-point observation factors.</p> <p>This helper assumes that the LiDAR front-end has already projected raw ranges into 3D world coordinates and, optionally, associated each point with a voxel id. If <code>measurement.voxel_ids</code> is provided, it is used directly; otherwise, the caller is expected to supply voxel associations separately.</p> <p>Concretely, this is a thin wrapper around :func:<code>lidar_scan_to_voxel_factors</code>, using <code>measurement.points_world</code> and <code>measurement.voxel_ids</code>.</p> <p>:param measurement: LiDAR measurement containing a point cloud in     world coordinates and optional voxel assignments. :type measurement: LidarMeasurement :param sigma: Noise level for each point in world units, forwarded to     :func:<code>voxel_point_obs_factor</code>. :type sigma: float :param factor_type: Factor type string used for all voxel-point     factors, typically <code>\"voxel_point_obs\"</code>. :type factor_type: str :return: List of :class:<code>MeasurementFactor</code> objects describing the     LiDAR point cloud constraints. :rtype: list[MeasurementFactor] :raises ValueError: If <code>measurement.voxel_ids</code> is <code>None</code> or its     length does not match the number of points.</p> Source code in <code>dsg-jit/dsg_jit/sensors/conversion.py</code> <pre><code>def lidar_measurement_to_voxel_factors(\n    measurement: LidarMeasurement,\n    sigma: float = 0.05,\n    factor_type: str = \"voxel_point_obs\",\n) -&gt; List[MeasurementFactor]:\n    \"\"\"\n    Convert a :class:`sensors.lidar.LidarMeasurement` into voxel-point\n    observation factors.\n\n    This helper assumes that the LiDAR front-end has already projected raw\n    ranges into 3D world coordinates and, optionally, associated each\n    point with a voxel id. If ``measurement.voxel_ids`` is provided, it is\n    used directly; otherwise, the caller is expected to supply voxel\n    associations separately.\n\n    Concretely, this is a thin wrapper around\n    :func:`lidar_scan_to_voxel_factors`, using\n    ``measurement.points_world`` and ``measurement.voxel_ids``.\n\n    :param measurement: LiDAR measurement containing a point cloud in\n        world coordinates and optional voxel assignments.\n    :type measurement: LidarMeasurement\n    :param sigma: Noise level for each point in world units, forwarded to\n        :func:`voxel_point_obs_factor`.\n    :type sigma: float\n    :param factor_type: Factor type string used for all voxel-point\n        factors, typically ``\"voxel_point_obs\"``.\n    :type factor_type: str\n    :return: List of :class:`MeasurementFactor` objects describing the\n        LiDAR point cloud constraints.\n    :rtype: list[MeasurementFactor]\n    :raises ValueError: If ``measurement.voxel_ids`` is ``None`` or its\n        length does not match the number of points.\n    \"\"\"\n    points_world = jnp.asarray(measurement.points_world, dtype=jnp.float32)\n    if points_world.ndim != 2 or points_world.shape[1] != 3:\n        raise ValueError(\n            f\"measurement.points_world must have shape (N, 3), got {points_world.shape}\"\n        )\n\n    if measurement.voxel_ids is None:\n        raise ValueError(\n            \"measurement.voxel_ids is None; voxel associations are required \"\n            \"to build voxel-point factors.\"\n        )\n\n    voxel_ids_seq: Sequence[int] = list(measurement.voxel_ids)\n    if len(voxel_ids_seq) != points_world.shape[0]:\n        raise ValueError(\n            f\"len(measurement.voxel_ids)={len(voxel_ids_seq)} does not match \"\n            f\"measurement.points_world.shape[0]={points_world.shape[0]}\"\n        )\n\n    return lidar_scan_to_voxel_factors(\n        voxel_ids=voxel_ids_seq,\n        points_world=points_world,\n        sigma=sigma,\n        factor_type=factor_type,\n    )\n</code></pre>"},{"location":"api/sensors/#sensors.conversion.lidar_scan_to_points_sensor","title":"<code>lidar_scan_to_points_sensor(scan)</code>","text":"<p>Convert a planar LiDAR scan into 3D points in the sensor frame.</p> <p>This function assumes a 2D planar LiDAR mounted in the <code>x-y</code> plane, with all points lying at <code>z=0</code> in the sensor frame::</p> <pre><code>x = r * cos(theta)\ny = r * sin(theta)\nz = 0\n</code></pre> <p>:param scan: LiDAR measurement containing per-beam ranges and angles. :returns: Array of points of shape <code>(N, 3)</code> in the sensor frame.</p> Source code in <code>dsg-jit/dsg_jit/sensors/conversion.py</code> <pre><code>def lidar_scan_to_points_sensor(\n    scan: LidarMeasurement,\n) -&gt; jnp.ndarray:\n    \"\"\"\n    Convert a planar LiDAR scan into 3D points in the sensor frame.\n\n    This function assumes a 2D planar LiDAR mounted in the ``x-y`` plane,\n    with all points lying at ``z=0`` in the sensor frame::\n\n        x = r * cos(theta)\n        y = r * sin(theta)\n        z = 0\n\n    :param scan: LiDAR measurement containing per-beam ranges and angles.\n    :returns: Array of points of shape ``(N, 3)`` in the sensor frame.\n    \"\"\"\n    ranges = jnp.asarray(scan.ranges, dtype=jnp.float32)\n    angles = jnp.asarray(scan.angles, dtype=jnp.float32)\n\n    x = ranges * jnp.cos(angles)\n    y = ranges * jnp.sin(angles)\n    z = jnp.zeros_like(x)\n\n    return jnp.stack([x, y, z], axis=-1)\n</code></pre>"},{"location":"api/sensors/#sensors.conversion.lidar_scan_to_points_world","title":"<code>lidar_scan_to_points_world(scan, T_world_sensor)</code>","text":"<p>Convert a planar LiDAR scan into 3D points in world coordinates.</p> <p>:param scan: LiDAR measurement in the sensor frame. :param T_world_sensor: Homogeneous transform from sensor to world,     shape <code>(4, 4)</code>. :returns: Array of points of shape <code>(N, 3)</code> in world coordinates.</p> Source code in <code>dsg-jit/dsg_jit/sensors/conversion.py</code> <pre><code>def lidar_scan_to_points_world(\n    scan: LidarMeasurement,\n    T_world_sensor: jnp.ndarray,\n) -&gt; jnp.ndarray:\n    \"\"\"\n    Convert a planar LiDAR scan into 3D points in world coordinates.\n\n    :param scan: LiDAR measurement in the sensor frame.\n    :param T_world_sensor: Homogeneous transform from sensor to world,\n        shape ``(4, 4)``.\n    :returns: Array of points of shape ``(N, 3)`` in world coordinates.\n    \"\"\"\n    pts_s = lidar_scan_to_points_sensor(scan)  # (N, 3)\n    ones = jnp.ones((pts_s.shape[0], 1), dtype=jnp.float32)\n    pts_s_h = jnp.concatenate([pts_s, ones], axis=1)  # (N, 4)\n    pts_w_h = (T_world_sensor @ pts_s_h.T).T  # (N, 4)\n    return pts_w_h[:, :3]\n</code></pre>"},{"location":"api/sensors/#sensors.conversion.lidar_scan_to_voxel_factors","title":"<code>lidar_scan_to_voxel_factors(voxel_ids, points_world, sigma=0.05, factor_type='voxel_point_obs')</code>","text":"<p>Convert a LiDAR point cloud into per-voxel observation factors.</p> <p>This helper assumes that a pre-processing step has already:</p> <ul> <li>Projected the LiDAR ranges into 3D points in world coordinates.</li> <li>Associated each point with a voxel id (e.g. via a voxel grid index).</li> </ul> <p>Given a list of voxel node ids and a matching array of 3D points, this function returns one :class:<code>MeasurementFactor</code> per point.</p> <p>:param voxel_ids: Iterable of voxel node ids, one per point. :type voxel_ids: Sequence[int] :param points_world: Array of 3D points in world coordinates with     shape <code>(N, 3)</code>, where <code>N == len(voxel_ids)</code>. :type points_world: jax.numpy.ndarray :param sigma: Noise level for each point in world units. :type sigma: float :param factor_type: Factor type string used for all voxel-point     factors, typically <code>\"voxel_point_obs\"</code>. :type factor_type: str :return: A list of :class:<code>MeasurementFactor</code> objects, one for each     point/voxel pair. :rtype: list[MeasurementFactor]</p> Source code in <code>dsg-jit/dsg_jit/sensors/conversion.py</code> <pre><code>def lidar_scan_to_voxel_factors(\n    voxel_ids: Sequence[int],\n    points_world: jnp.ndarray,\n    sigma: float = 0.05,\n    factor_type: str = \"voxel_point_obs\",\n) -&gt; List[MeasurementFactor]:\n    \"\"\"\n    Convert a LiDAR point cloud into per-voxel observation factors.\n\n    This helper assumes that a pre-processing step has already:\n\n    * Projected the LiDAR ranges into 3D points in world coordinates.\n    * Associated each point with a voxel id (e.g. via a voxel grid index).\n\n    Given a list of voxel node ids and a matching array of 3D points,\n    this function returns one :class:`MeasurementFactor` per point.\n\n    :param voxel_ids: Iterable of voxel node ids, one per point.\n    :type voxel_ids: Sequence[int]\n    :param points_world: Array of 3D points in world coordinates with\n        shape ``(N, 3)``, where ``N == len(voxel_ids)``.\n    :type points_world: jax.numpy.ndarray\n    :param sigma: Noise level for each point in world units.\n    :type sigma: float\n    :param factor_type: Factor type string used for all voxel-point\n        factors, typically ``\"voxel_point_obs\"``.\n    :type factor_type: str\n    :return: A list of :class:`MeasurementFactor` objects, one for each\n        point/voxel pair.\n    :rtype: list[MeasurementFactor]\n    \"\"\"\n    points_world = jnp.asarray(points_world, dtype=jnp.float32)\n    if points_world.ndim != 2 or points_world.shape[1] != 3:\n        raise ValueError(\n            f\"points_world must have shape (N, 3), got {points_world.shape}\"\n        )\n    if len(voxel_ids) != points_world.shape[0]:\n        raise ValueError(\n            f\"voxel_ids length {len(voxel_ids)} does not match \"\n            f\"points_world.shape[0] {points_world.shape[0]}\"\n        )\n\n    factors: List[MeasurementFactor] = []\n    for vid, pt in zip(voxel_ids, points_world):\n        factors.append(\n            voxel_point_obs_factor(\n                voxel_id=int(vid),\n                point_world=pt,\n                sigma=sigma,\n                factor_type=factor_type,\n            )\n        )\n    return factors\n</code></pre>"},{"location":"api/sensors/#sensors.conversion.measurement_factors_to_graph_factors","title":"<code>measurement_factors_to_graph_factors(meas_factors)</code>","text":"<p>Convert a sequence of :class:<code>MeasurementFactor</code> objects to concrete :class:<code>core.types.Factor</code> instances.</p> <p>Unique factor ids are generated using a simple running index; if you need stable ids, you can post-process the factors or construct them manually instead.</p> <p>:param meas_factors: Iterable of :class:<code>MeasurementFactor</code> objects     returned by the conversion helpers in this module. :type meas_factors: Iterable[MeasurementFactor] :return: A list of :class:<code>Factor</code> instances suitable for adding to     a :class:<code>FactorGraph</code>. :rtype: list[Factor]</p> Source code in <code>dsg-jit/dsg_jit/sensors/conversion.py</code> <pre><code>def measurement_factors_to_graph_factors(\n    meas_factors: Iterable[MeasurementFactor],\n) -&gt; List[Factor]:\n    \"\"\"\n    Convert a sequence of :class:`MeasurementFactor` objects to concrete\n    :class:`core.types.Factor` instances.\n\n    Unique factor ids are generated using a simple running index; if you\n    need stable ids, you can post-process the factors or construct\n    them manually instead.\n\n    :param meas_factors: Iterable of :class:`MeasurementFactor` objects\n        returned by the conversion helpers in this module.\n    :type meas_factors: Iterable[MeasurementFactor]\n    :return: A list of :class:`Factor` instances suitable for adding to\n        a :class:`FactorGraph`.\n    :rtype: list[Factor]\n    \"\"\"\n    graph_factors: List[Factor] = []\n    for idx, mf in enumerate(meas_factors):\n        fid = f\"meas_{idx}\"\n        graph_factors.append(\n            Factor(\n                id=fid,\n                type=mf.factor_type,\n                var_ids=tuple(mf.var_ids),\n                params=dict(mf.params),\n            )\n        )\n    return graph_factors\n</code></pre>"},{"location":"api/sensors/#sensors.conversion.pixel_to_ray_camera","title":"<code>pixel_to_ray_camera(cam, u, v)</code>","text":"<p>Convert a pixel coordinate into a normalized ray in the camera frame.</p> <p>The intrinsics are assumed to follow the usual pinhole model::</p> <pre><code>x = (u - cx) / fx\ny = (v - cy) / fy\nray_cam = [x, y, 1]\nray_cam /= ||ray_cam||\n</code></pre> <p>:param cam: Camera measurement object providing intrinsics. :param u: Pixel x-coordinate (column index). :param v: Pixel y-coordinate (row index). :returns: A unit 3D vector (shape <code>(3,)</code>) in the camera frame.</p> Source code in <code>dsg-jit/dsg_jit/sensors/conversion.py</code> <pre><code>def pixel_to_ray_camera(\n    cam: CameraMeasurement,\n    u: float,\n    v: float,\n) -&gt; jnp.ndarray:\n    \"\"\"\n    Convert a pixel coordinate into a normalized ray in the camera frame.\n\n    The intrinsics are assumed to follow the usual pinhole model::\n\n        x = (u - cx) / fx\n        y = (v - cy) / fy\n        ray_cam = [x, y, 1]\n        ray_cam /= ||ray_cam||\n\n    :param cam: Camera measurement object providing intrinsics.\n    :param u: Pixel x-coordinate (column index).\n    :param v: Pixel y-coordinate (row index).\n    :returns: A unit 3D vector (shape ``(3,)``) in the camera frame.\n    \"\"\"\n    fx = float(cam.intrinsics.fx)\n    fy = float(cam.intrinsics.fy)\n    cx = float(cam.intrinsics.cx)\n    cy = float(cam.intrinsics.cy)\n\n    x = (u - cx) / fx\n    y = (v - cy) / fy\n    ray = jnp.array([x, y, 1.0], dtype=jnp.float32)\n    ray = ray / jnp.linalg.norm(ray)\n    return ray\n</code></pre>"},{"location":"api/sensors/#sensors.conversion.pixels_to_rays_camera","title":"<code>pixels_to_rays_camera(cam, pixels)</code>","text":"<p>Convert a collection of pixel coordinates into rays in the camera frame.</p> <p>:param cam: Camera measurement object providing intrinsics. :param pixels: Iterable of <code>(u, v)</code> pixel coordinates. :returns: Array of unit 3D vectors of shape <code>(N, 3)</code> in the camera frame.</p> Source code in <code>dsg-jit/dsg_jit/sensors/conversion.py</code> <pre><code>def pixels_to_rays_camera(\n    cam: CameraMeasurement,\n    pixels: Iterable[Tuple[float, float]],\n) -&gt; jnp.ndarray:\n    \"\"\"\n    Convert a collection of pixel coordinates into rays in the camera frame.\n\n    :param cam: Camera measurement object providing intrinsics.\n    :param pixels: Iterable of ``(u, v)`` pixel coordinates.\n    :returns: Array of unit 3D vectors of shape ``(N, 3)`` in the camera frame.\n    \"\"\"\n    rays = [pixel_to_ray_camera(cam, u, v) for (u, v) in pixels]\n    return jnp.stack(rays, axis=0)\n</code></pre>"},{"location":"api/sensors/#sensors.conversion.range_1d_to_factor","title":"<code>range_1d_to_factor(pose_id, place_id, distance, sigma=0.05, factor_type='range_1d')</code>","text":"<p>Convert a scalar range measurement (1D) into a factor description.</p> <p>This is the generic bridge used by simple range sensors (e.g. the 1D range DSG experiment), where you have:</p> <pre><code>pose_x - place_x \u2248 distance\n</code></pre> <p>and a residual function of type <code>factor_type</code> that expects a <code>\"measurement\"</code> and optionally a <code>\"sigma\"</code> or <code>\"weight\"</code> in its parameter dictionary.</p> <p>:param pose_id: Node id of the pose variable in the factor graph. :type pose_id: int :param place_id: Node id of the place or landmark variable in the     factor graph. :type place_id: int :param distance: Measured distance between the pose and the place. :type distance: float :param sigma: Measurement noise standard deviation. If your residual     uses <code>weight</code> instead, you can convert this using     <code>1.0 / (sigma ** 2)</code> when creating the factor. :type sigma: float :param factor_type: String key for the residual function. This must     match a factor type registered into the :class:<code>FactorGraph</code>,     for example <code>\"range_1d\"</code>. :type factor_type: str :return: A :class:<code>MeasurementFactor</code> describing the range constraint. :rtype: MeasurementFactor</p> Source code in <code>dsg-jit/dsg_jit/sensors/conversion.py</code> <pre><code>def range_1d_to_factor(\n    pose_id: int,\n    place_id: int,\n    distance: float,\n    sigma: float = 0.05,\n    factor_type: str = \"range_1d\",\n) -&gt; MeasurementFactor:\n    \"\"\"\n    Convert a scalar range measurement (1D) into a factor description.\n\n    This is the generic bridge used by simple range sensors (e.g. the\n    1D range DSG experiment), where you have:\n\n        pose_x - place_x \u2248 distance\n\n    and a residual function of type ``factor_type`` that expects a\n    ``\"measurement\"`` and optionally a ``\"sigma\"`` or ``\"weight\"`` in\n    its parameter dictionary.\n\n    :param pose_id: Node id of the pose variable in the factor graph.\n    :type pose_id: int\n    :param place_id: Node id of the place or landmark variable in the\n        factor graph.\n    :type place_id: int\n    :param distance: Measured distance between the pose and the place.\n    :type distance: float\n    :param sigma: Measurement noise standard deviation. If your residual\n        uses ``weight`` instead, you can convert this using\n        ``1.0 / (sigma ** 2)`` when creating the factor.\n    :type sigma: float\n    :param factor_type: String key for the residual function. This must\n        match a factor type registered into the :class:`FactorGraph`,\n        for example ``\"range_1d\"``.\n    :type factor_type: str\n    :return: A :class:`MeasurementFactor` describing the range constraint.\n    :rtype: MeasurementFactor\n    \"\"\"\n    params: Dict[str, Any] = {\n        \"measurement\": jnp.array([distance], dtype=jnp.float32),\n        \"sigma\": float(sigma),\n    }\n    return MeasurementFactor(\n        factor_type=factor_type,\n        var_ids=(pose_id, place_id),\n        params=params,\n    )\n</code></pre>"},{"location":"api/sensors/#sensors.conversion.range_to_point_sensor","title":"<code>range_to_point_sensor(m)</code>","text":"<p>Convert a range measurement into a 3D point in the sensor frame.</p> <p>:param m: Range measurement with a scalar distance and unit ray direction     in the sensor frame. :returns: A 3D point (shape <code>(3,)</code>) in the sensor frame.</p> Source code in <code>dsg-jit/dsg_jit/sensors/conversion.py</code> <pre><code>def range_to_point_sensor(m: RangeMeasurement) -&gt; jnp.ndarray:\n    \"\"\"\n    Convert a range measurement into a 3D point in the sensor frame.\n\n    :param m: Range measurement with a scalar distance and unit ray direction\n        in the sensor frame.\n    :returns: A 3D point (shape ``(3,)``) in the sensor frame.\n    \"\"\"\n    d = float(m.distance)\n    dir_s = jnp.asarray(m.ray_dir, dtype=jnp.float32)\n    return d * dir_s\n</code></pre>"},{"location":"api/sensors/#sensors.conversion.range_to_point_world","title":"<code>range_to_point_world(m, T_world_sensor)</code>","text":"<p>Convert a range measurement into a 3D point in world coordinates.</p> <p>This assumes you already have the sensor pose <code>T_world_sensor</code> as a homogeneous transform matrix of shape <code>(4, 4)</code>. The point is first constructed in the sensor frame and then transformed into the world.</p> <p>:param m: Range measurement in the sensor frame. :param T_world_sensor: Homogeneous transform from sensor to world,     shape <code>(4, 4)</code>. :returns: A 3D point (shape <code>(3,)</code>) in world coordinates.</p> Source code in <code>dsg-jit/dsg_jit/sensors/conversion.py</code> <pre><code>def range_to_point_world(\n    m: RangeMeasurement,\n    T_world_sensor: jnp.ndarray,\n) -&gt; jnp.ndarray:\n    \"\"\"\n    Convert a range measurement into a 3D point in world coordinates.\n\n    This assumes you already have the sensor pose ``T_world_sensor`` as a\n    homogeneous transform matrix of shape ``(4, 4)``. The point is first\n    constructed in the sensor frame and then transformed into the world.\n\n    :param m: Range measurement in the sensor frame.\n    :param T_world_sensor: Homogeneous transform from sensor to world,\n        shape ``(4, 4)``.\n    :returns: A 3D point (shape ``(3,)``) in world coordinates.\n    \"\"\"\n    p_s = range_to_point_sensor(m)\n    p_s_h = jnp.concatenate([p_s, jnp.array([1.0], dtype=jnp.float32)], axis=0)\n    p_w_h = T_world_sensor @ p_s_h\n    return p_w_h[:3]\n</code></pre>"},{"location":"api/sensors/#sensors.conversion.raw_sample_to_camera_measurement","title":"<code>raw_sample_to_camera_measurement(sample, sensor_id='cam0', T_cam_body=None, seq=None)</code>","text":"<p>Convert a raw camera sample dictionary into a CameraMeasurement.</p> <p>Expected keys in <code>sample</code>:</p> <ul> <li><code>\"t\"</code> (optional): float timestamp. If missing, the current time is used.</li> <li><code>\"frame_id\"</code> (optional): string frame identifier.</li> <li>ONE of the following image-like entries (optional):<ul> <li><code>\"image\"</code>: (H, W) or (H, W, 3) array-like.</li> </ul> </li> <li>Optional directional data (for feature-based SLAM):<ul> <li><code>\"bearings\"</code>: (N, 3) array-like of unit directions.</li> <li><code>\"dirs\"</code>: (N, 3) array-like.</li> <li><code>\"rays\"</code>: (N, 3) array-like.</li> </ul> </li> </ul> <p>Any directional data is stored in the returned measurement's <code>metadata</code> under the corresponding key (e.g. <code>metadata[\"bearings\"]</code>).</p> <p>:param sample:     Raw sample dictionary produced by a sensor stream (e.g. ReadingStream     or FunctionStream) in the experiments. :param sensor_id:     Identifier for this camera (e.g. <code>\"cam0\"</code>). :param T_cam_body:     Optional 4x4 homogeneous transform from body frame to camera frame. :param seq:     Optional sequence index (frame counter).</p> <p>:returns:     A :class:<code>CameraMeasurement</code> containing a :class:<code>CameraFrame</code> plus     any directional data in the <code>metadata</code> field.</p> Source code in <code>dsg-jit/dsg_jit/sensors/conversion.py</code> <pre><code>def raw_sample_to_camera_measurement(\n    sample: Mapping[str, Any],\n    sensor_id: str = \"cam0\",\n    T_cam_body: Optional[np.ndarray] = None,\n    seq: Optional[int] = None,\n) -&gt; CameraMeasurement:\n    \"\"\"\n    Convert a raw camera sample dictionary into a CameraMeasurement.\n\n    Expected keys in ``sample``:\n\n    - ``\"t\"`` (optional): float timestamp. If missing, the current time is used.\n    - ``\"frame_id\"`` (optional): string frame identifier.\n    - ONE of the following image-like entries (optional):\n        * ``\"image\"``: (H, W) or (H, W, 3) array-like.\n    - Optional directional data (for feature-based SLAM):\n        * ``\"bearings\"``: (N, 3) array-like of unit directions.\n        * ``\"dirs\"``: (N, 3) array-like.\n        * ``\"rays\"``: (N, 3) array-like.\n\n    Any directional data is stored in the returned measurement's ``metadata``\n    under the corresponding key (e.g. ``metadata[\"bearings\"]``).\n\n    :param sample:\n        Raw sample dictionary produced by a sensor stream (e.g. ReadingStream\n        or FunctionStream) in the experiments.\n    :param sensor_id:\n        Identifier for this camera (e.g. ``\"cam0\"``).\n    :param T_cam_body:\n        Optional 4x4 homogeneous transform from body frame to camera frame.\n    :param seq:\n        Optional sequence index (frame counter).\n\n    :returns:\n        A :class:`CameraMeasurement` containing a :class:`CameraFrame` plus\n        any directional data in the ``metadata`` field.\n    \"\"\"\n    # Timestamp / frame id\n    t = float(sample.get(\"t\", time.time()))\n    frame_id = sample.get(\"frame_id\", None)\n\n    # Image (optional)\n    if \"image\" in sample:\n        img = np.asarray(sample[\"image\"])\n    else:\n        # If no image is present, create a dummy 1x1 grayscale image.\n        # This lets us still pass a valid CameraFrame downstream.\n        img = np.zeros((1, 1), dtype=np.float32)\n\n    # Decide color space from shape\n    if img.ndim == 3 and img.shape[-1] == 3:\n        color_space = \"rgb\"\n    else:\n        color_space = \"gray\"\n\n    frame = CameraFrame(\n        image=img,\n        timestamp=t,\n        frame_id=frame_id,\n        color_space=color_space,\n    )\n\n    # Collect directional data (bearings, dirs, rays) into metadata\n    metadata: Dict[str, Any] = {}\n\n    for key in (\"bearings\", \"dirs\", \"rays\"):\n        if key in sample:\n            metadata[key] = np.asarray(sample[key])\n\n    # Optionally keep any other extra keys under metadata[\"extra\"]\n    for k, v in sample.items():\n        if k not in (\"t\", \"frame_id\", \"image\", \"bearings\", \"dirs\", \"rays\"):\n            metadata.setdefault(\"extra\", {})[k] = v\n\n    if not metadata:\n        metadata = None  # keep clean if there is nothing to store\n\n    return CameraMeasurement(\n        frame=frame,\n        sensor_id=sensor_id,\n        T_cam_body=T_cam_body,\n        seq=seq,\n        metadata=metadata,\n    )\n</code></pre>"},{"location":"api/sensors/#sensors.conversion.raw_sample_to_imu_measurement","title":"<code>raw_sample_to_imu_measurement(sample)</code>","text":"<p>Convert a raw dict from a stream into an IMUMeasurement.</p> <p>Expected keys in <code>sample</code>:</p> <ul> <li>\"t\": float timestamp (seconds).</li> <li>\"accel\": array-like linear acceleration in the IMU frame.</li> <li>\"gyro\": array-like angular velocity in the IMU frame.</li> <li>\"dt\" (optional): time step in seconds since the previous sample.   If omitted, a default value is used.</li> </ul> <p>:param sample: Raw sample dictionary produced by a sensor stream. :return: An :class:<code>IMUMeasurement</code> instance.</p> Source code in <code>dsg-jit/dsg_jit/sensors/conversion.py</code> <pre><code>def raw_sample_to_imu_measurement(sample: Mapping[str, Any]) -&gt; IMUMeasurement:\n    \"\"\"\n    Convert a raw dict from a stream into an IMUMeasurement.\n\n    Expected keys in ``sample``:\n\n    - \"t\": float timestamp (seconds).\n    - \"accel\": array-like linear acceleration in the IMU frame.\n    - \"gyro\": array-like angular velocity in the IMU frame.\n    - \"dt\" (optional): time step in seconds since the previous sample.\n      If omitted, a default value is used.\n\n    :param sample: Raw sample dictionary produced by a sensor stream.\n    :return: An :class:`IMUMeasurement` instance.\n    \"\"\"\n    t = float(sample.get(\"t\", 0.0))\n    accel = jnp.array(sample[\"accel\"], dtype=jnp.float32)\n    gyro = jnp.array(sample[\"gyro\"], dtype=jnp.float32)\n\n    # Use provided dt if available, otherwise fall back to a reasonable default\n    dt = float(sample.get(\"dt\", 0.1))\n\n    return IMUMeasurement(\n        timestamp=t,\n        accel=accel,\n        gyro=gyro,\n        dt=dt,\n    )\n</code></pre>"},{"location":"api/sensors/#sensors.conversion.raw_sample_to_lidar_measurement","title":"<code>raw_sample_to_lidar_measurement(sample)</code>","text":"<p>Convert a raw LiDAR sample dictionary into a :class:<code>LidarMeasurement</code>.</p> <p>Expected keys in <code>sample</code>:</p> <ul> <li><code>\"ranges\"</code>: 1D array-like of LiDAR ranges. (required)</li> <li><code>\"angles\"</code>: 1D array-like of bearing angles (radians), same length as <code>ranges</code>. (optional)</li> <li><code>\"directions\"</code>: (N, 3) array-like of direction vectors. (optional)</li> <li><code>\"t\"</code> (optional): float timestamp.</li> <li><code>\"frame_id\"</code> (optional): string frame identifier.</li> </ul> <p>This is consistent with the rest of the LiDAR utilities in this module, which assume a planar LiDAR described by <code>ranges</code> and <code>angles</code>.</p> <p>:param sample: Raw sample dictionary produced by a sensor stream. :returns: A :class:<code>LidarMeasurement</code> instance. :raises KeyError: If required keys are missing from the sample.</p> Source code in <code>dsg-jit/dsg_jit/sensors/conversion.py</code> <pre><code>def raw_sample_to_lidar_measurement(sample: Mapping[str, Any]) -&gt; LidarMeasurement:\n    \"\"\"Convert a raw LiDAR sample dictionary into a :class:`LidarMeasurement`.\n\n    Expected keys in ``sample``:\n\n    - ``\"ranges\"``: 1D array-like of LiDAR ranges. (required)\n    - ``\"angles\"``: 1D array-like of bearing angles (radians), same length as ``ranges``. (optional)\n    - ``\"directions\"``: (N, 3) array-like of direction vectors. (optional)\n    - ``\"t\"`` (optional): float timestamp.\n    - ``\"frame_id\"`` (optional): string frame identifier.\n\n    This is consistent with the rest of the LiDAR utilities in this module,\n    which assume a planar LiDAR described by ``ranges`` and ``angles``.\n\n    :param sample: Raw sample dictionary produced by a sensor stream.\n    :returns: A :class:`LidarMeasurement` instance.\n    :raises KeyError: If required keys are missing from the sample.\n    \"\"\"\n    if \"ranges\" not in sample:\n        raise KeyError(\"raw_sample_to_lidar_measurement expected 'ranges' in sample\")\n\n    ranges = jnp.array(sample[\"ranges\"], dtype=jnp.float32)\n\n    # Determine directions (dirs) if present, else compute from angles if present, else None\n    dirs = None\n    if \"directions\" in sample:\n        dirs = jnp.array(sample[\"directions\"], dtype=jnp.float32)\n    elif \"angles\" in sample:\n        angles = jnp.array(sample[\"angles\"], dtype=jnp.float32)\n        # Planar lidar: directions in the x-y plane\n        dirs = jnp.stack(\n            [jnp.cos(angles), jnp.sin(angles), jnp.zeros_like(angles)], axis=-1\n        )\n    else:\n        dirs = None\n\n    return LidarMeasurement(\n        ranges=ranges,\n        directions=dirs,\n        t=sample.get(\"t\", None),\n        frame_id=sample.get(\"frame_id\", \"lidar\"),\n        metadata=None,\n    )\n</code></pre>"},{"location":"api/sensors/#sensors.conversion.voxel_point_obs_factor","title":"<code>voxel_point_obs_factor(voxel_id, point_world, sigma=0.05, factor_type='voxel_point_obs')</code>","text":"<p>Convert a single 3D point observation into a voxel-point factor.</p> <p>This is intended for mapping-style sensors (LiDAR, depth cameras, RGB-D, stereo) where you receive one or more 3D points in world coordinates and want to attach them to a voxel cell center.</p> <p>:param voxel_id: Node id of the voxel variable (<code>voxel_cell</code>)     in the factor graph. :type voxel_id: int :param point_world: Observed 3D point in world coordinates with shape     <code>(3,)</code>. :type point_world: jax.numpy.ndarray :param sigma: Noise level for this observation in world units     (meters, etc.). :type sigma: float :param factor_type: Factor type string (e.g. <code>\"voxel_point_obs\"</code>)     corresponding to the voxel-point residual used in your     measurement model. :type factor_type: str :return: A :class:<code>MeasurementFactor</code> describing the voxel-point     observation. :rtype: MeasurementFactor</p> Source code in <code>dsg-jit/dsg_jit/sensors/conversion.py</code> <pre><code>def voxel_point_obs_factor(\n    voxel_id: int,\n    point_world: jnp.ndarray,\n    sigma: float = 0.05,\n    factor_type: str = \"voxel_point_obs\",\n) -&gt; MeasurementFactor:\n    \"\"\"\n    Convert a single 3D point observation into a voxel-point factor.\n\n    This is intended for mapping-style sensors (LiDAR, depth cameras,\n    RGB-D, stereo) where you receive one or more 3D points in world\n    coordinates and want to attach them to a voxel cell center.\n\n    :param voxel_id: Node id of the voxel variable (``voxel_cell``)\n        in the factor graph.\n    :type voxel_id: int\n    :param point_world: Observed 3D point in world coordinates with shape\n        ``(3,)``.\n    :type point_world: jax.numpy.ndarray\n    :param sigma: Noise level for this observation in world units\n        (meters, etc.).\n    :type sigma: float\n    :param factor_type: Factor type string (e.g. ``\"voxel_point_obs\"``)\n        corresponding to the voxel-point residual used in your\n        measurement model.\n    :type factor_type: str\n    :return: A :class:`MeasurementFactor` describing the voxel-point\n        observation.\n    :rtype: MeasurementFactor\n    \"\"\"\n    point_world = jnp.asarray(point_world, dtype=jnp.float32).reshape(3,)\n    params: Dict[str, Any] = {\n        \"point_world\": point_world,\n        \"sigma\": float(sigma),\n    }\n    return MeasurementFactor(\n        factor_type=factor_type,\n        var_ids=(voxel_id,),\n        params=params,\n    )\n</code></pre>"},{"location":"api/sensors/#sensorsfusion","title":"<code>sensors.fusion</code>","text":"<p>Sensor fusion utilities for DSG-JIT.</p> <p>This module provides a small, opinionated fusion core that sits between raw sensor streams (e.g. LiDAR, cameras, IMUs) and the rest of the DSG-JIT world/scene-graph stack.</p> <p>The goals of this layer are:</p> <ul> <li>Provide a common abstraction to register named sensors and pull data   from synchronous streams.</li> <li>Convert raw samples into strongly-typed measurement objects defined in   :mod:<code>sensors.camera</code>, :mod:<code>sensors.lidar</code>, and :mod:<code>sensors.imu</code>.</li> <li>Dispatch the resulting measurements to user-provided callbacks that   can update a :class:<code>world.model.WorldModel</code> or   :class:<code>world.dynamic_scene_graph.DynamicSceneGraph</code>.</li> </ul> <p>This is intentionally lightweight:</p> <ul> <li>It does not assume any particular factor-graph structure.</li> <li>It does not run its own background threads or event loops.</li> <li>It is designed so that experiments can start simple (single-threaded   polling) while leaving room to grow into a more complex async or   multi-rate fusion system later on.</li> </ul> <p>Typical usage from an experiment::</p> <pre><code>from sensors.streams import ReadingStream\nfrom sensors.camera import CameraMeasurement\nfrom sensors.lidar import LidarMeasurement\nfrom sensors.fusion import SensorFusionManager\n\nfusion = SensorFusionManager()\n\n# 1) Register a camera and a lidar stream\nfusion.register_sensor(\n    name=\"cam0\",\n    modality=\"camera\",\n    stream=ReadingStream(camera_read_fn),\n)\nfusion.register_sensor(\n    name=\"lidar0\",\n    modality=\"lidar\",\n    stream=ReadingStream(lidar_read_fn),\n)\n\n# 2) Connect fusion to the world model via a callback\ndef on_measurement(meas):\n    if isinstance(meas, CameraMeasurement):\n        # add a bearing / reprojection factor, etc.\n        ...\n    elif isinstance(meas, LidarMeasurement):\n        # add range factors or occupancy updates\n        ...\n\nfusion.register_callback(on_measurement)\n\n# 3) Poll sensors in your main loop\nfor step in range(100):\n    fusion.poll_once()\n    # run optimization, render, etc.\n</code></pre> <p>In the future we can add:</p> <ul> <li>Async helpers that drive :class:<code>sensors.streams.AReadingStream</code>.</li> <li>Tighter integration with the dynamic scene graph (e.g. per-agent queues).</li> <li>Higher-level policies (e.g. downsampling, time sync, etc.).</li> </ul>"},{"location":"api/sensors/#sensors.fusion.FusedPoseEstimate","title":"<code>FusedPoseEstimate(t, pose_se3, covariance=None, source_counts=dict())</code>  <code>dataclass</code>","text":"<p>Fused SE(3) pose estimate produced by SensorFusionManager.</p> <p>:param t: Time index (discrete step or timestamp) associated with this     estimate. :param pose_se3: 6D se(3) pose vector in world coordinates, typically     <code>(tx, ty, tz, rx, ry, rz)</code>. :param covariance: Optional 6x6 covariance matrix for the fused pose. :param source_counts: Optional dictionary tracking how many measurements     contributed from each sensor type (e.g. <code>{\"imu\": 10, \"lidar\": 2}</code>).</p>"},{"location":"api/sensors/#sensors.fusion.RegisteredSensor","title":"<code>RegisteredSensor(name, modality, stream, converter)</code>  <code>dataclass</code>","text":"<p>Bookkeeping structure for a registered sensor.</p> <p>:param name: Logical name of the sensor (e.g. <code>\"lidar0\"</code>). :param modality: String describing the modality, e.g. <code>\"camera\"</code>,     <code>\"lidar\"</code>, or <code>\"imu\"</code>. This is used to choose a default     converter when one is not provided. :param stream: Underlying sensor stream used to pull raw samples. :param converter: Function that maps a raw sample from <code>stream</code> to     a :class:<code>~sensors.base.BaseMeasurement</code> instance.</p>"},{"location":"api/sensors/#sensors.fusion.SensorFusionManager","title":"<code>SensorFusionManager(default_callbacks=None, world_model=None, auto_register_world_callbacks=True)</code>","text":"<p>Central registry and dispatcher for sensor measurements.</p> <p>The fusion manager is intentionally minimal: it owns no threads and does not know about factor graphs or optimization. It simply:</p> <ul> <li>Keeps track of registered sensors.</li> <li>Polls synchronous streams on demand.</li> <li>Converts raw samples to measurement objects.</li> <li>Broadcasts those measurements to user callbacks.</li> </ul> <p>Experiments are free to use this in a tight, single-threaded loop, or to build more advanced async / multi-rate infrastructure on top.</p> <p>:param default_callbacks: Optional iterable of callbacks to register     at construction time. Each callback will be called as     <code>callback(measurement)</code> whenever a new     :class:<code>~sensors.base.BaseMeasurement</code> is produced.</p> <p>Create a new fusion manager.</p> <p>:param default_callbacks: Optional iterable of callbacks to register     immediately. Each callback will be invoked as <code>cb(measurement)</code>     for every measurement produced by :meth:<code>poll_once</code> or     :meth:<code>push_measurement</code>. :param world_model: Optional :class:<code>world.model.WorldModel</code> instance     to be associated with this fusion manager. If provided and     <code>auto_register_world_callbacks</code> is <code>True</code>, the manager will     automatically register per-modality callbacks that forward     measurements into the world model. :param auto_register_world_callbacks: If <code>True</code> and <code>world_model</code>     is not <code>None</code>, register default world-model callbacks for     camera, LiDAR, and IMU measurements (when the corresponding     handler methods exist on the world model).</p> Source code in <code>dsg-jit/dsg_jit/sensors/fusion.py</code> <pre><code>def __init__(\n    self,\n    default_callbacks: Optional[Iterable[Callable[[BaseMeasurement], None]]] = None,\n    world_model: Optional[\"WorldModel\"] = None,\n    auto_register_world_callbacks: bool = True,\n) -&gt; None:\n    \"\"\"Create a new fusion manager.\n\n    :param default_callbacks: Optional iterable of callbacks to register\n        immediately. Each callback will be invoked as ``cb(measurement)``\n        for every measurement produced by :meth:`poll_once` or\n        :meth:`push_measurement`.\n    :param world_model: Optional :class:`world.model.WorldModel` instance\n        to be associated with this fusion manager. If provided and\n        ``auto_register_world_callbacks`` is ``True``, the manager will\n        automatically register per-modality callbacks that forward\n        measurements into the world model.\n    :param auto_register_world_callbacks: If ``True`` and ``world_model``\n        is not ``None``, register default world-model callbacks for\n        camera, LiDAR, and IMU measurements (when the corresponding\n        handler methods exist on the world model).\n    \"\"\"\n\n    self._sensors: Dict[str, RegisteredSensor] = {}\n    self._callbacks: List[Callable[[BaseMeasurement], None]] = []\n    self._fused_history: List[\n        tuple[float | int, jnp.ndarray, Optional[jnp.ndarray], Dict[str, int]]\n    ] = []\n    self._world_model: Optional[\"WorldModel\"] = world_model\n\n    if default_callbacks is not None:\n        for cb in default_callbacks:\n            self.register_callback(cb)\n\n    if self._world_model is not None and auto_register_world_callbacks:\n        # Automatically hook camera / LiDAR / IMU measurements into the\n        # world model using any available handler methods.\n        self.attach_world_model(self._world_model, register_default_callbacks=True)\n</code></pre>"},{"location":"api/sensors/#sensors.fusion.SensorFusionManager.attach_world_model","title":"<code>attach_world_model(world_model, register_default_callbacks=True)</code>","text":"<p>Attach a :class:<code>world.model.WorldModel</code> to this fusion manager.</p> <p>When a world model is attached and <code>register_default_callbacks</code> is <code>True</code>, the manager will install per-modality callbacks that route camera, LiDAR, and IMU measurements into the world model using any available handler methods.</p> <p>Expected handler names on <code>world_model</code> are, for example:</p> <ul> <li><code>apply_camera_measurement</code> or <code>add_camera_measurement</code></li> <li><code>apply_lidar_measurement</code> or <code>add_lidar_measurement</code></li> <li><code>apply_imu_measurement</code> or <code>add_imu_measurement</code></li> </ul> <p>Only handlers that actually exist and are callable will be used.</p> <p>:param world_model: World model instance to associate. :param register_default_callbacks: If <code>True</code>, automatically     register default callbacks that forward measurements into the     world model.</p> Source code in <code>dsg-jit/dsg_jit/sensors/fusion.py</code> <pre><code>def attach_world_model(\n    self,\n    world_model: \"WorldModel\",\n    register_default_callbacks: bool = True,\n) -&gt; None:\n    \"\"\"Attach a :class:`world.model.WorldModel` to this fusion manager.\n\n    When a world model is attached and ``register_default_callbacks`` is\n    ``True``, the manager will install per-modality callbacks that route\n    camera, LiDAR, and IMU measurements into the world model using any\n    available handler methods.\n\n    Expected handler names on ``world_model`` are, for example:\n\n    * ``apply_camera_measurement`` or ``add_camera_measurement``\n    * ``apply_lidar_measurement`` or ``add_lidar_measurement``\n    * ``apply_imu_measurement`` or ``add_imu_measurement``\n\n    Only handlers that actually exist and are callable will be used.\n\n    :param world_model: World model instance to associate.\n    :param register_default_callbacks: If ``True``, automatically\n        register default callbacks that forward measurements into the\n        world model.\n    \"\"\"\n\n    self._world_model = world_model\n    if register_default_callbacks:\n        self._register_world_callbacks()\n</code></pre>"},{"location":"api/sensors/#sensors.fusion.SensorFusionManager.get_latest_pose","title":"<code>get_latest_pose()</code>","text":"<p>Return the most recent fused SE(3) pose estimate, if available.</p> <p>This is a thin convenience wrapper used by integration layers (e.g. world models or dynamic scene graphs) to pull a single, canonical pose update out of the fusion buffer.</p> <p>:returns: A :class:<code>FusedPoseEstimate</code> instance if any fused result     has been produced, or <code>None</code> if the manager has not yet     emitted a pose.</p> Source code in <code>dsg-jit/dsg_jit/sensors/fusion.py</code> <pre><code>def get_latest_pose(self) -&gt; Optional[FusedPoseEstimate]:\n    \"\"\"\n    Return the most recent fused SE(3) pose estimate, if available.\n\n    This is a thin convenience wrapper used by integration layers\n    (e.g. world models or dynamic scene graphs) to pull a single,\n    canonical pose update out of the fusion buffer.\n\n    :returns: A :class:`FusedPoseEstimate` instance if any fused result\n        has been produced, or ``None`` if the manager has not yet\n        emitted a pose.\n    \"\"\"\n    if not self._fused_history:\n        return None\n\n    # Assuming you internally store a list of (t, pose, cov, meta).\n    t, pose_se3, cov, source_counts = self._fused_history[-1]\n\n    return FusedPoseEstimate(\n        t=t,\n        pose_se3=pose_se3,\n        covariance=cov,\n        source_counts=source_counts,\n    )\n</code></pre>"},{"location":"api/sensors/#sensors.fusion.SensorFusionManager.poll_once","title":"<code>poll_once()</code>","text":"<p>Poll all registered synchronous streams exactly once.</p> <p>For each sensor whose stream is an instance of :class:<code>~sensors.streams.ReadingStream</code>, this method will:</p> <ol> <li>Call <code>stream.read()</code> to obtain a raw sample.</li> <li>If a non-<code>None</code> sample is returned, convert it to a    measurement via the registered converter.</li> <li>Dispatch the measurement to all registered callbacks.</li> </ol> <p>Asynchronous streams are not handled here; they can be consumed separately using their own <code>async for</code> loops.</p> <p>:return: The total number of measurements produced and     dispatched during this call.</p> Source code in <code>dsg-jit/dsg_jit/sensors/fusion.py</code> <pre><code>def poll_once(self) -&gt; int:\n    \"\"\"Poll all registered *synchronous* streams exactly once.\n\n    For each sensor whose stream is an instance of\n    :class:`~sensors.streams.ReadingStream`, this method will:\n\n    1. Call ``stream.read()`` to obtain a raw sample.\n    2. If a non-``None`` sample is returned, convert it to a\n       measurement via the registered converter.\n    3. Dispatch the measurement to all registered callbacks.\n\n    Asynchronous streams are not handled here; they can be consumed\n    separately using their own ``async for`` loops.\n\n    :return: The total number of measurements produced and\n        dispatched during this call.\n    \"\"\"\n\n    count = 0\n    for rs in self._sensors.values():\n        if not isinstance(rs.stream, ReadingStream):\n            # Async streams are handled outside of this helper.\n            continue\n\n        sample = rs.stream.read()\n        if sample is None:\n            continue\n\n        meas = rs.converter(sample)\n        self._dispatch(meas)\n        count += 1\n\n    return count\n</code></pre>"},{"location":"api/sensors/#sensors.fusion.SensorFusionManager.push_measurement","title":"<code>push_measurement(measurement)</code>","text":"<p>Inject a pre-constructed measurement into the fusion pipeline.</p> <p>This is useful when the experiment already builds measurement objects directly (e.g. from a simulator) and only wants to reuse the callback dispatch mechanism.</p> <p>:param measurement: Measurement instance to dispatch to all     registered callbacks.</p> Source code in <code>dsg-jit/dsg_jit/sensors/fusion.py</code> <pre><code>def push_measurement(self, measurement: BaseMeasurement) -&gt; None:\n    \"\"\"Inject a pre-constructed measurement into the fusion pipeline.\n\n    This is useful when the experiment already builds measurement\n    objects directly (e.g. from a simulator) and only wants to reuse\n    the callback dispatch mechanism.\n\n    :param measurement: Measurement instance to dispatch to all\n        registered callbacks.\n    \"\"\"\n\n    self._dispatch(measurement)\n</code></pre>"},{"location":"api/sensors/#sensors.fusion.SensorFusionManager.record_fused_pose","title":"<code>record_fused_pose(t, pose_se3, covariance=None, source_counts=None)</code>","text":"<p>Append a fused SE(3) pose estimate to the internal history buffer.</p> <p>This does not perform any fusion by itself; instead it allows an external estimator (e.g. an EKF or factor-graph solver) to publish its current best pose into the fusion manager so that callers can retrieve it via :meth:<code>get_latest_pose</code>.</p> <p>:param t: Time index or timestamp associated with the estimate. :param pose_se3: 6D se(3) pose vector in world coordinates. :param covariance: Optional 6x6 covariance matrix for the estimate. :param source_counts: Optional dictionary describing how many     measurements from each sensor type contributed to this pose.</p> Source code in <code>dsg-jit/dsg_jit/sensors/fusion.py</code> <pre><code>def record_fused_pose(\n    self,\n    t: float | int,\n    pose_se3: jnp.ndarray,\n    covariance: Optional[jnp.ndarray] = None,\n    source_counts: Optional[Dict[str, int]] = None,\n) -&gt; None:\n    \"\"\"\n    Append a fused SE(3) pose estimate to the internal history buffer.\n\n    This does not perform any fusion by itself; instead it allows an\n    external estimator (e.g. an EKF or factor-graph solver) to publish\n    its current best pose into the fusion manager so that callers can\n    retrieve it via :meth:`get_latest_pose`.\n\n    :param t: Time index or timestamp associated with the estimate.\n    :param pose_se3: 6D se(3) pose vector in world coordinates.\n    :param covariance: Optional 6x6 covariance matrix for the estimate.\n    :param source_counts: Optional dictionary describing how many\n        measurements from each sensor type contributed to this pose.\n    \"\"\"\n    if source_counts is None:\n        source_counts = {}\n    self._fused_history.append((t, pose_se3, covariance, source_counts))\n</code></pre>"},{"location":"api/sensors/#sensors.fusion.SensorFusionManager.register_callback","title":"<code>register_callback(callback)</code>","text":"<p>Register a callback to receive all fused measurements.</p> <p>:param callback: Function that accepts a     :class:<code>~sensors.base.BaseMeasurement</code> instance. It will be     called for every measurement produced by     :meth:<code>poll_once</code> or :meth:<code>push_measurement</code>.</p> Source code in <code>dsg-jit/dsg_jit/sensors/fusion.py</code> <pre><code>def register_callback(self, callback: Callable[[BaseMeasurement], None]) -&gt; None:\n    \"\"\"Register a callback to receive all fused measurements.\n\n    :param callback: Function that accepts a\n        :class:`~sensors.base.BaseMeasurement` instance. It will be\n        called for *every* measurement produced by\n        :meth:`poll_once` or :meth:`push_measurement`.\n    \"\"\"\n\n    self._callbacks.append(callback)\n</code></pre>"},{"location":"api/sensors/#sensors.fusion.SensorFusionManager.register_sensor","title":"<code>register_sensor(name, modality, stream, converter=None)</code>","text":"<p>Register a new sensor with the fusion manager.</p> <p>If <code>converter</code> is not provided, a default converter will be chosen based on <code>modality</code>.</p> <p>:param name: Logical sensor name, e.g. <code>\"cam0\"</code> or <code>\"lidar_front\"</code>. :param modality: Modality string (<code>\"camera\"</code>, <code>\"lidar\"</code>,     <code>\"imu\"</code>, or a custom value). Custom values must provide an     explicit <code>converter</code>. :param stream: Sensor stream object used to read raw samples. :param converter: Optional function that converts raw samples from     <code>stream</code> into measurement objects.</p> <p>:raises ValueError: If a sensor with the same name is already     registered, or if no default converter exists for the given     modality and no explicit converter is provided.</p> Source code in <code>dsg-jit/dsg_jit/sensors/fusion.py</code> <pre><code>def register_sensor(\n    self,\n    name: str,\n    modality: str,\n    stream: BaseSensorStream,\n    converter: Optional[Callable[[Any], BaseMeasurement]] = None,\n) -&gt; None:\n    \"\"\"Register a new sensor with the fusion manager.\n\n    If ``converter`` is not provided, a default converter will be\n    chosen based on ``modality``.\n\n    :param name: Logical sensor name, e.g. ``\"cam0\"`` or ``\"lidar_front\"``.\n    :param modality: Modality string (``\"camera\"``, ``\"lidar\"``,\n        ``\"imu\"``, or a custom value). Custom values must provide an\n        explicit ``converter``.\n    :param stream: Sensor stream object used to read raw samples.\n    :param converter: Optional function that converts raw samples from\n        ``stream`` into measurement objects.\n\n    :raises ValueError: If a sensor with the same name is already\n        registered, or if no default converter exists for the given\n        modality and no explicit converter is provided.\n    \"\"\"\n\n    if name in self._sensors:\n        raise ValueError(f\"Sensor '{name}' is already registered\")\n\n    if converter is None:\n        converter = self._infer_default_converter(modality)\n\n    self._sensors[name] = RegisteredSensor(\n        name=name,\n        modality=modality,\n        stream=stream,\n        converter=converter,\n    )\n</code></pre>"},{"location":"api/sensors/#sensorsimu","title":"<code>sensors.imu</code>","text":"<p>Inertial measurement unit (IMU) abstractions and simple integration utilities.</p> <p>This module provides a small set of IMU-related types and helpers that make it easy to wire IMU data into DSG-JIT experiments and factor graphs. The focus is on structured measurements and simple integration, rather than on a full production-grade inertial navigation system.</p> <p>The module typically exposes:</p> <ul> <li> <p><code>IMUMeasurement</code>:       A lightweight container for a single IMU sample, including body-frame       linear acceleration, angular velocity, and an associated <code>dt</code> (time       delta). A timestamp can also be stored for logging or alignment with       other sensors.</p> </li> <li> <p><code>IMUSensor</code>:       A thin wrapper around a user-defined sampling function. The sampling       function returns <code>IMUMeasurement</code> instances, and the wrapper       provides:         - A <code>read()</code> method for synchronous polling.         - An iterator interface for use in simple loops.         - Compatibility with the generic sensor streaming helpers.</p> </li> <li> <p><code>integrate_imu_naive</code>:       A toy integrator that demonstrates how to accumulate IMU measurements       into a position and velocity estimate. It assumes that:         - Acceleration is already expressed in the world frame, and         - Gravity has been compensated externally.       This function is intended for didactic experiments and not as a       replacement for a full IMU preintegration pipeline.</p> </li> </ul> <p>Usage patterns:</p> <ul> <li>Wrap any IMU source (hardware driver, simulator, dataset) with an     <code>IMUSensor</code> so that you always work with <code>IMUMeasurement</code> objects.</li> <li>For demonstration or unit tests, use <code>integrate_imu_naive</code> to produce     rough pose/velocity estimates and then inject those as odometry factors     into a factor graph.</li> <li>For more advanced use cases, replace the naive integrator with a     preintegration module, but keep the same <code>IMUMeasurement</code> and     <code>IMUSensor</code> interfaces so the rest of the system remains unchanged.</li> </ul> <p>The design goal is to make IMU handling:</p> <ul> <li>Explicit and transparent (no hidden global state).</li> <li>Composable with other sensors (cameras, range sensors, etc.).</li> <li>Easy to plug into the existing DSG-JIT world model and optimization     stack without requiring changes to core solvers.</li> </ul>"},{"location":"api/sensors/#sensors.imu.IMUMeasurement","title":"<code>IMUMeasurement(accel, gyro, dt, timestamp=None)</code>  <code>dataclass</code>","text":"<p>Single IMU sample consisting of specific force and angular velocity.</p> <p>This is a lightweight container for raw IMU readings that can be produced by hardware drivers, simulators, or log readers and then consumed by the factor-graph/DSG layers.</p> <p>The convention assumed here is:</p> <ul> <li><code>accel</code> is specific force in the IMU body frame, in <code>m/s^2</code>.</li> <li><code>gyro</code> is angular velocity in the IMU body frame, in <code>rad/s</code>.</li> <li><code>dt</code> is the time delta since the previous sample, in seconds.</li> <li><code>timestamp</code> is an optional absolute time in seconds.</li> </ul> <p>:param accel: Linear acceleration in the IMU/body frame, shape <code>(3,)</code>. :param gyro: Angular velocity in the IMU/body frame, shape <code>(3,)</code>. :param dt: Time delta since the previous sample, in seconds. :param timestamp: Optional absolute timestamp in seconds.</p>"},{"location":"api/sensors/#sensors.imu.IMUMeasurement.as_numpy","title":"<code>as_numpy()</code>","text":"<p>Return the acceleration and gyro as NumPy arrays.</p> <p>This is a small convenience helper for users who want to interoperate with NumPy-based tooling. If NumPy is not available, a :class:<code>RuntimeError</code> is raised.</p> <p>:return: Tuple <code>(accel_np, gyro_np)</code> as NumPy arrays. :raises RuntimeError: If NumPy is not installed or import failed.</p> Source code in <code>dsg-jit/dsg_jit/sensors/imu.py</code> <pre><code>def as_numpy(self) -&gt; tuple[\"np.ndarray\", \"np.ndarray\"]:  # type: ignore[name-defined]\n    \"\"\"Return the acceleration and gyro as NumPy arrays.\n\n    This is a small convenience helper for users who want to interoperate\n    with NumPy-based tooling. If NumPy is not available, a :class:`RuntimeError`\n    is raised.\n\n    :return: Tuple ``(accel_np, gyro_np)`` as NumPy arrays.\n    :raises RuntimeError: If NumPy is not installed or import failed.\n    \"\"\"\n\n    if np is None:  # type: ignore[truthy-function]\n        raise RuntimeError(\"NumPy is not available in this environment.\")\n    return np.asarray(self.accel), np.asarray(self.gyro)\n</code></pre>"},{"location":"api/sensors/#sensors.imu.IMUSampleFn","title":"<code>IMUSampleFn</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for callables that produce :class:<code>IMUMeasurement</code> samples.</p> <p>This is primarily used to type-annotate IMU sensor wrappers.</p> <p>:return: A new :class:<code>IMUMeasurement</code> instance.</p>"},{"location":"api/sensors/#sensors.imu.IMUSensor","title":"<code>IMUSensor(name, sample_fn)</code>","text":"<p>               Bases: <code>BaseSensor</code></p> <p>Generic IMU sensor wrapper.</p> <p>This class adapts any callable that returns :class:<code>IMUMeasurement</code> into the common sensor interface used by DSG-JIT. It is intentionally minimal: it does not attempt to manage threads, buffering, or synchronization\u2014those concerns are handled by the sensor stream utilities in :mod:<code>sensors.streams</code>.</p> <p>:param name: Human-readable sensor name. :param sample_fn: Callable producing a single :class:<code>IMUMeasurement</code> per call.</p> Source code in <code>dsg-jit/dsg_jit/sensors/imu.py</code> <pre><code>def __init__(self, name: str, sample_fn: IMUSampleFn) -&gt; None:\n    # ``BaseSensor`` may or may not define an ``__init__``; call it if present.\n    if hasattr(super(), \"__init__\"):\n        try:\n            super().__init__(name=name)  # type: ignore[call-arg]\n        except TypeError:\n            # Fallback if BaseSensor has a different signature.\n            super().__init__()  # type: ignore[misc]\n\n    self.name: str = name\n    self._sample_fn: IMUSampleFn = sample_fn\n</code></pre>"},{"location":"api/sensors/#sensors.imu.IMUSensor.__iter__","title":"<code>__iter__()</code>","text":"<p>Create an iterator over IMU samples.</p> <p>This is primarily useful when coupling the sensor with an asynchronous or synchronous sensor stream helper that consumes an iterator.</p> <p>:return: Infinite iterator yielding :class:<code>IMUMeasurement</code> objects.</p> Source code in <code>dsg-jit/dsg_jit/sensors/imu.py</code> <pre><code>def __iter__(self) -&gt; Iterable[IMUMeasurement]:\n    \"\"\"Create an iterator over IMU samples.\n\n    This is primarily useful when coupling the sensor with an asynchronous\n    or synchronous sensor stream helper that consumes an iterator.\n\n    :return: Infinite iterator yielding :class:`IMUMeasurement` objects.\n    \"\"\"\n\n    while True:\n        yield self.read()\n</code></pre>"},{"location":"api/sensors/#sensors.imu.IMUSensor.read","title":"<code>read()</code>","text":"<p>Read a single IMU measurement.</p> <p>This will typically perform a blocking read from a hardware device, a simulator, or a log file, depending on how <code>sample_fn</code> is implemented.</p> <p>:return: The next :class:<code>IMUMeasurement</code> sample.</p> Source code in <code>dsg-jit/dsg_jit/sensors/imu.py</code> <pre><code>def read(self) -&gt; IMUMeasurement:\n    \"\"\"Read a single IMU measurement.\n\n    This will typically perform a blocking read from a hardware device, a\n    simulator, or a log file, depending on how ``sample_fn`` is implemented.\n\n    :return: The next :class:`IMUMeasurement` sample.\n    \"\"\"\n\n    return self._sample_fn()\n</code></pre>"},{"location":"api/sensors/#sensors.imu.integrate_imu_naive","title":"<code>integrate_imu_naive(measurements, v0=None, p0=None)</code>","text":"<p>Naively integrate IMU measurements to update position and velocity.</p> <p>This helper performs a very simple, orientation-agnostic integration of a sequence of IMU samples. It assumes that the acceleration vectors are already expressed in the world frame and that gravity has been compensated for. As such, it is not a replacement for proper IMU preintegration, but it is convenient for toy 1D/3D experiments and testing the data flow from sensors into the optimizer.</p> <p>The integration scheme is:</p> <p>.. math::</p> <pre><code>v_{k+1} &amp;= v_k + a_k \\delta t_k\\\np_{k+1} &amp;= p_k + v_{k+1} \\delta t_k\\\n</code></pre> <p>:param measurements: Iterable of :class:<code>IMUMeasurement</code> objects, in time order. :param v0: Optional initial velocity, shape <code>(3,)</code>. Defaults to zeros. :param p0: Optional initial position, shape <code>(3,)</code>. Defaults to zeros. :return: Tuple <code>(p, v)</code> with the final position and velocity.</p> Source code in <code>dsg-jit/dsg_jit/sensors/imu.py</code> <pre><code>def integrate_imu_naive(\n    measurements: Iterable[IMUMeasurement],\n    v0: Optional[jnp.ndarray] = None,\n    p0: Optional[jnp.ndarray] = None,\n) -&gt; tuple[jnp.ndarray, jnp.ndarray]:\n    \"\"\"Naively integrate IMU measurements to update position and velocity.\n\n    This helper performs a very simple, orientation-agnostic integration of a\n    sequence of IMU samples. It assumes that the acceleration vectors are\n    already expressed in the world frame and that gravity has been compensated\n    for. As such, **it is not a replacement for proper IMU preintegration**, but\n    it is convenient for toy 1D/3D experiments and testing the data flow from\n    sensors into the optimizer.\n\n    The integration scheme is:\n\n    .. math::\n\n        v_{k+1} &amp;= v_k + a_k \\\\delta t_k\\\\\n        p_{k+1} &amp;= p_k + v_{k+1} \\\\delta t_k\\\\\n\n    :param measurements: Iterable of :class:`IMUMeasurement` objects, in time order.\n    :param v0: Optional initial velocity, shape ``(3,)``. Defaults to zeros.\n    :param p0: Optional initial position, shape ``(3,)``. Defaults to zeros.\n    :return: Tuple ``(p, v)`` with the final position and velocity.\n    \"\"\"\n\n    if v0 is None:\n        v = jnp.zeros(3, dtype=jnp.float32)\n    else:\n        v = jnp.asarray(v0, dtype=jnp.float32)\n\n    if p0 is None:\n        p = jnp.zeros(3, dtype=jnp.float32)\n    else:\n        p = jnp.asarray(p0, dtype=jnp.float32)\n\n    for meas in measurements:\n        a = jnp.asarray(meas.accel, dtype=jnp.float32)\n        dt = float(meas.dt)\n        v = v + a * dt\n        p = p + v * dt\n\n    return p, v\n</code></pre>"},{"location":"api/sensors/#sensorsintegration","title":"<code>sensors.integration</code>","text":"<p>Helpers for wiring sensor fusion results into DSG-JIT world models.</p> <p>This module provides small, stateless utilities that take fused pose estimates from :mod:<code>sensors.fusion</code> and apply them to a :class:<code>world.model.WorldModel</code> or dynamic scene graph.</p> <p>By keeping this logic in a separate integration layer, we avoid coupling the sensor stack directly to the optimization core, while still making it very easy for users to build real-time or batch pipelines.</p>"},{"location":"api/sensors/#sensors.integration.apply_fused_pose_to_world","title":"<code>apply_fused_pose_to_world(world, fusion, agent_id, t, fused=None)</code>","text":"<p>Apply a fused SE(3) pose estimate to the world model for a given agent.</p> <p>If a pose for <code>(agent_id, t)</code> already exists in the world, this function updates its value in-place. Otherwise, it creates a new agent pose variable via :meth:<code>world.model.WorldModel.add_agent_pose</code>.</p> <p>:param world: World model whose factor graph should be updated. :param fusion: Sensor fusion manager providing fused pose estimates. :param agent_id: String identifier for the agent (e.g. <code>\"robot0\"</code>). :param t: Discrete timestep index for this update. :param fused: Optional fused pose estimate. If <code>None</code>, this function     calls :meth:<code>SensorFusionManager.get_latest_pose</code> internally. :returns: The integer node id (<code>int(NodeId)</code>) corresponding to the     agent's pose variable at time <code>t</code>. :raises ValueError: If no fused estimate is available.</p> Source code in <code>dsg-jit/dsg_jit/sensors/integration.py</code> <pre><code>def apply_fused_pose_to_world(\n    world: WorldModel,\n    fusion: SensorFusionManager,\n    agent_id: str,\n    t: int,\n    fused: Optional[FusedPoseEstimate] = None,\n) -&gt; int:\n    \"\"\"\n    Apply a fused SE(3) pose estimate to the world model for a given agent.\n\n    If a pose for ``(agent_id, t)`` already exists in the world, this function\n    **updates** its value in-place. Otherwise, it **creates** a new agent pose\n    variable via :meth:`world.model.WorldModel.add_agent_pose`.\n\n    :param world: World model whose factor graph should be updated.\n    :param fusion: Sensor fusion manager providing fused pose estimates.\n    :param agent_id: String identifier for the agent (e.g. ``\"robot0\"``).\n    :param t: Discrete timestep index for this update.\n    :param fused: Optional fused pose estimate. If ``None``, this function\n        calls :meth:`SensorFusionManager.get_latest_pose` internally.\n    :returns: The integer node id (``int(NodeId)``) corresponding to the\n        agent's pose variable at time ``t``.\n    :raises ValueError: If no fused estimate is available.\n    \"\"\"\n    if fused is None:\n        fused = fusion.get_latest_pose()\n\n    if fused is None:\n        raise ValueError(\"No fused pose estimate available to apply to world.\")\n\n    pose_vec = jnp.asarray(fused.pose_se3)\n\n    # Check if we already have a pose for this (agent, t).\n    if agent_id in world.agent_pose_ids and t in world.agent_pose_ids[agent_id]:\n        nid = world.agent_pose_ids[agent_id][t]\n        world.fg.variables[nid].value = pose_vec\n    else:\n        nid = world.add_agent_pose(agent_id=agent_id, t=t, value=pose_vec)\n\n    return int(nid)\n</code></pre>"},{"location":"api/sensors/#sensors.integration.apply_trajectory_to_world","title":"<code>apply_trajectory_to_world(world, agent_id, trajectory)</code>","text":"<p>Bulk-apply a discrete trajectory to the world model as agent poses.</p> <p>This is useful for offline pipelines, where you already have a fused trajectory (e.g. from a batch fusion run) and simply want to seed or refresh the world model with those states.</p> <p>:param world: World model to update. :param agent_id: String identifier for the agent. :param trajectory: Mapping from timestep <code>t</code> to 6D se(3) pose vectors     in world coordinates. :returns: <code>None</code>. All updates are applied in-place.</p> Source code in <code>dsg-jit/dsg_jit/sensors/integration.py</code> <pre><code>def apply_trajectory_to_world(\n    world: WorldModel,\n    agent_id: str,\n    trajectory: dict[int, jnp.ndarray],\n) -&gt; None:\n    \"\"\"\n    Bulk-apply a discrete trajectory to the world model as agent poses.\n\n    This is useful for offline pipelines, where you already have a fused\n    trajectory (e.g. from a batch fusion run) and simply want to seed or\n    refresh the world model with those states.\n\n    :param world: World model to update.\n    :param agent_id: String identifier for the agent.\n    :param trajectory: Mapping from timestep ``t`` to 6D se(3) pose vectors\n        in world coordinates.\n    :returns: ``None``. All updates are applied in-place.\n    \"\"\"\n    for t, pose_vec in sorted(trajectory.items()):\n        pose_vec = jnp.asarray(pose_vec)\n        if agent_id in world.agent_pose_ids and t in world.agent_pose_ids[agent_id]:\n            nid = world.agent_pose_ids[agent_id][t]\n            world.fg.variables[nid].value = pose_vec\n        else:\n            world.add_agent_pose(agent_id=agent_id, t=t, value=pose_vec)\n</code></pre>"},{"location":"api/sensors/#sensorslidar","title":"<code>sensors.lidar</code>","text":"<p>LiDAR sensor abstractions and utilities for DSG-JIT.</p> <p>This module defines a lightweight representation of LiDAR data\u2014either 1D range scans, 2D planar scans, or sparse 3D point samples\u2014and provides a simple, JAX-friendly interface for integrating such scans into the factor graph or dynamic scene graph layers.</p> <p>The module includes:</p> <ul> <li> <p>LiDARScan       A minimal container representing a single LiDAR measurement:         - Ranges (1D, 2D, or 3D depending on sensor type)         - Optional beam angles or directions         - Optional timestamp       The structure is intentionally simple so that downstream algorithms       (e.g., geometry-based localization, place association, or occupancy       grid inference) can build on top of it without being locked into a       particular LiDAR model.</p> </li> <li> <p>LiDARSensor       A wrapper around any user-provided LiDAR capture function. This allows       plugging in real hardware, ROS topics, simulation engines, or synthetic       data generators. The wrapper returns <code>LiDARScan</code> objects and is fully       compatible with both synchronous and asynchronous streaming utilities.</p> </li> <li> <p>Helper transforms       Utilities for:         - Converting range/angle scans into 2D or 3D point clouds.         - Projecting LiDAR points into world coordinates given a robot pose.         - Preparing LiDAR-derived factors for integration into the factor           graph (e.g., bearing-range residuals, scan-matching constraints).</p> </li> </ul> <p>Design philosophy:</p> <ul> <li>Keep the LiDAR model minimal and general.</li> <li>Allow users to choose how scans translate into DSG elements (places,     objects, layout nodes, occupancy voxels).</li> <li>Cleanly interoperate with the broader DSG-JIT world model, enabling:         - scan\u2192point cloud\u2192place association         - scan\u2192object detection integration         - scan\u2192unknown-space discovery         - scan\u2192range constraints between robot poses and map nodes</li> </ul> <p>This module intentionally avoids tying LiDAR data to a specific SLAM method (e.g., ICP, NDT, LOAM); instead, it provides a consistent base layer for future plugins and extensions.</p>"},{"location":"api/sensors/#sensors.lidar.LidarMeasurement","title":"<code>LidarMeasurement(ranges, directions=None, t=None, frame_id='lidar', metadata=None)</code>  <code>dataclass</code>","text":"<p>Lightweight container for a single LiDAR scan.</p> <p>This structure is deliberately minimal and JAX-friendly. It can be used for 1D range scans, 2D planar scans, or sparse 3D point samples, and is meant to serve as an intermediate representation between raw sensor data and DSG-JIT factors (e.g., range/bearing residuals, voxel updates).</p> <p>:param ranges:     LiDAR ranges in sensor coordinates.</p> <pre><code>Typical shapes:\n\n* 1D scan: ``(N,)`` where each entry is a range sample.\n* 2D grid: ``(H, W)`` for image-like range sensors.\n* Sparse 3D: ``(N,)`` used together with ``directions`` below.\n\nValues are typically in meters.\n</code></pre> <p>:type ranges: jax.numpy.ndarray</p> <p>:param directions:     Optional unit vectors giving the direction of each range sample in     the sensor frame.</p> <pre><code>Typical shapes:\n\n* 1D scan: ``(N, 3)`` where each row is a 3D direction vector.\n* 2D grid: ``(H, W, 3)`` matching the shape of ``ranges``.\n\nIf ``None``, downstream code is expected to infer directions based\non sensor intrinsics (e.g., azimuth/elevation tables or a pinhole\ncamera model).\n</code></pre> <p>:type directions: Optional[jax.numpy.ndarray]</p> <p>:param t:     Optional timestamp (e.g., in seconds). This can be used to align the     measurement with the dynamic scene graph time index or other sensors. :type t: Optional[float]</p> <p>:param frame_id:     Identifier for the sensor frame from which this measurement was     taken (e.g. <code>\"lidar_front\"</code>). This is useful when a robot carries     multiple LiDAR units or when extrinsic calibration is maintained     per frame. :type frame_id: str</p> <p>:param metadata:     Optional dictionary for any additional information (e.g., intensity     values, per-beam noise estimates, or scan ID). This field is not     used by the core library but can be useful for higher-level     perception algorithms. :type metadata: Optional[dict]</p>"},{"location":"api/sensors/#sensors.lidar.RangeSensor","title":"<code>RangeSensor(name, agent_id, config, sg)</code>","text":"<p>               Bases: <code>Sensor</code></p> <p>Simple range-only sensor attached to an agent.</p> <p>Given a :class:<code>SensorReading</code> whose <code>data</code> field is a scalar range, this sensor produces a single <code>\"range\"</code> factor connecting the agent's pose at time <code>t</code> to a 3D target node.</p> <p>It expects:</p> <ul> <li>the agent trajectory to be registered in the   :class:<code>DynamicSceneGraph</code> under the same <code>agent_id</code> used to   construct this sensor, and</li> <li>the target node id to be present in the underlying   :class:<code>SceneGraphWorld</code>.</li> </ul> <p>The factor uses :func:<code>slam.measurements.range_residual</code> and is registered under the factor type <code>\"range\"</code>.</p> Source code in <code>dsg-jit/dsg_jit/sensors/lidar.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    agent_id: str,\n    config: RangeSensorConfig,\n    sg: SceneGraphWorld,\n) -&gt; None:\n    super().__init__(name=name, agent_id=agent_id)\n    self.config = config\n    self.sg = sg  # used to look up the target's variable index\n</code></pre>"},{"location":"api/sensors/#sensors.lidar.RangeSensor.build_factors","title":"<code>build_factors(wm, dsg, reading)</code>","text":"<p>Build a single range factor from a reading.</p> <p>:param wm: World model whose factor graph already contains the     agent poses and the target node declared in the config. :type wm: world.model.WorldModel :param dsg: Dynamic scene graph providing the pose node id for     <code>(agent_id, reading.t)</code>. :type dsg: world.dynamic_scene_graph.DynamicSceneGraph :param reading: Range measurement; <code>reading.data</code> is assumed     to be a scalar float. :type reading: sensors.base.SensorReading :return: List containing a single <code>\"range\"</code> factor. :rtype: list[core.types.Factor]</p> Source code in <code>dsg-jit/dsg_jit/sensors/lidar.py</code> <pre><code>def build_factors(\n    self,\n    wm: WorldModel,\n    dsg: DynamicSceneGraph,\n    reading: SensorReading,\n) -&gt; List[Factor]:\n    \"\"\"\n    Build a single range factor from a reading.\n\n    :param wm: World model whose factor graph already contains the\n        agent poses and the target node declared in the config.\n    :type wm: world.model.WorldModel\n    :param dsg: Dynamic scene graph providing the pose node id for\n        ``(agent_id, reading.t)``.\n    :type dsg: world.dynamic_scene_graph.DynamicSceneGraph\n    :param reading: Range measurement; ``reading.data`` is assumed\n        to be a scalar float.\n    :type reading: sensors.base.SensorReading\n    :return: List containing a single ``\"range\"`` factor.\n    :rtype: list[core.types.Factor]\n    \"\"\"\n    t = reading.t\n    range_meas = float(reading.data)\n\n    # Resolve pose node id from the DSG trajectory.\n    pose_nid = dsg.world.pose_trajectory[(self.agent_id, t)]\n\n    # Variable ids: [pose, target]\n    var_ids = (pose_nid, self.config.target_node)\n\n    # Params for range_residual.\n    params: Dict[str, jnp.ndarray] = {\n        \"range\": jnp.array(range_meas, dtype=jnp.float32),\n        \"weight\": sigma_to_weight(self.config.noise_sigma),\n    }\n\n    factor = Factor(\n        id=len(wm.fg.factors),\n        type=\"range\",\n        var_ids=var_ids,\n        params=params,\n    )\n    return [factor]\n</code></pre>"},{"location":"api/sensors/#sensors.lidar.RangeSensorConfig","title":"<code>RangeSensorConfig(noise_sigma, target_node)</code>  <code>dataclass</code>","text":"<p>Configuration for a simple range-only sensor.</p> <p>:param noise_sigma: Standard deviation of the range measurement, in     the same units as the world coordinates (typically meters). :type noise_sigma: float :param target_node: Node id of the 3D target in the     :class:<code>SceneGraphWorld</code> (e.g. a room or object center). :type target_node: int</p>"},{"location":"api/sensors/#sensorsstreams","title":"<code>sensors.streams</code>","text":"<p>Generic sensor streaming utilities for DSG-JIT.</p> <p>This module provides a unified abstraction layer for handling live or simulated sensor data streams\u2014synchronous or asynchronous\u2014so that all sensor types (IMU, LiDAR, cameras, range sensors, etc.) can plug into DSG-JIT\u2019s dynamic scene graph pipeline without requiring unique logic for each device.</p> <p>The key goal is to decouple how data is produced (polling, callbacks, asynchronous feeds) from how DSG-JIT consumes that data (factor graph updates, node creation, temporal linking).</p> <p>The module typically defines:</p> <ul> <li> <p>SynchronousStreams</p> <ul> <li>A minimal wrapper around a sensor object that exposes a <code>read()</code>     method.</li> <li>Designed for simple for-loops or offline dataset playback.</li> <li>Ensures each call returns a typed measurement (e.g., IMUMeasurement,     CameraFrame, LiDARScan).</li> </ul> </li> <li> <p>AsynchronousStreams</p> <ul> <li>Provides asyncio-based background tasks that fetch sensor data     without blocking the main SLAM/DSG loop.</li> <li>Each sensor type is polled in a separate coroutine, and the latest     measurement is stored internally for consumption.</li> <li>Enables future real-time extensions (e.g., multi-sensor fusion,     asynchronous factor graph updates).</li> </ul> </li> <li> <p>StreamHandle</p> <ul> <li>An ergonomic wrapper exposing:       <code>.latest()</code> \u2013 retrieve most recent measurement.       <code>.reset()</code> \u2013 clear buffer.       <code>.close()</code> \u2013 stop background tasks.</li> <li>Useful for synchronized fusion pipelines where multiple sensors must     provide data simultaneously.</li> </ul> </li> </ul> <p>Design philosophy:</p> <ul> <li>Treat all sensors uniformly\u2014same streaming API regardless of modality.</li> <li>Allow both synchronous and asynchronous execution with zero change to     downstream SLAM/DSG logic.</li> <li>Enable future \u201cplug-and-play\u201d sensor integration for real robots,     simulators, prerecorded logs, or unit test data.</li> </ul> <p>This module does not itself perform SLAM or scene graph updates\u2014it only defines the mechanism by which sensors deliver data into such pipelines.</p>"},{"location":"api/sensors/#sensors.streams.AsyncFileRangeStream","title":"<code>AsyncFileRangeStream(path, delay=None)</code>","text":"<p>               Bases: <code>AsyncReadingStream</code></p> <p>Asynchronous file-backed range stream.</p> <p>This behaves like :class:<code>FileRangeStream</code>, but exposes an async iterator interface so it can be consumed with <code>async for</code>. An optional <code>delay</code> can be used to simulate a sensor publishing at a fixed rate.</p> <p>.. note::</p> <p>File I/O is still performed using the standard blocking <code>open</code> call.    For small logs and simple simulations this is usually fine, but for    large files or strict real-time requirements you may prefer to replace    this with a true async file reader.</p> <p>:param path: Path to a text file containing one numeric value per line. :type path: str :param delay: Optional delay between consecutive readings, in seconds. :type delay: float or None</p> <p>Initialize the asynchronous file-backed range stream.</p> <p>:param path: Path to a text file containing one numeric value per line. :type path: str :param delay: Optional delay between consecutive readings, in seconds. :type delay: float or None</p> Source code in <code>dsg-jit/dsg_jit/sensors/streams.py</code> <pre><code>def __init__(self, path: str, delay: Optional[float] = None):\n    \"\"\"Initialize the asynchronous file-backed range stream.\n\n    :param path: Path to a text file containing one numeric value per line.\n    :type path: str\n    :param delay: Optional delay between consecutive readings, in seconds.\n    :type delay: float or None\n    \"\"\"\n    self.path = path\n    self.delay = delay\n</code></pre>"},{"location":"api/sensors/#sensors.streams.AsyncFileRangeStream.__aiter__","title":"<code>__aiter__()</code>  <code>async</code>","text":"<p>Asynchronously iterate over sensor readings.</p> <p>If <code>delay</code> is set, the coroutine sleeps for that many seconds between consecutive readings.</p> <p>:return: Asynchronous iterator over :class:<code>SensorReading</code> objects. :rtype: AsyncIterator[SensorReading]</p> Source code in <code>dsg-jit/dsg_jit/sensors/streams.py</code> <pre><code>async def __aiter__(self) -&gt; AsyncIterator[SensorReading]:\n    \"\"\"Asynchronously iterate over sensor readings.\n\n    If ``delay`` is set, the coroutine sleeps for that many seconds\n    between consecutive readings.\n\n    :return: Asynchronous iterator over :class:`SensorReading` objects.\n    :rtype: AsyncIterator[SensorReading]\n    \"\"\"\n    # Note: we use regular file I/O here; for most offline logs this is\n    # sufficient and keeps the dependency surface small.\n    with open(self.path) as f:\n        for t, line in enumerate(f):\n            if self.delay is not None:\n                await asyncio.sleep(self.delay)\n            yield SensorReading(t=t, data=float(line.strip()))\n</code></pre>"},{"location":"api/sensors/#sensors.streams.AsyncReadingStream","title":"<code>AsyncReadingStream</code>","text":"<p>               Bases: <code>BaseSensorStream</code></p> <p>Asynchronous stream of :class:<code>SensorReading</code> objects.</p> <p>Subclasses implement :meth:<code>__aiter__</code> to provide an async iterator over sensor readings. This is useful when integrating with an asyncio-based event loop or real-time sensor drivers.</p>"},{"location":"api/sensors/#sensors.streams.AsyncReadingStream.__aiter__","title":"<code>__aiter__()</code>","text":"<p>Return an asynchronous iterator over sensor readings.</p> <p>:return: Asynchronous iterator over :class:<code>SensorReading</code> objects. :rtype: AsyncIterator[SensorReading]</p> Source code in <code>dsg-jit/dsg_jit/sensors/streams.py</code> <pre><code>def __aiter__(self) -&gt; AsyncIterator[SensorReading]:\n    \"\"\"Return an asynchronous iterator over sensor readings.\n\n    :return: Asynchronous iterator over :class:`SensorReading` objects.\n    :rtype: AsyncIterator[SensorReading]\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/sensors/#sensors.streams.BaseSensorStream","title":"<code>BaseSensorStream</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for all sensor streams used by DSG-JIT.</p> <p>This defines the minimal interface that synchronous and asynchronous sensor streams must support so they can be registered with :class:<code>sensors.fusion.SensorFusionManager</code>.</p> <p>Subclasses may implement either sync or async behavior:</p> <ul> <li>Synchronous streams must implement :meth:<code>read</code>.</li> <li>Asynchronous streams must implement :meth:<code>__aiter__</code>.</li> </ul> <p>Implementations may choose to support both, but it is not required.</p>"},{"location":"api/sensors/#sensors.streams.BaseSensorStream.__aiter__","title":"<code>__aiter__()</code>","text":"<p>Asynchronous iteration interface. Async-only streams MUST implement this. Sync-only streams may raise <code>NotImplementedError</code>.</p> Source code in <code>dsg-jit/dsg_jit/sensors/streams.py</code> <pre><code>def __aiter__(self) -&gt; AsyncIterator[Any]:\n    \"\"\"\n    Asynchronous iteration interface. Async-only streams MUST implement\n    this. Sync-only streams may raise ``NotImplementedError``.\n    \"\"\"\n    raise NotImplementedError(\"This stream does not support async iteration.\")\n</code></pre>"},{"location":"api/sensors/#sensors.streams.BaseSensorStream.close","title":"<code>close()</code>","text":"<p>Optional cleanup hook.</p> <p>Streams that hold system resources (files, sockets, hardware handles) should override this to release them.</p> Source code in <code>dsg-jit/dsg_jit/sensors/streams.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"\n    Optional cleanup hook.\n\n    Streams that hold system resources (files, sockets, hardware handles)\n    should override this to release them.\n    \"\"\"\n    return None\n</code></pre>"},{"location":"api/sensors/#sensors.streams.BaseSensorStream.read","title":"<code>read()</code>","text":"<p>Return the next sample from the stream, or <code>None</code> if no sample is currently available.</p> <p>Sync-only streams MUST implement this. Async-only streams may raise <code>NotImplementedError</code>.</p> Source code in <code>dsg-jit/dsg_jit/sensors/streams.py</code> <pre><code>def read(self) -&gt; Optional[Any]:\n    \"\"\"\n    Return the next sample from the stream, or ``None`` if no sample\n    is currently available.\n\n    Sync-only streams MUST implement this. Async-only streams may raise\n    ``NotImplementedError``.\n    \"\"\"\n    raise NotImplementedError(\"This stream does not support sync read().\")\n</code></pre>"},{"location":"api/sensors/#sensors.streams.FileRangeStream","title":"<code>FileRangeStream(path)</code>","text":"<p>               Bases: <code>ReadingStream</code></p> <p>Synchronous stream backed by a plain-text file.</p> <p>Each line in the file is interpreted as a single floating-point range measurement. The line index is used as the time step <code>t</code>.</p> <p>:param path: Path to a text file containing one numeric value per line. :type path: str</p> <p>Initialize the file-backed range stream.</p> <p>:param path: Path to a text file containing one numeric value per line. :type path: str</p> Source code in <code>dsg-jit/dsg_jit/sensors/streams.py</code> <pre><code>def __init__(self, path: str):\n    \"\"\"Initialize the file-backed range stream.\n\n    :param path: Path to a text file containing one numeric value per line.\n    :type path: str\n    \"\"\"\n    super().__init__()\n    self.path = path\n</code></pre>"},{"location":"api/sensors/#sensors.streams.FileRangeStream.__iter__","title":"<code>__iter__()</code>","text":"<p>Yield sensor readings from the underlying file.</p> <p>Each yielded reading has <code>t</code> equal to the zero-based line index and <code>data</code> equal to the parsed floating-point value.</p> <p>:return: Iterator over :class:<code>SensorReading</code> objects. :rtype: Iterator[SensorReading]</p> Source code in <code>dsg-jit/dsg_jit/sensors/streams.py</code> <pre><code>def __iter__(self) -&gt; Iterator[SensorReading]:\n    \"\"\"Yield sensor readings from the underlying file.\n\n    Each yielded reading has ``t`` equal to the zero-based line index and\n    ``data`` equal to the parsed floating-point value.\n\n    :return: Iterator over :class:`SensorReading` objects.\n    :rtype: Iterator[SensorReading]\n    \"\"\"\n    with open(self.path) as f:\n        for t, line in enumerate(f):\n            yield SensorReading(t=t, data=float(line.strip()))\n</code></pre>"},{"location":"api/sensors/#sensors.streams.FunctionStream","title":"<code>FunctionStream(fn)</code>","text":"<p>               Bases: <code>ReadingStream</code></p> <p>Synchronous stream that pulls samples from a user-provided callback function instead of a file or iterator.</p> The callback must return either <ul> <li>a SensorReading</li> <li>None (to indicate end of data)</li> </ul> Source code in <code>dsg-jit/dsg_jit/sensors/streams.py</code> <pre><code>def __init__(self, fn):\n    super().__init__()\n    self.fn = fn\n</code></pre>"},{"location":"api/sensors/#sensors.streams.ReadingStream","title":"<code>ReadingStream()</code>","text":"<p>               Bases: <code>BaseSensorStream</code></p> <p>Synchronous stream of :class:<code>SensorReading</code> objects.</p> <p>Concrete subclasses implement :meth:<code>__iter__</code> to yield readings one by one.</p> <p>Typical usage::</p> <pre><code>stream = FileRangeStream(\"ranges.txt\")\nfor reading in stream:\n    process(reading)\n</code></pre> <p>Initialize a new reading stream.</p> <p>Subclasses typically only need to override :meth:<code>__iter__</code>. This base constructor sets up internal state for :meth:<code>read</code>.</p> Source code in <code>dsg-jit/dsg_jit/sensors/streams.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"\n    Initialize a new reading stream.\n\n    Subclasses typically only need to override :meth:`__iter__`. This base\n    constructor sets up internal state for :meth:`read`.\n    \"\"\"\n    self._iter: Optional[Iterator[SensorReading]] = None\n</code></pre>"},{"location":"api/sensors/#sensors.streams.ReadingStream.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over sensor readings.</p> <p>:return: Iterator over :class:<code>SensorReading</code> objects. :rtype: Iterator[SensorReading]</p> Source code in <code>dsg-jit/dsg_jit/sensors/streams.py</code> <pre><code>def __iter__(self) -&gt; Iterator[SensorReading]:\n    \"\"\"Iterate over sensor readings.\n\n    :return: Iterator over :class:`SensorReading` objects.\n    :rtype: Iterator[SensorReading]\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/sensors/#sensors.streams.ReadingStream.read","title":"<code>read()</code>","text":"<p>Return the next sensor reading from the stream, or <code>None</code> if the underlying iterator is exhausted.</p> <p>This method adapts the iterator protocol (<code>__iter__</code>) to the :class:<code>BaseSensorStream</code> synchronous <code>read</code> API, so that :class:<code>~sensors.fusion.SensorFusionManager</code> and other callers can treat all synchronous streams uniformly.</p> <p>:return: Next sensor reading, or <code>None</code> if no further data is          available. :rtype: Optional[SensorReading]</p> Source code in <code>dsg-jit/dsg_jit/sensors/streams.py</code> <pre><code>def read(self) -&gt; Optional[SensorReading]:\n    \"\"\"\n    Return the next sensor reading from the stream, or ``None`` if the\n    underlying iterator is exhausted.\n\n    This method adapts the iterator protocol (``__iter__``) to the\n    :class:`BaseSensorStream` synchronous ``read`` API, so that\n    :class:`~sensors.fusion.SensorFusionManager` and other callers can\n    treat all synchronous streams uniformly.\n\n    :return: Next sensor reading, or ``None`` if no further data is\n             available.\n    :rtype: Optional[SensorReading]\n    \"\"\"\n    if self._iter is None:\n        self._iter = iter(self)\n    try:\n        return next(self._iter)\n    except StopIteration:\n        return None\n</code></pre>"},{"location":"api/slam/","title":"SLAM Modules","text":"<p>This section documents the differentiable SE(3) manifold operations, factor residuals, and SLAM-oriented measurement models.</p>"},{"location":"api/slam/#slammanifold","title":"<code>slam.manifold</code>","text":"<p>Manifold utilities for SE(3) and Euclidean variables in DSG-JIT.</p> <p>This module centralizes the geometric logic needed by manifold-aware optimization routines, in particular:</p> <pre><code>\u2022 SE(3) exponential / logarithm maps\n\u2022 Retraction and local parameterization for poses\n\u2022 Jacobian-friendly helpers for composing / inverting SE(3)\n\u2022 Metadata that maps variable types to their manifold model\n  (e.g. \"pose_se3\" \u2192 \"se3\", \"place1d\" \u2192 \"euclidean\")\n</code></pre> <p>The core idea is that the optimizer (e.g. Gauss\u2013Newton) should work in a local tangent space while the state lives on a manifold (SE(3) for poses, \u211d\u207f for Euclidean variables). This module provides:</p> <pre><code>\u2022 Primitive SE(3) operations:\n    - `se3_exp`, `se3_log`         (tangent \u2194 group)\n    - `so3_exp`, `so3_log`         (rotation-only)\n    - `relative_pose_se3`          (pose_a\u207b\u00b9 \u2218 pose_b)\n    - `se3_retract`                (pose \u2295 \u03b4\u03be update rule)\n\n\u2022 Manifold metadata helpers:\n    - `TYPE_TO_MANIFOLD`           (str \u2192 {\"se3\", \"euclidean\", ...})\n    - `get_manifold_for_var_type`\n    - `build_manifold_metadata`    (NodeId \u2192 slice, manifold type)\n</code></pre>"},{"location":"api/slam/#slam.manifold--integration-with-the-optimizer","title":"Integration with the Optimizer","text":"<p><code>optimization.solvers.gauss_newton_manifold</code> uses this module to:</p> <pre><code>1. Split the global state vector into blocks per variable.\n2. Decide which update rule to apply:\n    - SE(3) retraction for \"pose_se3\" blocks\n    - Plain addition for Euclidean blocks\n3. Keep the core solver logic generic while remaining\n   numerically stable on curved manifolds.\n</code></pre>"},{"location":"api/slam/#slam.manifold--design-goals","title":"Design Goals","text":"<p>\u2022 Numerical stability:     Use small-angle fallbacks and well-conditioned SE(3) operations to     avoid NaNs in optimization and differentiation.</p> <p>\u2022 Separation of concerns:     The factor graph and residuals should not hard-code SE(3) math; all     manifold operations live here, behind a clean API.</p> <p>\u2022 JAX-friendly:     All functions are written in a way that is compatible with JIT     compilation, <code>jax.grad</code>, and <code>jax.jvp</code> / <code>vmap</code>.</p>"},{"location":"api/slam/#slam.manifold--notes","title":"Notes","text":"<p>This module currently focuses on SE(3) + Euclidean manifolds, but the design allows extending to other manifolds (e.g. SO(2), quaternions, Lie groups for velocities) by:</p> <pre><code>\u2022 Adding new entries to `TYPE_TO_MANIFOLD`\n\u2022 Implementing the corresponding retract / exp / log primitives\n\u2022 Extending the manifold-aware solver dispatch if needed\n</code></pre>"},{"location":"api/slam/#slam.manifold.build_manifold_metadata","title":"<code>build_manifold_metadata(packed_state, fg)</code>","text":"<p>Build manifold metadata for a factor graph.</p> <p>This function inspects the variables in a :class:<code>~core.factor_graph.FactorGraph</code> and constructs two lookup tables that are consumed by manifold-aware solvers such as :func:<code>optimization.solvers.gauss_newton_manifold</code>:</p> <ul> <li><code>block_slices</code> maps each :class:<code>~core.types.NodeId</code> to a   :class:<code>slice</code> in the packed state vector.</li> <li><code>manifold_types</code> maps each :class:<code>~core.types.NodeId</code> to a   short string describing the manifold model (e.g. <code>\"se3\"</code> or   <code>\"euclidean\"</code>).</li> </ul> <p>The indices produced by :meth:<code>core.factor_graph.FactorGraph.pack_state</code> may be stored either as slices or as <code>(start, length)</code> tuples; this helper normalizes everything to proper Python <code>slice</code> objects so the solver does not need to handle multiple formats.</p> <p>:param fg: The factor graph whose variables should be analyzed to     construct manifold metadata. :return: A tuple <code>(block_slices, manifold_types)</code> where     <code>block_slices</code> is a mapping from :class:<code>~core.types.NodeId</code>     to :class:<code>slice</code> in the flat state vector, and     <code>manifold_types</code> is a mapping from :class:<code>~core.types.NodeId</code>     to a manifold model name string.</p> Source code in <code>dsg-jit/dsg_jit/slam/manifold.py</code> <pre><code>def build_manifold_metadata(\n    packed_state: jnp.ndarray,\n    fg: FactorGraph\n) -&gt; Tuple[Dict[NodeId, slice], Dict[NodeId, str]]:\n    \"\"\"Build manifold metadata for a factor graph.\n\n    This function inspects the variables in a :class:`~core.factor_graph.FactorGraph`\n    and constructs two lookup tables that are consumed by\n    manifold-aware solvers such as\n    :func:`optimization.solvers.gauss_newton_manifold`:\n\n    * ``block_slices`` maps each :class:`~core.types.NodeId` to a\n      :class:`slice` in the packed state vector.\n    * ``manifold_types`` maps each :class:`~core.types.NodeId` to a\n      short string describing the manifold model (e.g. ``\"se3\"`` or\n      ``\"euclidean\"``).\n\n    The indices produced by :meth:`core.factor_graph.FactorGraph.pack_state`\n    may be stored either as slices or as ``(start, length)`` tuples;\n    this helper normalizes everything to proper Python ``slice``\n    objects so the solver does not need to handle multiple formats.\n\n    :param fg: The factor graph whose variables should be analyzed to\n        construct manifold metadata.\n    :return: A tuple ``(block_slices, manifold_types)`` where\n        ``block_slices`` is a mapping from :class:`~core.types.NodeId`\n        to :class:`slice` in the flat state vector, and\n        ``manifold_types`` is a mapping from :class:`~core.types.NodeId`\n        to a manifold model name string.\n    \"\"\"\n    _, index = packed_state\n\n    block_slices: Dict[NodeId, slice] = {}\n    manifold_types: Dict[NodeId, str] = {}\n\n    for nid, var in fg.variables.items():\n        idx = index[nid]\n\n        # Normalize to a slice\n        if isinstance(idx, slice):\n            sl = idx\n        else:\n            # assume (start, length)\n            start, length = idx\n            sl = slice(start, start + length)\n\n        block_slices[nid] = sl\n\n        manifold = get_manifold_for_var_type(var.type)\n        manifold_types[nid] = manifold\n\n    return block_slices, manifold_types\n</code></pre>"},{"location":"api/slam/#slam.manifold.get_manifold_for_var_type","title":"<code>get_manifold_for_var_type(var_type)</code>","text":"<p>Return the manifold model name for a given variable type.</p> <p>This is a thin helper around :data:<code>TYPE_TO_MANIFOLD</code> that maps a high-level variable type tag (e.g. <code>\"pose_se3\"</code>, <code>\"place1d\"</code>) to the underlying manifold model used by manifold-aware solvers.</p> <p>:param var_type: Variable type string, such as <code>\"pose_se3\"</code>,     <code>\"place1d\"</code>, <code>\"room1d\"</code>, <code>\"landmark3d\"</code> or     <code>\"voxel_cell\"</code>. :return: The manifold model name (for example <code>\"se3\"</code> or     <code>\"euclidean\"</code>). If the type is unknown, <code>\"euclidean\"</code> is     returned by default.</p> Source code in <code>dsg-jit/dsg_jit/slam/manifold.py</code> <pre><code>def get_manifold_for_var_type(var_type: str) -&gt; str:\n    \"\"\"Return the manifold model name for a given variable type.\n\n    This is a thin helper around :data:`TYPE_TO_MANIFOLD` that maps a\n    high-level variable type tag (e.g. ``\"pose_se3\"``, ``\"place1d\"``)\n    to the underlying manifold model used by manifold-aware solvers.\n\n    :param var_type: Variable type string, such as ``\"pose_se3\"``,\n        ``\"place1d\"``, ``\"room1d\"``, ``\"landmark3d\"`` or\n        ``\"voxel_cell\"``.\n    :return: The manifold model name (for example ``\"se3\"`` or\n        ``\"euclidean\"``). If the type is unknown, ``\"euclidean\"`` is\n        returned by default.\n    \"\"\"\n    return TYPE_TO_MANIFOLD.get(var_type, \"euclidean\")\n</code></pre>"},{"location":"api/slam/#slammeasurements","title":"<code>slam.measurements</code>","text":"<p>Residual models (measurement factors) for DSG-JIT.</p> <p>This module defines the measurement-level building blocks used by the factor graph:</p> <pre><code>\u2022 Each function here implements a residual:\n      r(x; params) \u2208 \u211d\u1d4f\n  compatible with JAX differentiation and JIT compilation.\n\n\u2022 Factor types in the graph (e.g. \"prior\", \"odom_se3_geodesic\",\n  \"voxel_point_obs\") are mapped to these residual functions via\n  `FactorGraph.register_residual`.\n</code></pre> <p>Broadly, the residuals fall into several families:</p>"},{"location":"api/slam/#slam.measurements--1-priors-and-simple-euclidean-factors","title":"1. Priors and Simple Euclidean Factors","text":"<pre><code>\u2022 `prior_residual`:\n    Generic prior on any variable:\n        r = x \u2212 target\n\nUseful for:\n    - anchoring poses (pose0 \u2248 identity)\n    - clamping scalar variables (places, rooms, weights, etc.)\n</code></pre>"},{"location":"api/slam/#slam.measurements--2-se3-slam-style-motion-factors","title":"2. SE(3) / SLAM-Style Motion Factors","text":"<pre><code>\u2022 `odom_se3_geodesic_residual`:\n    SE(3) relative pose constraint using the group logarithm:\n        r = log( meas\u207b\u00b9 \u2218 (T_i\u207b\u00b9 \u2218 T_j) )\n\n    Works on \"pose_se3\" variables and lives in se(3) (6D tangent).\n\n\u2022 (Optionally) additive variants:\n    - `odom_se3_additive_residual`\n      for simpler experiments where translation/rotation are treated\n      additively in \u211d\u2076.\n</code></pre> <p>These encode frame-to-frame odometry, loop closures, and generic relative pose constraints between SE(3) nodes.</p>"},{"location":"api/slam/#slam.measurements--3-landmark-and-attachment-factors","title":"3. Landmark and Attachment Factors","text":"<pre><code>\u2022 `pose_landmark_relative_residual`:\n    Relative pose between a SE(3) pose and a landmark position,\n    typically enforcing:\n        T_pose \u2218 landmark \u2248 measurement\n\n\u2022 `pose_landmark_bearing_residual`:\n    Bearing-only constraint between a pose and a landmark (e.g.,\n    enforcing angular consistency between measurement and predicted\n    direction).\n\n\u2022 `pose_place_attachment_residual`:\n    Softly attaches a pose coordinate (e.g. x) to a 1D \"place\"\n    variable, used for 1D topological / metric alignment.\n</code></pre> <p>These connect metric states (poses, landmarks, places) into a coherent SLAM + scene-graph representation.</p>"},{"location":"api/slam/#slam.measurements--4-voxel-grid-volumetric-factors","title":"4. Voxel Grid / Volumetric Factors","text":"<pre><code>\u2022 `voxel_smoothness_residual`:\n    Encourages neighboring voxel centers to form a smooth chain or\n    grid. Used to regularize voxel grids representing surfaces or\n    1D/2D/3D structures.\n\n\u2022 `voxel_point_observation_residual`:\n    Ties a voxel cell to an observed point in world coordinates,\n    often used for learning voxel positions from point-like\n    observations.\n</code></pre> <p>These factors are key to the differentiable voxel experiments and hybrid SE3 + voxel benchmarks.</p>"},{"location":"api/slam/#slam.measurements--5-weighting-and-noise-models","title":"5. Weighting and Noise Models","text":"<p>Most residuals support per-factor weightings via a shared helper:</p> <pre><code>\u2022 `_apply_weight(r, params)`:\n    Applies scalar or diagonal weights to a residual, enabling:\n\n        - Hand-tuned noise models (e.g. \u03c3\u207b\u00b9)\n        - Learnable factor-type weights (via log_scales)\n        - Consistent scaling for multi-term objectives\n</code></pre> <p>This is what allows the engine to support learnable factor weights in Phase 4 experiments (e.g. learning odom vs. observation trade-offs).</p>"},{"location":"api/slam/#slam.measurements--design-goals","title":"Design Goals","text":"<p>\u2022 Clear factor semantics:     Each residual corresponds to a named factor type used throughout     tests and experiments, so it\u2019s obvious what each factor is doing.</p> <p>\u2022 Differentiable and JIT-friendly:     All residuals are written to be compatible with <code>jax.jit</code> and     <code>jax.grad</code>, enabling higher-level meta-learning and end-to-end     differentiable training loops.</p> <p>\u2022 Composable:     Residuals do not own the factor graph logic; they simply implement     r(x; params). All graph structure, manifold handling, and joint     optimization is handled in <code>core.factor_graph</code>, <code>slam.manifold</code>,     and <code>optimization.solvers</code>.</p>"},{"location":"api/slam/#slam.measurements--notes","title":"Notes","text":"<p>When adding a new factor type:</p> <pre><code>1. Implement a residual here:\n       def my_factor_residual(x: jnp.ndarray, params: Dict[str, jnp.ndarray]) -&gt; jnp.ndarray\n\n2. Register it with the factor graph:\n       fg.register_residual(\"my_factor\", my_factor_residual)\n\n3. (Optionally) add tests under `tests/` and, if relevant, a\n   differentiable experiment under `experiments/`.\n</code></pre> <p>This pattern keeps the measurement models centralized and makes the engine easy to extend for new research ideas.</p>"},{"location":"api/slam/#slam.measurements.object_at_pose_residual","title":"<code>object_at_pose_residual(x, params)</code>","text":"<p>Residual tying a 3D object position to a pose translation.</p> <p>Interprets <code>x</code> as <code>[pose(6), object(3)]</code> and encourages the object position to coincide with the pose translation plus an optional fixed offset.</p> <p>:param x: Stacked state block <code>[pose(6), object(3)]</code>. :type x: jnp.ndarray :param params: Parameter dictionary containing integer fields     <code>\"pose_dim\"</code> and <code>\"obj_dim\"</code>, and optionally <code>\"offset\"</code>     (a 3D vector) and a weight handled by :func:<code>_apply_weight</code>. :type params: dict :return: 3D residual <code>object - (pose_translation + offset)</code>. :rtype: jnp.ndarray</p> Source code in <code>dsg-jit/dsg_jit/slam/measurements.py</code> <pre><code>def object_at_pose_residual(x: jnp.ndarray, params: dict) -&gt; jnp.ndarray:\n    \"\"\"\n    Residual tying a 3D object position to a pose translation.\n\n    Interprets ``x`` as ``[pose(6), object(3)]`` and encourages the\n    object position to coincide with the pose translation plus an\n    optional fixed offset.\n\n    :param x: Stacked state block ``[pose(6), object(3)]``.\n    :type x: jnp.ndarray\n    :param params: Parameter dictionary containing integer fields\n        ``\"pose_dim\"`` and ``\"obj_dim\"``, and optionally ``\"offset\"``\n        (a 3D vector) and a weight handled by :func:`_apply_weight`.\n    :type params: dict\n    :return: 3D residual ``object - (pose_translation + offset)``.\n    :rtype: jnp.ndarray\n    \"\"\"\n    pose_dim = int(params[\"pose_dim\"])\n    obj_dim = int(params[\"obj_dim\"])\n\n    assert x.shape[0] == pose_dim + obj_dim\n\n    pose = x[:pose_dim]\n    obj = x[pose_dim : pose_dim + obj_dim]\n\n    offset = params.get(\"offset\", jnp.zeros(3))\n    offset = jnp.asarray(offset).reshape(3,)\n\n    t = pose[:3]  # tx, ty, tz\n    r = obj - (t + offset)\n    return _apply_weight(r, params)\n</code></pre>"},{"location":"api/slam/#slam.measurements.odom_residual","title":"<code>odom_residual(x, params)</code>","text":"<p>Simple odometry-style residual in Euclidean space.</p> <p>Interprets <code>x</code> as a concatenation of two poses <code>pose0</code> and <code>pose1</code> in R^d and enforces an additive odometry relation</p> <p><code>(pose1 - pose0) - measurement = 0</code>.</p> <p>:param x: Stacked pose vector <code>[pose0, pose1]</code>. :type x: jnp.ndarray :param params: Parameter dictionary containing <code>\"measurement\"</code> with     the desired relative displacement. :type params: Dict[str, jnp.ndarray] :return: Euclidean odometry residual. :rtype: jnp.ndarray</p> Source code in <code>dsg-jit/dsg_jit/slam/measurements.py</code> <pre><code>def odom_residual(x: jnp.ndarray, params: Dict[str, jnp.ndarray]) -&gt; jnp.ndarray:\n    \"\"\"\n    Simple odometry-style residual in Euclidean space.\n\n    Interprets ``x`` as a concatenation of two poses ``pose0`` and\n    ``pose1`` in R^d and enforces an additive odometry relation\n\n    ``(pose1 - pose0) - measurement = 0``.\n\n    :param x: Stacked pose vector ``[pose0, pose1]``.\n    :type x: jnp.ndarray\n    :param params: Parameter dictionary containing ``\"measurement\"`` with\n        the desired relative displacement.\n    :type params: Dict[str, jnp.ndarray]\n    :return: Euclidean odometry residual.\n    :rtype: jnp.ndarray\n    \"\"\"\n    dim = x.shape[0] // 2\n    pose0 = x[:dim]\n    pose1 = x[dim:]\n    meas = params[\"measurement\"]\n    return (pose1 - pose0) - meas\n</code></pre>"},{"location":"api/slam/#slam.measurements.odom_se3_geodesic_residual","title":"<code>odom_se3_geodesic_residual(x, params)</code>","text":"<p>Experimental SE(3) geodesic residual using <code>relative_pose_se3</code>.</p> <p>Interprets <code>x</code> as two 6D poses in se(3) and uses :func:<code>core.math3d.relative_pose_se3</code> to compute the estimated relative pose before subtracting the provided measurement.</p> <p>:param x: Stacked pose vector <code>[pose0(6), pose1(6)]</code>. :type x: jnp.ndarray :param params: Parameter dictionary containing <code>\"measurement\"</code> with     the desired relative pose in se(3), and optionally a weight     understood by :func:<code>_apply_weight</code>. :type params: Dict[str, jnp.ndarray] :return: Geodesic SE(3) odometry residual in se(3). :rtype: jnp.ndarray</p> Source code in <code>dsg-jit/dsg_jit/slam/measurements.py</code> <pre><code>def odom_se3_geodesic_residual(x: jnp.ndarray, params: Dict[str, jnp.ndarray]) -&gt; jnp.ndarray:\n    \"\"\"\n    Experimental SE(3) geodesic residual using ``relative_pose_se3``.\n\n    Interprets ``x`` as two 6D poses in se(3) and uses\n    :func:`core.math3d.relative_pose_se3` to compute the estimated\n    relative pose before subtracting the provided measurement.\n\n    :param x: Stacked pose vector ``[pose0(6), pose1(6)]``.\n    :type x: jnp.ndarray\n    :param params: Parameter dictionary containing ``\"measurement\"`` with\n        the desired relative pose in se(3), and optionally a weight\n        understood by :func:`_apply_weight`.\n    :type params: Dict[str, jnp.ndarray]\n    :return: Geodesic SE(3) odometry residual in se(3).\n    :rtype: jnp.ndarray\n    \"\"\"\n    assert x.shape[0] == 12, \"odom_se3_geodesic_residual expects two 6D poses stacked.\"\n\n    pose0 = x[:6]\n    pose1 = x[6:]\n    meas = params[\"measurement\"]\n\n    xi_est = relative_pose_se3(pose0, pose1)\n    r = xi_est - meas\n    return _apply_weight(r, params)\n</code></pre>"},{"location":"api/slam/#slam.measurements.odom_se3_residual","title":"<code>odom_se3_residual(x, params)</code>","text":"<p>SE(3)-style odometry residual in a 6D vector parameterization.</p> <p>Treats each pose as a 6-vector <code>[tx, ty, tz, wx, wy, wz]</code> and a 6D measurement in the same parameterization. The residual is</p> <p><code>(pose_j - pose_i) - measurement</code>.</p> <p>This is a simple additive model in R^6 and is used as the workhorse SE(3) chain factor in many experiments.</p> <p>:param x: Stacked pose vector <code>[pose_i(6), pose_j(6)]</code>. :type x: jnp.ndarray :param params: Parameter dictionary containing <code>\"measurement\"</code> with     the desired relative pose in R^6. :type params: Dict[str, jnp.ndarray] :return: SE(3) odometry residual in R^6. :rtype: jnp.ndarray</p> Source code in <code>dsg-jit/dsg_jit/slam/measurements.py</code> <pre><code>def odom_se3_residual(x: jnp.ndarray, params: Dict[str, jnp.ndarray]) -&gt; jnp.ndarray:\n    \"\"\"\n    SE(3)-style odometry residual in a 6D vector parameterization.\n\n    Treats each pose as a 6-vector ``[tx, ty, tz, wx, wy, wz]`` and a\n    6D measurement in the same parameterization. The residual is\n\n    ``(pose_j - pose_i) - measurement``.\n\n    This is a simple additive model in R^6 and is used as the workhorse\n    SE(3) chain factor in many experiments.\n\n    :param x: Stacked pose vector ``[pose_i(6), pose_j(6)]``.\n    :type x: jnp.ndarray\n    :param params: Parameter dictionary containing ``\"measurement\"`` with\n        the desired relative pose in R^6.\n    :type params: Dict[str, jnp.ndarray]\n    :return: SE(3) odometry residual in R^6.\n    :rtype: jnp.ndarray\n    \"\"\"\n    #residual true Newton Solver for pure SE(3)\n    #TODO replace with true Newton Solver\n    dim = x.shape[0] // 2  # should be 6\n    pose_i = x[:dim]\n    pose_j = x[dim:]\n    meas = params[\"measurement\"]\n    r = (pose_j - pose_i) - meas\n    return r\n</code></pre>"},{"location":"api/slam/#slam.measurements.pose_landmark_bearing_residual","title":"<code>pose_landmark_bearing_residual(x, params)</code>","text":"<p>Bearing-only residual between a pose and a 3D landmark.</p> <p>Interprets <code>x</code> as <code>[pose(6), landmark(3)]</code> and compares the predicted bearing from the pose to the landmark against a measured bearing vector.</p> <p>:param x: Stacked state block <code>[pose(6), landmark(3)]</code>. :type x: jnp.ndarray :param params: Parameter dictionary containing <code>\"bearing_meas\"</code>     (a 3D bearing vector in the pose frame). Any weighting is     applied upstream. :type params: dict :return: 3D residual <code>bearing_pred - bearing_meas</code>. :rtype: jnp.ndarray</p> Source code in <code>dsg-jit/dsg_jit/slam/measurements.py</code> <pre><code>def pose_landmark_bearing_residual(\n    x: jnp.ndarray,\n    params: dict,\n) -&gt; jnp.ndarray:\n    \"\"\"\n    Bearing-only residual between a pose and a 3D landmark.\n\n    Interprets ``x`` as ``[pose(6), landmark(3)]`` and compares the\n    predicted bearing from the pose to the landmark against a measured\n    bearing vector.\n\n    :param x: Stacked state block ``[pose(6), landmark(3)]``.\n    :type x: jnp.ndarray\n    :param params: Parameter dictionary containing ``\"bearing_meas\"``\n        (a 3D bearing vector in the pose frame). Any weighting is\n        applied upstream.\n    :type params: dict\n    :return: 3D residual ``bearing_pred - bearing_meas``.\n    :rtype: jnp.ndarray\n    \"\"\"\n    pose = x[:6]\n    landmark = x[6:9]\n\n    bearing_meas = params[\"bearing_meas\"]  # (3,)\n\n    T = se3_exp(pose)\n    R = T[:3, :3]\n    t = T[:3, 3]\n\n    landmark_pose = R.T @ (landmark - t)\n\n    def safe_normalize(v):\n        n = jnp.linalg.norm(v)\n        return v / (n + 1e-8)\n\n    bearing_pred = safe_normalize(landmark_pose)\n    bearing_meas = safe_normalize(bearing_meas)\n\n    residual = bearing_pred - bearing_meas\n    return residual\n</code></pre>"},{"location":"api/slam/#slam.measurements.pose_landmark_relative_residual","title":"<code>pose_landmark_relative_residual(x, params)</code>","text":"<p>Relative pose\u2013landmark residual in SE(3).</p> <p>Interprets <code>x</code> as <code>[pose(6), landmark(3)]</code> and enforces that the landmark, expressed in the pose frame, matches a measured 3D point.</p> <p>:param x: Stacked state block <code>[pose(6), landmark(3)]</code>. :type x: jnp.ndarray :param params: Parameter dictionary containing <code>\"measurement\"</code>     (a 3D point in the pose frame). Any weighting is applied     upstream by :func:<code>_apply_weight</code>. :type params: dict :return: 3D residual between predicted and measured landmark     positions in the pose frame. :rtype: jnp.ndarray</p> Source code in <code>dsg-jit/dsg_jit/slam/measurements.py</code> <pre><code>def pose_landmark_relative_residual(\n    x: jnp.ndarray,\n    params: dict,\n) -&gt; jnp.ndarray:\n    \"\"\"\n    Relative pose\u2013landmark residual in SE(3).\n\n    Interprets ``x`` as ``[pose(6), landmark(3)]`` and enforces that the\n    landmark, expressed in the pose frame, matches a measured 3D point.\n\n    :param x: Stacked state block ``[pose(6), landmark(3)]``.\n    :type x: jnp.ndarray\n    :param params: Parameter dictionary containing ``\"measurement\"``\n        (a 3D point in the pose frame). Any weighting is applied\n        upstream by :func:`_apply_weight`.\n    :type params: dict\n    :return: 3D residual between predicted and measured landmark\n        positions in the pose frame.\n    :rtype: jnp.ndarray\n    \"\"\"\n    pose = x[:6]\n    landmark = x[6:9]\n\n    meas = params[\"measurement\"]  # (3,)\n    T = se3_exp(pose)\n    R = T[:3, :3]\n    t = T[:3, 3]\n\n    # landmark expressed in pose frame\n    landmark_pose = R.T @ (landmark - t)\n\n    residual = landmark_pose - meas\n    return residual  # weight is applied via _apply_weight in FactorGraph\n</code></pre>"},{"location":"api/slam/#slam.measurements.pose_place_attachment_residual","title":"<code>pose_place_attachment_residual(x, params)</code>","text":"<p>Residual tying a scalar place variable to one coordinate of a pose.</p> <p>Interprets <code>x</code> as <code>[pose, place]</code> and enforces that the place value tracks a particular coordinate of the pose (e.g., x-position).</p> <p>:param x: Stacked state block <code>[pose, place]</code>. :type x: jnp.ndarray :param params: Parameter dictionary with integer entries     <code>\"pose_dim\"</code>, <code>\"place_dim\"</code>, and <code>\"pose_coord_index\"</code>     indicating the layout of <code>x</code> and which pose coordinate to     attach to. May also contain a weight handled by     :func:<code>_apply_weight</code>. :type params: dict :return: 1D residual enforcing <code>place[0] \u2248 pose[pose_coord_index]</code>. :rtype: jnp.ndarray</p> Source code in <code>dsg-jit/dsg_jit/slam/measurements.py</code> <pre><code>def pose_place_attachment_residual(x: jnp.ndarray, params: dict) -&gt; jnp.ndarray:\n    \"\"\"\n    Residual tying a scalar place variable to one coordinate of a pose.\n\n    Interprets ``x`` as ``[pose, place]`` and enforces that the place\n    value tracks a particular coordinate of the pose (e.g., x-position).\n\n    :param x: Stacked state block ``[pose, place]``.\n    :type x: jnp.ndarray\n    :param params: Parameter dictionary with integer entries\n        ``\"pose_dim\"``, ``\"place_dim\"``, and ``\"pose_coord_index\"``\n        indicating the layout of ``x`` and which pose coordinate to\n        attach to. May also contain a weight handled by\n        :func:`_apply_weight`.\n    :type params: dict\n    :return: 1D residual enforcing ``place[0] \u2248 pose[pose_coord_index]``.\n    :rtype: jnp.ndarray\n    \"\"\"\n    pose_dim = int(params[\"pose_dim\"])\n    place_dim = int(params[\"place_dim\"])\n    coord_idx = int(params[\"pose_coord_index\"])\n\n    assert x.shape[0] == pose_dim + place_dim\n\n    pose = x[:pose_dim]\n    place = x[pose_dim : pose_dim + place_dim]\n\n    # Make it 1D of length 1, not scalar\n    r = jnp.array([place[0] - pose[coord_idx]])\n    return _apply_weight(r, params)\n</code></pre>"},{"location":"api/slam/#slam.measurements.pose_temporal_smoothness_residual","title":"<code>pose_temporal_smoothness_residual(x, params)</code>","text":"<p>Temporal smoothness residual between two SE(3) poses.</p> <p>Interprets <code>x</code> as <code>[pose_t, pose_t1]</code> in R^6 and penalizes the difference <code>pose_t1 - pose_t</code>.</p> <p>:param x: Stacked state block <code>[pose_t(6), pose_t1(6)]</code>. :type x: jnp.ndarray :param params: Parameter dictionary, optionally containing a weight     handled by :func:<code>_apply_weight</code>. :type params: dict :return: 6D temporal smoothness residual. :rtype: jnp.ndarray</p> Source code in <code>dsg-jit/dsg_jit/slam/measurements.py</code> <pre><code>def pose_temporal_smoothness_residual(x: jnp.ndarray, params: dict) -&gt; jnp.ndarray:\n    \"\"\"\n    Temporal smoothness residual between two SE(3) poses.\n\n    Interprets ``x`` as ``[pose_t, pose_t1]`` in R^6 and penalizes the\n    difference ``pose_t1 - pose_t``.\n\n    :param x: Stacked state block ``[pose_t(6), pose_t1(6)]``.\n    :type x: jnp.ndarray\n    :param params: Parameter dictionary, optionally containing a weight\n        handled by :func:`_apply_weight`.\n    :type params: dict\n    :return: 6D temporal smoothness residual.\n    :rtype: jnp.ndarray\n    \"\"\"\n    dim = x.shape[0] // 2\n    pose_t = x[:dim]\n    pose_t1 = x[dim:]\n    r = pose_t1 - pose_t\n    return _apply_weight(r, params)\n</code></pre>"},{"location":"api/slam/#slam.measurements.pose_voxel_point_residual","title":"<code>pose_voxel_point_residual(x, params)</code>","text":"<p>Residual between a pose and a voxel center given a point measurement.</p> <p>Interprets <code>x</code> as <code>[pose(6), voxel_center(3)]</code>. The measurement is a point expressed in the pose frame; it is projected into the world frame and compared against the voxel center.</p> <p>:param x: Stacked state block <code>[pose(6), voxel_center(3)]</code>. :type x: jnp.ndarray :param params: Parameter dictionary containing <code>\"point_meas\"</code>     (a 3D point in the pose frame). Any weighting is applied     upstream by :func:<code>_apply_weight</code>. :type params: dict :return: 3D residual <code>voxel_center - predicted_world_point</code>. :rtype: jnp.ndarray</p> Source code in <code>dsg-jit/dsg_jit/slam/measurements.py</code> <pre><code>def pose_voxel_point_residual(\n    x: jnp.ndarray,\n    params: dict,\n) -&gt; jnp.ndarray:\n    \"\"\"\n    Residual between a pose and a voxel center given a point measurement.\n\n    Interprets ``x`` as ``[pose(6), voxel_center(3)]``. The measurement\n    is a point expressed in the pose frame; it is projected into the\n    world frame and compared against the voxel center.\n\n    :param x: Stacked state block ``[pose(6), voxel_center(3)]``.\n    :type x: jnp.ndarray\n    :param params: Parameter dictionary containing ``\"point_meas\"``\n        (a 3D point in the pose frame). Any weighting is applied\n        upstream by :func:`_apply_weight`.\n    :type params: dict\n    :return: 3D residual ``voxel_center - predicted_world_point``.\n    :rtype: jnp.ndarray\n    \"\"\"\n    pose = x[:6]\n    voxel = x[6:9]  # voxel center in world frame\n\n    point_meas = params[\"point_meas\"]  # (3,)\n\n    T = se3_exp(pose)          # 4x4\n    R = T[:3, :3]\n    t = T[:3, 3]\n\n    world_point = R @ point_meas + t  # predicted world point from this measurement\n\n    residual = voxel - world_point\n    return residual\n</code></pre>"},{"location":"api/slam/#slam.measurements.prior_residual","title":"<code>prior_residual(x, params)</code>","text":"<p>Simple prior on a single variable.</p> <p>Computes <code>residual = x - target</code> for any vector dimension.</p> <p>:param x: Current variable value (flattened state block). :type x: jnp.ndarray :param params: Parameter dictionary containing <code>\"target\"</code> and     optionally a weight understood by :func:<code>_apply_weight</code>. :type params: Dict[str, jnp.ndarray] :return: Prior residual <code>x - target</code> (possibly reweighted). :rtype: jnp.ndarray</p> Source code in <code>dsg-jit/dsg_jit/slam/measurements.py</code> <pre><code>def prior_residual(x: jnp.ndarray, params: Dict[str, jnp.ndarray]) -&gt; jnp.ndarray:\n    \"\"\"\n    Simple prior on a single variable.\n\n    Computes ``residual = x - target`` for any vector dimension.\n\n    :param x: Current variable value (flattened state block).\n    :type x: jnp.ndarray\n    :param params: Parameter dictionary containing ``\"target\"`` and\n        optionally a weight understood by :func:`_apply_weight`.\n    :type params: Dict[str, jnp.ndarray]\n    :return: Prior residual ``x - target`` (possibly reweighted).\n    :rtype: jnp.ndarray\n    \"\"\"\n    target = params[\"target\"]\n    r = x - target\n    return _apply_weight(r, params)\n</code></pre>"},{"location":"api/slam/#slam.measurements.range_residual","title":"<code>range_residual(x, params)</code>","text":"<p>Range-only residual between a pose and a 3D target.</p> <p>This residual assumes that <code>x</code> is the concatenation of a 6D SE(3) pose (in se(3) vector form) and a 3D target position::</p> <pre><code>x = [pose_se3(6), target(3)]\n</code></pre> <p>Only the translational part of the pose is used. The residual is::</p> <pre><code>r = ||target - t|| - r_meas\n</code></pre> <p>where <code>t</code> is the pose translation and <code>r_meas</code> is the measured range. A scalar weight is applied in the same way as other residuals via :func:<code>_apply_weight</code>.</p> <p>:param x: Concatenated pose and target state, shape <code>(9,)</code>. :param params: Parameter dictionary with keys:     - <code>\"range\"</code>: scalar or length-1 array containing the       measured range.     - <code>\"weight\"</code> (optional): scalar weight to apply. If omitted,       a weight of <code>1.0</code> is used by :func:<code>_apply_weight</code>. :return: Residual vector of shape <code>(1,)</code> (after weighting).</p> Source code in <code>dsg-jit/dsg_jit/slam/measurements.py</code> <pre><code>def range_residual(x: jnp.ndarray, params: Dict[str, jnp.ndarray]) -&gt; jnp.ndarray:\n    \"\"\"\n    Range-only residual between a pose and a 3D target.\n\n    This residual assumes that ``x`` is the concatenation of a 6D SE(3)\n    pose (in se(3) vector form) and a 3D target position::\n\n        x = [pose_se3(6), target(3)]\n\n    Only the translational part of the pose is used. The residual is::\n\n        r = ||target - t|| - r_meas\n\n    where ``t`` is the pose translation and ``r_meas`` is the measured\n    range. A scalar weight is applied in the same way as other residuals\n    via :func:`_apply_weight`.\n\n    :param x: Concatenated pose and target state, shape ``(9,)``.\n    :param params: Parameter dictionary with keys:\n        - ``\"range\"``: scalar or length-1 array containing the\n          measured range.\n        - ``\"weight\"`` (optional): scalar weight to apply. If omitted,\n          a weight of ``1.0`` is used by :func:`_apply_weight`.\n    :return: Residual vector of shape ``(1,)`` (after weighting).\n    \"\"\"\n    # Split state: first 6 are se(3) (pose), last 3 are 3D target position.\n    pose = x[:6]\n    target = x[6:9]\n\n    # Translation component of the pose.\n    t = pose[:3]\n\n    # Euclidean distance between pose translation and target.\n    diff = target - t\n    dist = jnp.linalg.norm(diff)\n\n    # Measured range can be a scalar or length-1 array.\n    r_meas = params[\"range\"]\n    r_meas = jnp.array(r_meas, dtype=jnp.float32).reshape(())\n\n    # Residual: predicted - measured.\n    r = dist - r_meas\n\n    # Wrap as 1D vector and apply weight.\n    r_vec = jnp.array([r], dtype=jnp.float32)\n    return _apply_weight(r_vec, params)\n</code></pre>"},{"location":"api/slam/#slam.measurements.se3_chain_residual","title":"<code>se3_chain_residual(x, params)</code>","text":"<p>Alias for SE(3) chain / odometry residual used in visualization.</p> <p>This is a thin wrapper around :func:<code>odom_se3_residual</code>, so that experiments and visualization code can refer to a semantically descriptive name (\"se3_chain\") without duplicating logic.</p> <p>:param x: Stacked pose vector <code>[pose_i(6), pose_j(6)]</code>. :type x: jnp.ndarray :param params: Parameter dictionary containing <code>\"measurement\"</code> with     the desired relative pose in R^6. :type params: Dict[str, jnp.ndarray] :return: SE(3) chain residual produced by :func:<code>odom_se3_residual</code>. :rtype: jnp.ndarray</p> Source code in <code>dsg-jit/dsg_jit/slam/measurements.py</code> <pre><code>def se3_chain_residual(x: jnp.ndarray, params: Dict[str, jnp.ndarray]) -&gt; jnp.ndarray:\n    \"\"\"\n    Alias for SE(3) chain / odometry residual used in visualization.\n\n    This is a thin wrapper around :func:`odom_se3_residual`, so that\n    experiments and visualization code can refer to a semantically\n    descriptive name (\"se3_chain\") without duplicating logic.\n\n    :param x: Stacked pose vector ``[pose_i(6), pose_j(6)]``.\n    :type x: jnp.ndarray\n    :param params: Parameter dictionary containing ``\"measurement\"`` with\n        the desired relative pose in R^6.\n    :type params: Dict[str, jnp.ndarray]\n    :return: SE(3) chain residual produced by :func:`odom_se3_residual`.\n    :rtype: jnp.ndarray\n    \"\"\"\n    return odom_se3_residual(x, params)\n</code></pre>"},{"location":"api/slam/#slam.measurements.sigma_to_weight","title":"<code>sigma_to_weight(sigma)</code>","text":"<p>Convert standard deviation(s) to an information-style weight.</p> <p>For a scalar standard deviation <code>sigma</code>, this returns <code>1 / sigma**2</code>. For a vector of standard deviations, it returns the elementwise inverse-variance <code>1 / sigma[i]**2</code>.</p> <p>:param sigma: Scalar or vector of standard deviations. :type sigma: Union[float, jnp.ndarray] :return: Scalar or vector of weights <code>1 / sigma**2</code>. :rtype: jnp.ndarray</p> Source code in <code>dsg-jit/dsg_jit/slam/measurements.py</code> <pre><code>def sigma_to_weight(sigma):\n    \"\"\"\n    Convert standard deviation(s) to an information-style weight.\n\n    For a scalar standard deviation ``sigma``, this returns ``1 / sigma**2``.\n    For a vector of standard deviations, it returns the elementwise\n    inverse-variance ``1 / sigma[i]**2``.\n\n    :param sigma: Scalar or vector of standard deviations.\n    :type sigma: Union[float, jnp.ndarray]\n    :return: Scalar or vector of weights ``1 / sigma**2``.\n    :rtype: jnp.ndarray\n    \"\"\"\n    s = jnp.asarray(sigma)\n    return 1.0 / (s * s)\n</code></pre>"},{"location":"api/slam/#slam.measurements.voxel_point_observation_residual","title":"<code>voxel_point_observation_residual(x, params)</code>","text":"<p>Observation factor tying a voxel center to a world-frame point.</p> <p>Interprets <code>x</code> as <code>[voxel_center(3)]</code> and encourages it to match an observed point in world coordinates.</p> <p>:param x: State block containing a single voxel center. :type x: jnp.ndarray :param params: Parameter dictionary containing <code>\"point_world\"</code>     (a 3D point in the world frame). Any weighting is applied     upstream by :func:<code>_apply_weight</code>. :type params: dict :return: 3D residual <code>voxel_center - point_world</code>. :rtype: jnp.ndarray</p> Source code in <code>dsg-jit/dsg_jit/slam/measurements.py</code> <pre><code>def voxel_point_observation_residual(\n    x: jnp.ndarray,\n    params: dict,\n) -&gt; jnp.ndarray:\n    \"\"\"\n    Observation factor tying a voxel center to a world-frame point.\n\n    Interprets ``x`` as ``[voxel_center(3)]`` and encourages it to match\n    an observed point in world coordinates.\n\n    :param x: State block containing a single voxel center.\n    :type x: jnp.ndarray\n    :param params: Parameter dictionary containing ``\"point_world\"``\n        (a 3D point in the world frame). Any weighting is applied\n        upstream by :func:`_apply_weight`.\n    :type params: dict\n    :return: 3D residual ``voxel_center - point_world``.\n    :rtype: jnp.ndarray\n    \"\"\"\n    voxel = x[:3]\n    point_world = params[\"point_world\"]  # (3,)\n    return voxel - point_world\n</code></pre>"},{"location":"api/slam/#slam.measurements.voxel_smoothness_residual","title":"<code>voxel_smoothness_residual(x, params)</code>","text":"<p>Smoothness / grid regularity constraint between two voxel centers.</p> <p>Interprets <code>x</code> as <code>[voxel_i(3), voxel_j(3)]</code> and penalizes the deviation from an expected offset between neighboring voxels.</p> <p>:param x: Stacked state block <code>[voxel_i(3), voxel_j(3)]</code>. :type x: jnp.ndarray :param params: Parameter dictionary containing <code>\"offset\"</code> (a 3D     expected difference <code>voxel_j - voxel_i</code>) and optionally a     weight handled by :func:<code>_apply_weight</code>. :type params: dict :return: 3D residual <code>(voxel_j - voxel_i) - offset</code>. :rtype: jnp.ndarray</p> Source code in <code>dsg-jit/dsg_jit/slam/measurements.py</code> <pre><code>def voxel_smoothness_residual(\n    x: jnp.ndarray,\n    params: dict,\n) -&gt; jnp.ndarray:\n    \"\"\"\n    Smoothness / grid regularity constraint between two voxel centers.\n\n    Interprets ``x`` as ``[voxel_i(3), voxel_j(3)]`` and penalizes the\n    deviation from an expected offset between neighboring voxels.\n\n    :param x: Stacked state block ``[voxel_i(3), voxel_j(3)]``.\n    :type x: jnp.ndarray\n    :param params: Parameter dictionary containing ``\"offset\"`` (a 3D\n        expected difference ``voxel_j - voxel_i``) and optionally a\n        weight handled by :func:`_apply_weight`.\n    :type params: dict\n    :return: 3D residual ``(voxel_j - voxel_i) - offset``.\n    :rtype: jnp.ndarray\n    \"\"\"\n    voxel_i = x[:3]\n    voxel_j = x[3:6]\n\n    offset = params[\"offset\"]  # (3,)\n\n    residual = (voxel_j - voxel_i) - offset\n    return residual\n</code></pre>"},{"location":"api/slam/#slampipeline","title":"<code>slam.pipeline</code>","text":"<p>High-level SLAM pipelines built on top of DSG-JIT.</p> <p>This module provides small, composable helpers that glue together:</p> <ul> <li>WorldModel / SceneGraphWorld</li> <li>Sensors + SensorFusionManager</li> <li>FactorGraph + Gauss-Newton optimizer</li> </ul> <p>The intent is that experiments (or ROS2 nodes) call into these functions rather than reimplementing the same boilerplate in every file.</p>"},{"location":"api/slam/#slam.pipeline.PoseGraphResult","title":"<code>PoseGraphResult(x_opt, pose_ids, landmark_ids=None)</code>  <code>dataclass</code>","text":"<p>Result of a pose-graph SLAM solve.</p> <p>:param x_opt: Optimized stacked state vector. :type x_opt: jax.numpy.ndarray :param pose_ids: List of node ids corresponding to poses in the graph. :type pose_ids: list[int] :param landmark_ids: Optional list of landmark node ids, if present. :type landmark_ids: list[int] | None</p>"},{"location":"api/slam/#slam.pipeline.pose_vectors_from_result","title":"<code>pose_vectors_from_result(wm, result)</code>","text":"<p>Extract SE(3) pose vectors from an optimized solution.</p> <p>:param wm:     The world model that owns the variables. :type wm: world.model.WorldModel :param result:     Optimization result describing pose node ids and the stacked state. :type result: PoseGraphResult</p> <p>:return:     Mapping from pose node id -&gt; pose vector (6,). :rtype: dict[int, jax.numpy.ndarray]</p> Source code in <code>dsg-jit/dsg_jit/slam/pipeline.py</code> <pre><code>def pose_vectors_from_result(\n    wm: WorldModel,\n    result: PoseGraphResult,\n) -&gt; Dict[int, jnp.ndarray]:\n    \"\"\"\n    Extract SE(3) pose vectors from an optimized solution.\n\n    :param wm:\n        The world model that owns the variables.\n    :type wm: world.model.WorldModel\n    :param result:\n        Optimization result describing pose node ids and the stacked state.\n    :type result: PoseGraphResult\n\n    :return:\n        Mapping from pose node id -&gt; pose vector (6,).\n    :rtype: dict[int, jax.numpy.ndarray]\n    \"\"\"\n    x_opt = result.x_opt\n    _, index = wm.pack_state()\n\n    out: Dict[int, jnp.ndarray] = {}\n    for nid in result.pose_ids:\n        sl = index[nid]\n        out[nid] = x_opt[sl]\n    return out\n</code></pre>"},{"location":"api/slam/#slam.pipeline.run_pose_graph_slam","title":"<code>run_pose_graph_slam(wm, cfg=None)</code>","text":"<p>Run Gauss-Newton on the pose/landmark graph in <code>wm.fg</code>.</p> <p>This treats whatever is currently in the WorldModel's factor graph as the SLAM problem. It does not modify <code>wm</code> in-place; it returns the optimized stacked state and helper lists for extracting poses/landmarks.</p> <p>Typical usage:</p> <p>.. code-block:: python</p> <pre><code>result = run_pose_graph_slam(wm)\nposes = [result.x_opt[index[nid]] for nid in result.pose_ids]\n</code></pre> <p>:param wm:     The world model containing a FactorGraph with SE(3) pose variables     (and optionally landmark variables) plus factors (odom, priors,     range/bearing, etc.). :type wm: world.model.WorldModel :param cfg:     Configuration for the Gauss-Newton solver. If <code>None</code>, a default     <code>GNConfig</code> is used. :type cfg: core.types.GNConfig | None</p> <p>:return:     A :class:<code>PoseGraphResult</code> containing the optimized stacked state     vector and node-id lists for poses and landmarks. :rtype: PoseGraphResult</p> Source code in <code>dsg-jit/dsg_jit/slam/pipeline.py</code> <pre><code>def run_pose_graph_slam(\n    wm: WorldModel,\n    cfg: GNConfig | None = None,\n) -&gt; PoseGraphResult:\n    \"\"\"\n    Run Gauss-Newton on the pose/landmark graph in ``wm.fg``.\n\n    This treats whatever is currently in the WorldModel's factor graph as\n    the SLAM problem. It does not modify ``wm`` in-place; it returns the\n    optimized stacked state and helper lists for extracting poses/landmarks.\n\n    Typical usage:\n\n    .. code-block:: python\n\n        result = run_pose_graph_slam(wm)\n        poses = [result.x_opt[index[nid]] for nid in result.pose_ids]\n\n    :param wm:\n        The world model containing a FactorGraph with SE(3) pose variables\n        (and optionally landmark variables) plus factors (odom, priors,\n        range/bearing, etc.).\n    :type wm: world.model.WorldModel\n    :param cfg:\n        Configuration for the Gauss-Newton solver. If ``None``, a default\n        ``GNConfig`` is used.\n    :type cfg: core.types.GNConfig | None\n\n    :return:\n        A :class:`PoseGraphResult` containing the optimized stacked state\n        vector and node-id lists for poses and landmarks.\n    :rtype: PoseGraphResult\n    \"\"\"\n    if cfg is None:\n        cfg = GNConfig()\n\n    fg: FactorGraph = wm.fg\n\n    # Pack initial state\n    x0, _ = wm.pack_state()\n    residual_fn = wm.build_residual()\n\n    # Manifold types: we already stored these per-variable in the graph.\n    manifold_types = build_manifold_metadata(packed_state=wm.pack_state(),fg=fg)\n\n\n\n    # Solve\n    x_opt = gauss_newton_manifold(\n        residual_fn,\n        x0,\n        manifold_types,\n        cfg,\n    )\n\n    # Build convenience lists for poses / landmarks.\n    pose_ids: List[int] = []\n    landmark_ids: List[int] = []\n\n    for nid, v in wm.fg.variables.items():\n        if v.manifold == \"se3\":\n            pose_ids.append(nid)\n        elif v.manifold == \"R3\":\n            landmark_ids.append(nid)\n\n    return PoseGraphResult(\n        x_opt=x_opt,\n        pose_ids=sorted(pose_ids),\n        landmark_ids=sorted(landmark_ids) if landmark_ids else None,\n    )\n</code></pre>"},{"location":"api/slam/#slam.pipeline.update_worldmodel_from_solution","title":"<code>update_worldmodel_from_solution(wm, result)</code>","text":"<p>Write optimized variables from a :class:<code>PoseGraphResult</code> back into <code>wm</code>.</p> <p>This is a small helper so that downstream code (DSG construction, visualization, dataset export) can reflect the optimized state.</p> <p>:param wm:     The world model whose factor-graph variables will be updated in-place. :type wm: world.model.WorldModel :param result:     Output from :func:<code>run_pose_graph_slam</code>, containing the optimized     stacked state vector. :type result: PoseGraphResult</p> Source code in <code>dsg-jit/dsg_jit/slam/pipeline.py</code> <pre><code>def update_worldmodel_from_solution(wm: WorldModel, result: PoseGraphResult) -&gt; None:\n    \"\"\"\n    Write optimized variables from a :class:`PoseGraphResult` back into ``wm``.\n\n    This is a small helper so that downstream code (DSG construction,\n    visualization, dataset export) can reflect the optimized state.\n\n    :param wm:\n        The world model whose factor-graph variables will be updated in-place.\n    :type wm: world.model.WorldModel\n    :param result:\n        Output from :func:`run_pose_graph_slam`, containing the optimized\n        stacked state vector.\n    :type result: PoseGraphResult\n    \"\"\"\n    fg = wm.fg\n    x_opt = result.x_opt\n    _, index = wm.pack_state()  # re-pack to get consistent slices\n\n    for nid, sl in index.items():\n        v = fg.variables[nid]\n        v.value = x_opt[sl]\n</code></pre>"},{"location":"api/slam/#slam.pipeline.visualize_pose_graph_3d","title":"<code>visualize_pose_graph_3d(wm, title=None)</code>","text":"<p>Convenience helper to plot the current factor graph in 3D.</p> <p>This simply calls :func:<code>world.visualization.plot_factor_graph_3d</code> with the world's underlying :class:<code>FactorGraph</code>.</p> <p>:param wm:     World model whose factor graph will be visualized. :type wm: world.model.WorldModel :param title:     Optional plot title. :type title: str | None</p> Source code in <code>dsg-jit/dsg_jit/slam/pipeline.py</code> <pre><code>def visualize_pose_graph_3d(\n    wm: WorldModel,\n    title: str | None = None,\n) -&gt; None:\n    \"\"\"\n    Convenience helper to plot the current factor graph in 3D.\n\n    This simply calls :func:`world.visualization.plot_factor_graph_3d`\n    with the world's underlying :class:`FactorGraph`.\n\n    :param wm:\n        World model whose factor graph will be visualized.\n    :type wm: world.model.WorldModel\n    :param title:\n        Optional plot title.\n    :type title: str | None\n    \"\"\"\n    plot_factor_graph_3d(wm.fg)\n</code></pre>"},{"location":"api/world/","title":"World Model Modules","text":"<p>This section documents the high-level world model, scene-graph integration, voxel grid management, and training utilities.</p>"},{"location":"api/world/#worldmodel","title":"<code>world.model</code>","text":"<p>World-level wrapper and optimization front-end around the core factor graph.</p> <p>This module defines the world model abstraction: a typed layer on top of <code>core.factor_graph.FactorGraph</code> that understands high-level entities (poses, places, rooms, voxels, objects, agents) and also centralizes residual construction, JIT compilation, and solver orchestration.</p> <p>In other words, :class:<code>WorldModel</code> is the bridge between:</p> <pre><code>\u2022 Low-level optimization (factor graph, residual functions, manifolds)\n\u2022 High-level scene graph abstractions (poses, agents, rooms, voxels)\n\u2022 Application code that wants a simple, stable API for \"optimize my world\"\n</code></pre> <p>The underlying :class:<code>FactorGraph</code> remains a relatively small, generic data structure that stores variables and factors and knows nothing about JAX, JIT, or manifolds. All JAX-specific logic (residual registries, vmap-based batching, Gauss\u2013Newton wrappers, etc.) is owned by the world model.</p>"},{"location":"api/world/#world.model--key-responsibilities","title":"Key responsibilities","text":"<ul> <li>Manage the underlying :class:<code>FactorGraph</code> instance.</li> <li>Provide ergonomic helpers to:     \u2022 Add variables with automatically assigned :class:<code>NodeId</code>s.     \u2022 Add typed factors (e.g. priors, odometry, attachments, voxel terms).     \u2022 Pack / unpack state vectors for optimization.</li> <li>Maintain simple bookkeeping structures (e.g. maps from user-facing   handles / indices back to :class:<code>NodeId</code>s) so that experiments and   higher-level layers do not need to manipulate :class:<code>NodeId</code> directly.</li> <li>Maintain a residual-function registry that maps factor-type strings   (e.g. <code>\"odom_se3\"</code>, <code>\"voxel_point_obs\"</code>) to JAX-compatible   residuals.</li> <li>Build unified, vmap-optimized residual and objective functions on   demand, caching compiled versions keyed by graph structure.</li> <li>Expose convenient optimization entry points (e.g. :meth:<code>optimize</code>,   or :class:<code>optimization.jit_wrappers.JittedGN</code>) that operate directly   on the world model.</li> </ul>"},{"location":"api/world/#world.model--typical-usage","title":"Typical usage","text":"<p>Experiments and higher layers typically:</p> <pre><code>1. Construct a :class:`WorldModel`.\n2. Add variables &amp; factors according to a scenario.\n3. Register residual functions for each factor type of interest.\n4. Build a residual or objective from the world model and call into\n   :mod:`dsg_jit.optimization.solvers` or :mod:`dsg_jit.optimization.jit_wrappers`\n   to run Gauss\u2013Newton (potentially manifold-aware) or gradient-based\n   optimization.\n5. Decode and interpret the optimized state via the world model\u2019s\n   convenience accessors, or export it to higher-level scene-graph\n   structures.\n</code></pre>"},{"location":"api/world/#world.model--design-goals","title":"Design goals","text":"<ul> <li>Backend separation: keep :class:<code>FactorGraph</code> as a minimal,   backend-agnostic data structure (variables, factors, connectivity),   while :class:<code>WorldModel</code> owns JAX-facing logic such as residual   construction, vmap batching, and JIT caching.</li> <li>Scene-friendly: provide enough structure that scene graphs, voxel   modules, and DSG layers can build on top of the world model without   duplicating graph or optimization logic.</li> <li>Ergonomic but explicit: favor simple, explicit methods   (<code>add_variable</code>, <code>add_factor</code>, <code>register_residual</code>, <code>optimize</code>)   over hidden magic, so that experiments remain easy to debug and extend.</li> </ul>"},{"location":"api/world/#world.model.ActiveWindowTemplate","title":"<code>ActiveWindowTemplate(variable_slots, factor_slots)</code>  <code>dataclass</code>","text":"<p>Defines a fixed-capacity active factor graph template for JIT-stable operation. Each variable/factor slot is identified by (type, slot_idx).</p>"},{"location":"api/world/#world.model.FactorSlot","title":"<code>FactorSlot(factor_type, slot_idx, factor_id, var_slot_keys)</code>  <code>dataclass</code>","text":"<p>Bookkeeping for a factor slot in the active template.</p>"},{"location":"api/world/#world.model.VarSlot","title":"<code>VarSlot(var_type, slot_idx, node_id, dim)</code>  <code>dataclass</code>","text":"<p>Bookkeeping for a variable slot in the active template.</p>"},{"location":"api/world/#world.model.WorldModel","title":"<code>WorldModel()</code>  <code>dataclass</code>","text":"<p>High-level world model built on top of :class:<code>FactorGraph</code>.</p> Modes <ul> <li>Dynamic/unbounded FG (legacy, research mode): Variables and factors can be added/removed dynamically.</li> <li>Fixed-capacity active template (real-time / JIT-stable mode): A fixed set of variable/factor slots is preallocated for JIT-compatibility and in-place updates.</li> </ul> <p>In addition to wrapping the core factor graph, this class keeps simple bookkeeping dictionaries that make it easier to build static and dynamic scene graphs on top of DSG-JIT. These maps are deliberately lightweight and optional: if you never pass a name when adding variables, the underlying optimization behavior is unchanged.</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def __init__(self) -&gt; None:\n    # Core factor graph\n    self.fg = FactorGraph()\n    # Semantic maps; these are purely for convenience and do not affect\n    # the underlying optimization.\n    self.pose_ids = {}\n    self.room_ids = {}\n    self.place_ids = {}\n    self.object_ids = {}\n    # Mapping: agent_id -&gt; {timestep -&gt; NodeId}\n    self.agent_pose_ids = {}\n    # Residual Registry\n    self._residual_registry: Dict[str, ResidualFn] = {}\n    self._compiled_solvers: Dict[Tuple[str, str], Any] = {}\n    # Active window template fields (for slot-based mode)\n    self._active_template: Optional[ActiveWindowTemplate] = None\n    self._var_slots: Dict[Tuple[str, int], VarSlot] = {}\n    self._factor_slots: Dict[Tuple[str, int], FactorSlot] = {}\n    self._active_factor_mask: Dict[FactorId, bool] = {}\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.add_agent_pose","title":"<code>add_agent_pose(agent_id, t, value, var_type='pose')</code>","text":"<p>Add (and register) a pose for a particular agent at a timestep.</p> <p>This convenience helper is meant for dynamic scene graphs where you track multiple agents over time. It simply delegates to :meth:<code>add_variable</code> and then records the mapping <code>(agent_id, t)</code>.</p> <p>:param agent_id: String identifier for the agent (e.g. <code>\"robot_0\"</code>). :param t: Discrete timestep index. :param value: Initial pose value for this agent at time <code>t</code>. :param var_type: Underlying variable type to use (defaults to     <code>\"pose\"</code>; you can change this to <code>\"pose_se3\"</code> in advanced     use-cases). :returns: The :class:<code>NodeId</code> of the new agent pose variable.</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def add_agent_pose(\n    self,\n    agent_id: str,\n    t: int,\n    value: jnp.ndarray,\n    var_type: str = \"pose\",\n) -&gt; NodeId:\n    \"\"\"Add (and register) a pose for a particular agent at a timestep.\n\n    This convenience helper is meant for dynamic scene graphs where you\n    track multiple agents over time. It simply delegates to\n    :meth:`add_variable` and then records the mapping ``(agent_id, t)``.\n\n    :param agent_id: String identifier for the agent (e.g. ``\"robot_0\"``).\n    :param t: Discrete timestep index.\n    :param value: Initial pose value for this agent at time ``t``.\n    :param var_type: Underlying variable type to use (defaults to\n        ``\"pose\"``; you can change this to ``\"pose_se3\"`` in advanced\n        use-cases).\n    :returns: The :class:`NodeId` of the new agent pose variable.\n    \"\"\"\n    nid = self.add_variable(var_type, value)\n    if agent_id not in self.agent_pose_ids:\n        self.agent_pose_ids[agent_id] = {}\n    self.agent_pose_ids[agent_id][t] = nid\n    return nid\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.add_camera_bearings","title":"<code>add_camera_bearings(pose_id, landmark_ids, bearings, weight=None, factor_type='pose_landmark_bearing')</code>","text":"<p>Add one or more camera bearing factors for a single pose.</p> <p>This is a thin convenience wrapper for camera-like measurements that observe known landmarks via bearing (direction) only. It assumes that the underlying factor type is implemented by a residual such as :func:<code>slam.measurements.pose_landmark_bearing_residual</code>.</p> <p>Each row of :param:<code>bearings</code> is expected to correspond to one landmark in :param:<code>landmark_ids</code>. The dimensionality (e.g. 2D angle or 3D unit vector) is left to the residual function.</p> <p>:param pose_id: Identifier of the pose variable from which all     bearings are taken. :param landmark_ids: List of landmark node identifiers, one per row     in <code>bearings</code>. :param bearings: Array of shape <code>(N, D)</code> containing bearing     measurements in the sensor or camera frame. :param weight: Optional scalar weight or inverse noise level applied     uniformly to all bearings in this call. If <code>None</code>, the default     inside the residual is used. :param factor_type: Factor type string to register in the underlying     :class:<code>FactorGraph</code>. Defaults to <code>\"pose_landmark_bearing\"</code>. :returns: The :class:<code>FactorId</code> of the last factor added. One factor     is added per (pose, landmark) pair.</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def add_camera_bearings(\n    self,\n    pose_id: NodeId,\n    landmark_ids: list[NodeId],\n    bearings: jnp.ndarray,\n    weight: float | None = None,\n    factor_type: str = \"pose_landmark_bearing\",\n) -&gt; FactorId:\n    \"\"\"Add one or more camera bearing factors for a single pose.\n\n    This is a thin convenience wrapper for camera-like measurements that\n    observe known landmarks via bearing (direction) only. It assumes that\n    the underlying factor type is implemented by a residual such as\n    :func:`slam.measurements.pose_landmark_bearing_residual`.\n\n    Each row of :param:`bearings` is expected to correspond to one\n    landmark in :param:`landmark_ids`. The dimensionality (e.g. 2D angle\n    or 3D unit vector) is left to the residual function.\n\n    :param pose_id: Identifier of the pose variable from which all\n        bearings are taken.\n    :param landmark_ids: List of landmark node identifiers, one per row\n        in ``bearings``.\n    :param bearings: Array of shape ``(N, D)`` containing bearing\n        measurements in the sensor or camera frame.\n    :param weight: Optional scalar weight or inverse noise level applied\n        uniformly to all bearings in this call. If ``None``, the default\n        inside the residual is used.\n    :param factor_type: Factor type string to register in the underlying\n        :class:`FactorGraph`. Defaults to ``\"pose_landmark_bearing\"``.\n    :returns: The :class:`FactorId` of the last factor added. One factor\n        is added per (pose, landmark) pair.\n    \"\"\"\n    if bearings.shape[0] != len(landmark_ids):\n        raise ValueError(\n            \"add_camera_bearings expected len(landmark_ids) == bearings.shape[0], \"\n            f\"got {len(landmark_ids)} vs {bearings.shape[0]}\"\n        )\n\n    last_fid: FactorId | None = None\n    for lm_id, b in zip(landmark_ids, bearings):\n        params: Dict[str, object] = {\"bearing\": jnp.asarray(b)}\n        if weight is not None:\n            params[\"weight\"] = float(weight)\n        last_fid = self.add_factor(factor_type, [pose_id, lm_id], params)\n\n    # mypy/linters: last_fid will never be None if bearings is non-empty.\n    if last_fid is None:\n        raise ValueError(\"add_camera_bearings called with empty bearings array.\")\n    return last_fid\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.add_factor","title":"<code>add_factor(f_type, var_ids, params)</code>","text":"<p>Add a new factor to the underlying factor graph.</p> <p>This allocates a fresh :class:<code>FactorId</code>, normalizes the input variable identifiers to :class:<code>NodeId</code> instances, constructs a :class:<code>core.types.Factor</code>, and registers it in :attr:<code>fg</code>.</p> <p>:param f_type: String identifying the factor type. This must match a     key in :attr:<code>FactorGraph.residual_fns</code> so that the appropriate     residual function can be looked up during optimization. :param var_ids: Iterable of variable identifiers (ints or     :class:<code>NodeId</code> instances) that this factor connects. :param params: Dictionary of factor parameters passed through to the     residual function (e.g. measurements, noise models, weights). :returns: The :class:<code>FactorId</code> of the newly added factor.</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def add_factor(self, f_type: str, var_ids, params: Dict) -&gt; FactorId:\n    \"\"\"Add a new factor to the underlying factor graph.\n\n    This allocates a fresh :class:`FactorId`, normalizes the input\n    variable identifiers to :class:`NodeId` instances, constructs a\n    :class:`core.types.Factor`, and registers it in :attr:`fg`.\n\n    :param f_type: String identifying the factor type. This must match a\n        key in :attr:`FactorGraph.residual_fns` so that the appropriate\n        residual function can be looked up during optimization.\n    :param var_ids: Iterable of variable identifiers (ints or\n        :class:`NodeId` instances) that this factor connects.\n    :param params: Dictionary of factor parameters passed through to the\n        residual function (e.g. measurements, noise models, weights).\n    :returns: The :class:`FactorId` of the newly added factor.\n    \"\"\"\n    # Allocate a fresh FactorId. We cannot rely on len(self.fg.factors)\n    # when factors may have been removed (e.g. after marginalization),\n    # so we take the maximum existing id and add one.\n    if self.fg.factors:\n        max_existing_id = max(int(fid) for fid in self.fg.factors.keys())\n        fid_int = max_existing_id + 1\n    else:\n        fid_int = 0\n    fid = FactorId(fid_int)\n\n    # Normalize everything to NodeId\n    node_ids = tuple(NodeId(int(vid)) for vid in var_ids)\n\n    f = Factor(\n        id=fid,\n        type=f_type,\n        var_ids=node_ids,\n        params=params,\n    )\n    self.fg.add_factor(f)\n    # Adding a factor changes the factor graph structure; clear cached\n    # compiled solvers / residuals so they can be rebuilt consistently.\n    return fid\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.add_imu_preintegration_factor","title":"<code>add_imu_preintegration_factor(pose_i, pose_j, delta, weight=None, factor_type='pose_imu_preintegration')</code>","text":"<p>Add an IMU preintegration-style factor between two poses.</p> <p>This is intended to work with a preintegrated IMU summary (e.g. as produced by :mod:<code>sensors.imu</code>), where <code>delta</code> contains fields such as <code>\"dR\"</code>, <code>\"dv\"</code>, <code>\"dp\"</code>, and corresponding covariance or information terms.</p> <p>The exact keys expected in <code>delta</code> are left to the residual implementation for <code>factor_type</code>, but by storing the dictionary unchanged in <code>params[\"delta\"]</code> we keep this interface flexible.</p> <p>:param pose_i: NodeId of the starting pose (time :math:<code>t_k</code>). :param pose_j: NodeId of the ending pose (time :math:<code>t_{k+1}</code>). :param delta: Dictionary describing the preintegrated IMU increment     between <code>pose_i</code> and <code>pose_j</code>. All arrays should be JAX     arrays or types convertible via :func:<code>jax.numpy.asarray</code>. :param weight: Optional scalar weight / scaling to apply to the IMU     factor inside the residual. :param factor_type: Factor type string to register; by default this is     <code>\"pose_imu_preintegration\"</code>. :returns: The :class:<code>FactorId</code> of the created IMU factor.</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def add_imu_preintegration_factor(\n    self,\n    pose_i: NodeId,\n    pose_j: NodeId,\n    delta: Dict[str, jnp.ndarray],\n    weight: float | None = None,\n    factor_type: str = \"pose_imu_preintegration\",\n) -&gt; FactorId:\n    \"\"\"Add an IMU preintegration-style factor between two poses.\n\n    This is intended to work with a preintegrated IMU summary (e.g. as\n    produced by :mod:`sensors.imu`), where ``delta`` contains fields such\n    as ``\"dR\"``, ``\"dv\"``, ``\"dp\"``, and corresponding covariance or\n    information terms.\n\n    The exact keys expected in ``delta`` are left to the residual\n    implementation for ``factor_type``, but by storing the dictionary\n    unchanged in ``params[\"delta\"]`` we keep this interface flexible.\n\n    :param pose_i: NodeId of the starting pose (time :math:`t_k`).\n    :param pose_j: NodeId of the ending pose (time :math:`t_{k+1}`).\n    :param delta: Dictionary describing the preintegrated IMU increment\n        between ``pose_i`` and ``pose_j``. All arrays should be JAX\n        arrays or types convertible via :func:`jax.numpy.asarray`.\n    :param weight: Optional scalar weight / scaling to apply to the IMU\n        factor inside the residual.\n    :param factor_type: Factor type string to register; by default this is\n        ``\"pose_imu_preintegration\"``.\n    :returns: The :class:`FactorId` of the created IMU factor.\n    \"\"\"\n    params: Dict[str, object] = {\"delta\": {k: jnp.asarray(v) for k, v in delta.items()}}\n    if weight is not None:\n        params[\"weight\"] = float(weight)\n    return self.add_factor(factor_type, [pose_i, pose_j], params)\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.add_lidar_ranges","title":"<code>add_lidar_ranges(pose_id, landmark_ids, ranges, directions=None, weight=None, factor_type='pose_lidar_range')</code>","text":"<p>Add LiDAR-style range factors for a single pose.</p> <p>This helper is intended for simple range-only or range-with-direction measurements to known landmarks, coming from a LiDAR or depth sensor.</p> <p>The interpretation of <code>directions</code> depends on the chosen residual implementation, but a common convention is that each row is a unit vector in the sensor frame pointing toward the target.</p> <p>:param pose_id: Identifier of the pose variable from which ranges     are measured. :param landmark_ids: List of landmark node identifiers, one per range     sample. :param ranges: Array of shape <code>(N,)</code> holding range values in meters. :param directions: Optional array of shape <code>(N, 3)</code> with unit     direction vectors associated with each range measurement. :param weight: Optional scalar weight applied to all range factors. :param factor_type: Factor type string to register; by default this is     <code>\"pose_lidar_range\"</code>. The residual function for this type is     expected to consume <code>\"range\"</code> and optionally <code>\"direction\"</code> in     <code>params</code>. :returns: The :class:<code>FactorId</code> of the last factor added.</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def add_lidar_ranges(\n    self,\n    pose_id: NodeId,\n    landmark_ids: list[NodeId],\n    ranges: jnp.ndarray,\n    directions: Optional[jnp.ndarray] = None,\n    weight: float | None = None,\n    factor_type: str = \"pose_lidar_range\",\n) -&gt; FactorId:\n    \"\"\"Add LiDAR-style range factors for a single pose.\n\n    This helper is intended for simple range-only or range-with-direction\n    measurements to known landmarks, coming from a LiDAR or depth sensor.\n\n    The interpretation of ``directions`` depends on the chosen residual\n    implementation, but a common convention is that each row is a unit\n    vector in the sensor frame pointing toward the target.\n\n    :param pose_id: Identifier of the pose variable from which ranges\n        are measured.\n    :param landmark_ids: List of landmark node identifiers, one per range\n        sample.\n    :param ranges: Array of shape ``(N,)`` holding range values in meters.\n    :param directions: Optional array of shape ``(N, 3)`` with unit\n        direction vectors associated with each range measurement.\n    :param weight: Optional scalar weight applied to all range factors.\n    :param factor_type: Factor type string to register; by default this is\n        ``\"pose_lidar_range\"``. The residual function for this type is\n        expected to consume ``\"range\"`` and optionally ``\"direction\"`` in\n        ``params``.\n    :returns: The :class:`FactorId` of the last factor added.\n    \"\"\"\n    if ranges.shape[0] != len(landmark_ids):\n        raise ValueError(\n            \"add_lidar_ranges expected len(landmark_ids) == ranges.shape[0], \"\n            f\"got {len(landmark_ids)} vs {ranges.shape[0]}\"\n        )\n    if directions is not None and directions.shape[0] != ranges.shape[0]:\n        raise ValueError(\n            \"add_lidar_ranges expected directions.shape[0] == ranges.shape[0], \"\n            f\"got {directions.shape[0]} vs {ranges.shape[0]}\"\n        )\n\n    last_fid: FactorId | None = None\n    for i, lm_id in enumerate(landmark_ids):\n        params: Dict[str, object] = {\"range\": float(ranges[i])}\n        if directions is not None:\n            params[\"direction\"] = jnp.asarray(directions[i])\n        if weight is not None:\n            params[\"weight\"] = float(weight)\n        last_fid = self.add_factor(factor_type, [pose_id, lm_id], params)\n\n    if last_fid is None:\n        raise ValueError(\"add_lidar_ranges called with empty ranges array.\")\n    return last_fid\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.add_object","title":"<code>add_object(center, name=None)</code>","text":"<p>Add an object centroid variable (3D point).</p> <p>:param center: 3D position of the object centroid. :param name: Optional semantic name to register in :attr:<code>object_ids</code>. :returns: The :class:<code>NodeId</code> of the new object variable.</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def add_object(self, center: jnp.ndarray, name: Optional[str] = None) -&gt; NodeId:\n    \"\"\"Add an object centroid variable (3D point).\n\n    :param center: 3D position of the object centroid.\n    :param name: Optional semantic name to register in :attr:`object_ids`.\n    :returns: The :class:`NodeId` of the new object variable.\n    \"\"\"\n    nid = self.add_variable(\"object\", center)\n    if name is not None:\n        self.object_ids[name] = nid\n    return nid\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.add_place","title":"<code>add_place(center, name=None)</code>","text":"<p>Add a place / waypoint variable (3D point).</p> <p>:param center: 3D position of the place/waypoint. :param name: Optional semantic name to register in :attr:<code>place_ids</code>. :returns: The :class:<code>NodeId</code> of the new place variable.</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def add_place(self, center: jnp.ndarray, name: Optional[str] = None) -&gt; NodeId:\n    \"\"\"Add a place / waypoint variable (3D point).\n\n    :param center: 3D position of the place/waypoint.\n    :param name: Optional semantic name to register in :attr:`place_ids`.\n    :returns: The :class:`NodeId` of the new place variable.\n    \"\"\"\n    nid = self.add_variable(\"place\", center)\n    if name is not None:\n        self.place_ids[name] = nid\n    return nid\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.add_pose","title":"<code>add_pose(value, name=None)</code>","text":"<p>Add an SE(3) pose variable.</p> <p>This is a thin wrapper around :meth:<code>add_variable</code>. If <code>name</code> is provided, the pose is also registered in :attr:<code>pose_ids</code>, which can be useful for scene-graph style code that wants stable, human-readable handles.</p> <p>:param value: Initial pose value, typically a 6D se(3) vector. :param name: Optional semantic name used as a key in :attr:<code>pose_ids</code>. :returns: The :class:<code>NodeId</code> of the newly created pose variable.</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def add_pose(self, value: jnp.ndarray, name: Optional[str] = None) -&gt; NodeId:\n    \"\"\"Add an SE(3) pose variable.\n\n    This is a thin wrapper around :meth:`add_variable`. If ``name`` is\n    provided, the pose is also registered in :attr:`pose_ids`, which can\n    be useful for scene-graph style code that wants stable, human-readable\n    handles.\n\n    :param value: Initial pose value, typically a 6D se(3) vector.\n    :param name: Optional semantic name used as a key in :attr:`pose_ids`.\n    :returns: The :class:`NodeId` of the newly created pose variable.\n    \"\"\"\n    nid = self.add_variable(\"pose\", value)\n    if name is not None:\n        self.pose_ids[name] = nid\n    return nid\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.add_room","title":"<code>add_room(center, name=None)</code>","text":"<p>Add a room center variable (3D point).</p> <p>:param center: 3D position of the room center. :param name: Optional semantic name to register in :attr:<code>room_ids</code>. :returns: The :class:<code>NodeId</code> of the new room variable.</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def add_room(self, center: jnp.ndarray, name: Optional[str] = None) -&gt; NodeId:\n    \"\"\"Add a room center variable (3D point).\n\n    :param center: 3D position of the room center.\n    :param name: Optional semantic name to register in :attr:`room_ids`.\n    :returns: The :class:`NodeId` of the new room variable.\n    \"\"\"\n    nid = self.add_variable(\"room\", center)\n    if name is not None:\n        self.room_ids[name] = nid\n    return nid\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.add_variable","title":"<code>add_variable(var_type, value)</code>","text":"<p>Add a new variable to the underlying factor graph.</p> <p>This allocates a fresh :class:<code>NodeId</code>, constructs a :class:<code>core.types.Variable</code> with the given type and initial value, registers it in :attr:<code>fg</code>, and returns the newly created id.</p> <p>:param var_type: String describing the variable type (e.g. <code>\"pose\"</code>,     <code>\"room\"</code>, <code>\"place\"</code>, <code>\"object\"</code>). This is used by     residual functions and manifold metadata to interpret the state. :param value: Initial value for the variable, represented as a     1D JAX array. The dimensionality is inferred from     <code>value.shape[0]</code>. :returns: The :class:<code>NodeId</code> of the newly added variable.</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def add_variable(self, var_type: str, value: jnp.ndarray) -&gt; NodeId:\n    \"\"\"Add a new variable to the underlying factor graph.\n\n    This allocates a fresh :class:`NodeId`, constructs a\n    :class:`core.types.Variable` with the given type and initial value,\n    registers it in :attr:`fg`, and returns the newly created id.\n\n    :param var_type: String describing the variable type (e.g. ``\"pose\"``,\n        ``\"room\"``, ``\"place\"``, ``\"object\"``). This is used by\n        residual functions and manifold metadata to interpret the state.\n    :param value: Initial value for the variable, represented as a\n        1D JAX array. The dimensionality is inferred from\n        ``value.shape[0]``.\n    :returns: The :class:`NodeId` of the newly added variable.\n    \"\"\"\n    # Allocate a fresh NodeId. We cannot rely on len(self.fg.variables)\n    # when variables may have been removed (e.g. after marginalization),\n    # so we take the maximum existing id and add one.\n    if self.fg.variables:\n        max_existing_id = max(int(nid) for nid in self.fg.variables.keys())\n        nid_int = max_existing_id + 1\n    else:\n        nid_int = 0\n    nid = NodeId(nid_int)\n    v = Variable(id=nid, type=var_type, value=value)\n    self.fg.add_variable(v)\n    # Graph structure has changed; clear any cached compiled solvers\n    # and residuals so they can be rebuilt on demand.\n    return nid\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.build_objective","title":"<code>build_objective()</code>","text":"<p>Construct a scalar objective <code>f(x) = ||r(x)||^2</code>.</p> <p>This wraps :meth:<code>build_residual</code> and returns a function that computes the squared L2 norm of the residual vector.</p> <p>:return: JIT-compiled objective function <code>f(x)</code>. :rtype: Callable[[jnp.ndarray], jnp.ndarray]</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def build_objective(self):\n    \"\"\"Construct a scalar objective ``f(x) = ||r(x)||^2``.\n\n    This wraps :meth:`build_residual` and returns a function\n    that computes the squared L2 norm of the residual vector.\n\n    :return: JIT-compiled objective function ``f(x)``.\n    :rtype: Callable[[jnp.ndarray], jnp.ndarray]\n    \"\"\"\n    residual = self.build_residual()\n\n    def objective(x: jnp.ndarray) -&gt; jnp.ndarray:\n        r = residual(x)\n        return jnp.sum(r ** 2)\n\n    return jax.jit(objective)\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.build_residual","title":"<code>build_residual(*, use_type_weights=False, learn_odom=False, learn_voxel_points=False)</code>","text":"<p>Construct a unified residual function for the current world.</p> <p>This method is the WorldModel-level entry point for building a JAX-compatible residual function that stacks all factor residuals. It is intended to subsume the various specialized builders that previously lived on :class:<code>FactorGraph</code>, such as:</p> <ul> <li><code>build_residual_function_with_type_weights</code></li> <li><code>build_residual_function_se3_odom_param_multi</code></li> <li><code>build_residual_function_voxel_point_param[_multi]</code></li> </ul> <p>Instead of having separate entry points, this method exposes a single interface whose behavior is controlled by configuration flags and a structured \"hyper-parameter\" argument passed at call time.</p>"},{"location":"api/world/#world.model.WorldModel.build_residual--parameters","title":"Parameters","text":"<p>use_type_weights : bool, optional     Currently unused in this implementation. Reserved for future     integration with type-weighted residuals. learn_odom : bool, optional     Currently unused in this implementation. Reserved for future     integration with learnable odometry parameters. learn_voxel_points : bool, optional     Currently unused in this implementation. Reserved for future     integration with learnable voxel observation points.</p>"},{"location":"api/world/#world.model.WorldModel.build_residual--returns","title":"Returns","text":"<p>callable     A JAX-compatible residual function. In the simplest case     (all flags <code>False</code>) the signature is <code>r(x)</code> where <code>x</code> is     a packed state vector.</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def build_residual(\n    self,\n    *,\n    use_type_weights: bool = False,\n    learn_odom: bool = False,\n    learn_voxel_points: bool = False,\n) -&gt; Callable[..., Any]:\n    \"\"\"Construct a unified residual function for the current world.\n\n    This method is the WorldModel-level entry point for building a\n    JAX-compatible residual function that stacks all factor residuals.\n    It is intended to subsume the various specialized builders that\n    previously lived on :class:`FactorGraph`, such as:\n\n    * ``build_residual_function_with_type_weights``\n    * ``build_residual_function_se3_odom_param_multi``\n    * ``build_residual_function_voxel_point_param[_multi]``\n\n    Instead of having separate entry points, this method exposes a\n    single interface whose behavior is controlled by configuration\n    flags and a structured \"hyper-parameter\" argument passed at call\n    time.\n\n    Parameters\n    ----------\n    use_type_weights : bool, optional\n        Currently unused in this implementation. Reserved for future\n        integration with type-weighted residuals.\n    learn_odom : bool, optional\n        Currently unused in this implementation. Reserved for future\n        integration with learnable odometry parameters.\n    learn_voxel_points : bool, optional\n        Currently unused in this implementation. Reserved for future\n        integration with learnable voxel observation points.\n\n    Returns\n    -------\n    callable\n        A JAX-compatible residual function. In the simplest case\n        (all flags ``False``) the signature is ``r(x)`` where ``x`` is\n        a packed state vector.\n    \"\"\"\n    # NOTE: For now, the configuration flags are accepted but not yet\n    # wired into the implementation. They are kept in the signature to\n    # preserve the planned API surface and avoid breaking callers.\n    if use_type_weights or learn_odom or learn_voxel_points:\n        raise NotImplementedError(\n            \"Hyper-parameterized residuals are provided by dedicated \"\n            \"WorldModel helper methods (e.g. \"\n            \"build_residual_function_with_type_weights, \"\n            \"build_residual_function_se3_odom_param_multi). \"\n            \"The generic build_residual hyper-parameter flags are not \"\n            \"yet implemented.\"\n        )\n\n    # Slot-based mode: Use a constant cache key and enforce fixed structure.\n    if self._active_template is not None:\n        cache_key = (\"residual\", \"active_template\")\n    else:\n        # Legacy dynamic mode: cache by structure.\n        factors = tuple(self.fg.factors.values())\n        var_count = len(self.fg.variables)\n        sig_parts = [f\"{f.type}:{len(f.var_ids)}\" for f in factors]\n        structure_sig = f\"v{var_count}|\" + \"|\".join(sig_parts)\n        cache_key = (\"residual\", structure_sig)\n\n    cached = self._compiled_solvers.get(cache_key)\n    if cached is not None:\n        return cached\n\n    # Group factors as before.\n    factors = tuple(self.fg.factors.values())\n    group_to_factors: Dict[Tuple[str, Tuple[int, ...]], List[Factor]] = {}\n    for f in factors:\n        var_dims: List[int] = []\n        for nid in f.var_ids:\n            v = self.fg.variables[nid].value\n            var_dims.append(int(jnp.asarray(v).shape[0]))\n        shape_sig = tuple(var_dims)\n        key = (f.type, shape_sig)\n        group_to_factors.setdefault(key, []).append(f)\n\n    residual_fns = self._residual_registry\n    _, index = self.pack_state()\n\n    def residual(x: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"Stacked residual function over all factors for the current graph, with slot-based activity mask if present.\"\"\"\n        var_values = self.unpack_state(x, index)\n        res_chunks: List[jnp.ndarray] = []\n\n        for (f_type, _shape_sig), flist in group_to_factors.items():\n            res_fn = residual_fns.get(f_type, None)\n            if res_fn is None:\n                raise ValueError(\n                    f\"No residual fn registered for factor type '{f_type}'\"\n                )\n            if not flist:\n                continue\n            # Singleton group\n            if len(flist) == 1:\n                f = flist[0]\n                vs = [var_values[nid] for nid in f.var_ids]\n                stacked = jnp.concatenate(vs)\n                # Slot-based: multiply by \"active\" param if present\n                r = res_fn(stacked, f.params)\n                activity = f.params.get(\"active\", 1.0)\n                r = r * activity\n                res_chunks.append(jnp.reshape(r, (-1,)))\n                continue\n            # Batched path\n            stacked_states: List[jnp.ndarray] = []\n            params_list: List[Dict[str, Any]] = []\n            for f in flist:\n                vs = [var_values[nid] for nid in f.var_ids]\n                stacked_states.append(jnp.concatenate(vs))\n                params_list.append(f.params)\n            stacked_states_arr = jnp.stack(stacked_states, axis=0)\n            params_tree = jtu.tree_map(\n                lambda *vals: jnp.stack(\n                    [jnp.asarray(v) for v in vals], axis=0\n                ),\n                *params_list,\n            )\n            def single_factor_residual(s: jnp.ndarray, p: Dict[str, Any]) -&gt; jnp.ndarray:\n                r = res_fn(s, p)\n                activity = p.get(\"active\", 1.0)\n                return r * activity\n            batched_res = jax.vmap(single_factor_residual)(\n                stacked_states_arr, params_tree\n            )\n            res_chunks.append(jnp.reshape(batched_res, (-1,)))\n        if not res_chunks:\n            return jnp.zeros((0,), dtype=x.dtype)\n        return jnp.concatenate(res_chunks, axis=0)\n\n    residual_jit = jax.jit(residual)\n    self._compiled_solvers[cache_key] = residual_jit\n    return residual_jit\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.build_residual_function_se3_odom_param_multi","title":"<code>build_residual_function_se3_odom_param_multi()</code>","text":"<p>Build a residual function with learnable SE(3) odometry.</p> <p>All factors of type <code>\"odom_se3\"</code> are treated as depending on a parameter array <code>theta</code> of shape <code>(K, 6)</code>, where <code>K</code> is the number of odometry factors. Each row of <code>theta</code> represents a perturbable se(3) measurement.</p>"},{"location":"api/world/#world.model.WorldModel.build_residual_function_se3_odom_param_multi--returns","title":"Returns","text":"<p>(residual_fn, index)     <code>residual_fn(x, theta)</code> and the pack index mapping from     :meth:<code>pack_state</code>.</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def build_residual_function_se3_odom_param_multi(self):\n    \"\"\"Build a residual function with learnable SE(3) odometry.\n\n    All factors of type ``\\\"odom_se3\\\"`` are treated as depending on a\n    parameter array ``theta`` of shape ``(K, 6)``, where ``K`` is the\n    number of odometry factors. Each row of ``theta`` represents a\n    perturbable se(3) measurement.\n\n    Returns\n    -------\n    (residual_fn, index)\n        ``residual_fn(x, theta)`` and the pack index mapping from\n        :meth:`pack_state`.\n    \"\"\"\n    factors = list(self.fg.factors.values())\n    residual_fns = self._residual_registry\n\n    _, index = self.pack_state()\n\n    def residual(x: jnp.ndarray, theta: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"\n        Parameters\n        ----------\n        x : jnp.ndarray\n            Flat state vector.\n        theta : jnp.ndarray\n            Shape (K, 6), per-odom se(3) measurement.\n        \"\"\"\n        var_values = self.unpack_state(x, index)\n        res_list: List[jnp.ndarray] = []\n        odom_idx = 0\n\n        for f in factors:\n            res_fn = residual_fns.get(f.type, None)\n            if res_fn is None:\n                raise ValueError(\n                    f\"No residual fn registered for factor type '{f.type}'\"\n                )\n\n            stacked = jnp.concatenate([var_values[vid] for vid in f.var_ids])\n\n            if f.type == \"odom_se3\":\n                meas = theta[odom_idx]  # (6,)\n                odom_idx += 1\n                base_params = dict(f.params)\n                base_params[\"measurement\"] = meas\n                params = base_params\n            else:\n                params = f.params\n\n            r = res_fn(stacked, params)\n            w = params.get(\"weight\", 1.0)\n            res_list.append(jnp.sqrt(w) * r)\n\n        if not res_list:\n            return jnp.zeros((0,), dtype=x.dtype)\n\n        return jnp.concatenate(res_list)\n\n    return residual, index\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.build_residual_function_voxel_point_param","title":"<code>build_residual_function_voxel_point_param()</code>","text":"<p>Build a residual function with a shared voxel observation point.</p> <p>All factors of type <code>\"voxel_point_obs\"</code> will use a dynamic <code>point_world</code> argument passed at call time, rather than a fixed value stored in the factor params.</p>"},{"location":"api/world/#world.model.WorldModel.build_residual_function_voxel_point_param--returns","title":"Returns","text":"<p>(residual_fn, index)     <code>residual_fn(x, point_world)</code> where <code>point_world</code> has     shape (3,).</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def build_residual_function_voxel_point_param(self):\n    \"\"\"Build a residual function with a shared voxel observation point.\n\n    All factors of type ``\\\"voxel_point_obs\\\"`` will use a dynamic\n    ``point_world`` argument passed at call time, rather than a fixed\n    value stored in the factor params.\n\n    Returns\n    -------\n    (residual_fn, index)\n        ``residual_fn(x, point_world)`` where ``point_world`` has\n        shape (3,).\n    \"\"\"\n    factors = list(self.fg.factors.values())\n    residual_fns = self._residual_registry\n\n    _, index = self.pack_state()\n\n    def residual(x: jnp.ndarray, point_world: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"\n        Parameters\n        ----------\n        x : jnp.ndarray\n            Flat state vector.\n        point_world : jnp.ndarray\n            Shape (3,), observation point in world coords for ALL\n            voxel_point_obs factors. For now we assume a single\n            voxel_point_obs, or that all share the same point.\n        \"\"\"\n        var_values = self.unpack_state(x, index)\n        res_list: List[jnp.ndarray] = []\n\n        for f in factors:\n            res_fn = residual_fns.get(f.type, None)\n            if res_fn is None:\n                raise ValueError(\n                    f\"No residual fn registered for factor type '{f.type}'\"\n                )\n\n            stacked = jnp.concatenate([var_values[vid] for vid in f.var_ids])\n\n            if f.type == \"voxel_point_obs\":\n                base_params = dict(f.params)\n                base_params[\"point_world\"] = point_world\n                params = base_params\n            else:\n                params = f.params\n\n            r = res_fn(stacked, params)\n            w = params.get(\"weight\", 1.0)\n            res_list.append(jnp.sqrt(w) * r)\n\n        if not res_list:\n            return jnp.zeros((0,), dtype=x.dtype)\n\n        return jnp.concatenate(res_list)\n\n    return residual, index\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.build_residual_function_voxel_point_param_multi","title":"<code>build_residual_function_voxel_point_param_multi()</code>","text":"<p>Build a residual function with per-factor voxel observation points.</p> <p>Each <code>\"voxel_point_obs\"</code> factor consumes a row of the parameter array <code>theta</code> of shape <code>(K, 3)</code>, where <code>K</code> is the number of such factors.</p>"},{"location":"api/world/#world.model.WorldModel.build_residual_function_voxel_point_param_multi--returns","title":"Returns","text":"<p>(residual_fn, index)     <code>residual_fn(x, theta)</code> where <code>theta</code> has shape (K, 3).</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def build_residual_function_voxel_point_param_multi(self):\n    \"\"\"Build a residual function with per-factor voxel observation points.\n\n    Each ``\\\"voxel_point_obs\\\"`` factor consumes a row of the parameter\n    array ``theta`` of shape ``(K, 3)``, where ``K`` is the number of\n    such factors.\n\n    Returns\n    -------\n    (residual_fn, index)\n        ``residual_fn(x, theta)`` where ``theta`` has shape (K, 3).\n    \"\"\"\n    factors = list(self.fg.factors.values())\n    residual_fns = self._residual_registry\n\n    _, index = self.pack_state()\n\n    def residual(x: jnp.ndarray, theta: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"\n        Parameters\n        ----------\n        x : jnp.ndarray\n            Flat state vector.\n        theta : jnp.ndarray\n            Shape (K, 3), per-voxel-point observation in world\n            coordinates.\n        \"\"\"\n        var_values = self.unpack_state(x, index)\n        res_list: List[jnp.ndarray] = []\n        obs_idx = 0  # python counter over voxel_point_obs factors\n\n        for f in factors:\n            res_fn = residual_fns.get(f.type, None)\n            if res_fn is None:\n                raise ValueError(\n                    f\"No residual fn registered for factor type '{f.type}'\"\n                )\n\n            stacked = jnp.concatenate([var_values[vid] for vid in f.var_ids])\n\n            if f.type == \"voxel_point_obs\":\n                point_world = theta[obs_idx]  # (3,)\n                obs_idx += 1\n                base_params = dict(f.params)\n                base_params[\"point_world\"] = point_world\n                params = base_params\n            else:\n                params = f.params\n\n            r = res_fn(stacked, params)\n            w = params.get(\"weight\", 1.0)\n            res_list.append(jnp.sqrt(w) * r)\n\n        if not res_list:\n            return jnp.zeros((0,), dtype=x.dtype)\n\n        return jnp.concatenate(res_list)\n\n    return residual, index\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.build_residual_function_with_type_weights","title":"<code>build_residual_function_with_type_weights(factor_type_order)</code>","text":"<p>Build a residual function that supports learnable type weights.</p> <p>The returned function has signature <code>r(x, log_scales)</code> where <code>log_scales[i]</code> is the log-weight associated with <code>factor_type_order[i]</code>. Missing types default to unit weight.</p> <p>This is a WorldModel-based version of the old FactorGraph helper, implemented in terms of <code>pack_state</code>, <code>unpack_state</code>, and the WorldModel residual registry.</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def build_residual_function_with_type_weights(\n    self, factor_type_order: List[str]\n):\n    \"\"\"Build a residual function that supports learnable type weights.\n\n    The returned function has signature ``r(x, log_scales)`` where\n    ``log_scales[i]`` is the log-weight associated with\n    ``factor_type_order[i]``. Missing types default to unit weight.\n\n    This is a WorldModel-based version of the old FactorGraph helper,\n    implemented in terms of ``pack_state``, ``unpack_state``, and the\n    WorldModel residual registry.\n    \"\"\"\n    factors = list(self.fg.factors.values())\n    residual_fns = self._residual_registry\n    _, index = self.pack_state()\n\n    type_to_idx = {t: i for i, t in enumerate(factor_type_order)}\n\n    def residual(x: jnp.ndarray, log_scales: jnp.ndarray) -&gt; jnp.ndarray:\n        var_values = self.unpack_state(x, index)\n        res_list: List[jnp.ndarray] = []\n\n        for factor in factors:\n            res_fn = residual_fns.get(factor.type, None)\n            if res_fn is None:\n                raise ValueError(\n                    f\"No residual fn registered for factor type '{factor.type}'\"\n                )\n\n            stacked = jnp.concatenate(\n                [var_values[vid] for vid in factor.var_ids], axis=0\n            )\n            r = res_fn(stacked, factor.params)  # (k,)\n\n            idx = type_to_idx.get(factor.type, None)\n            if idx is not None:\n                scale = jnp.exp(log_scales[idx])\n            else:\n                scale = 1.0\n\n            r_scaled = scale * r\n            r_scaled = jnp.reshape(r_scaled, (-1,))\n            res_list.append(r_scaled)\n\n        if not res_list:\n            return jnp.zeros((0,), dtype=x.dtype)\n\n        return jnp.concatenate(res_list, axis=0)\n\n    return residual\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.configure_factor_slot","title":"<code>configure_factor_slot(factor_type, slot_idx, var_ids, params, active=True)</code>","text":"<p>Configure a factor slot in the active template: set variable ids, params, and activity.</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def configure_factor_slot(\n    self,\n    factor_type: str,\n    slot_idx: int,\n    var_ids: Tuple[NodeId, ...],\n    params: Dict,\n    active: bool = True,\n) -&gt; None:\n    \"\"\"Configure a factor slot in the active template: set variable ids, params, and activity.\"\"\"\n    slot_key = (factor_type, slot_idx)\n    slot = self._factor_slots.get(slot_key)\n    if slot is None:\n        raise KeyError(f\"Factor slot {slot_key} not found in active template.\")\n    fid = slot.factor_id\n    f = self.fg.factors[fid]\n    # Update factor's var_ids and params in place.\n    object.__setattr__(f, \"var_ids\", tuple(var_ids))\n\n    # IMPORTANT: preserve existing keys so vmapped stacking sees a\n    # consistent pytree structure across all factors in a batched group.\n    new_params = dict(f.params)\n    new_params.update(params)\n    # Normalize scalar params to JAX arrays for stable stacking.\n    for k, v in list(new_params.items()):\n        if isinstance(v, (float, int)):\n            new_params[k] = jnp.array(v, dtype=jnp.float32)\n    new_params[\"active\"] = jnp.array(1.0 if active else 0.0, dtype=jnp.float32)\n    f.params = new_params\n    self._active_factor_mask[fid] = active\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.fixed_lag_marginalize","title":"<code>fixed_lag_marginalize(keep_ids, damping=1e-06)</code>","text":"<p>Disabled: Fixed-lag marginalization is not supported in active template mode. Use bounded active templates for sliding window/fixed-lag smoothing instead.</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def fixed_lag_marginalize(\n    self,\n    keep_ids: List[NodeId],\n    damping: float = 1e-6,\n) -&gt; None:\n    \"\"\"\n    Disabled: Fixed-lag marginalization is not supported in active template mode.\n    Use bounded active templates for sliding window/fixed-lag smoothing instead.\n    \"\"\"\n    if self._active_template is not None:\n        # Fixed-lag smoothing is handled via bounded active templates.\n        # This method is disabled in slot-based mode.\n        return\n    # (Legacy code for dynamic mode could be restored here if needed.)\n    pass\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.get_residual","title":"<code>get_residual(factor_type)</code>","text":"<p>Return the residual function registered for a given factor type.</p>"},{"location":"api/world/#world.model.WorldModel.get_residual--parameters","title":"Parameters","text":"<p>factor_type : str     String identifier for the factor type.</p>"},{"location":"api/world/#world.model.WorldModel.get_residual--returns","title":"Returns","text":"<p>callable or None     The residual function previously registered via     :meth:<code>register_residual</code>, or <code>None</code> if no function is     registered for the requested type.</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def get_residual(self, factor_type: str) -&gt; Optional[Callable[..., Any]]:\n    \"\"\"Return the residual function registered for a given factor type.\n\n    Parameters\n    ----------\n    factor_type : str\n        String identifier for the factor type.\n\n    Returns\n    -------\n    callable or None\n        The residual function previously registered via\n        :meth:`register_residual`, or ``None`` if no function is\n        registered for the requested type.\n    \"\"\"\n    return self._residual_registry.get(factor_type)\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.get_residuals","title":"<code>get_residuals()</code>","text":"<p>Returns the residual registry, all currently registered residuals.</p> <p>:return: Dict[str, ResidualFn]</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def get_residuals(self) -&gt; Dict[str, ResidualFn]:\n    \"\"\"Returns the residual registry, all currently registered residuals.\n\n    :return: Dict[str, ResidualFn]\n    \"\"\"\n    return self._residual_registry\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.get_variable_value","title":"<code>get_variable_value(nid)</code>","text":"<p>Return the current value of a variable.</p> <p>This is a thin convenience wrapper over the underlying :class:<code>FactorGraph</code> variable storage and is useful when building dynamic scene graphs that want to query individual nodes.</p> <p>:param nid: Identifier of the variable. :returns: A JAX array holding the variable's current value.</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def get_variable_value(self, nid: NodeId) -&gt; jnp.ndarray:\n    \"\"\"Return the current value of a variable.\n\n    This is a thin convenience wrapper over the underlying\n    :class:`FactorGraph` variable storage and is useful when building\n    dynamic scene graphs that want to query individual nodes.\n\n    :param nid: Identifier of the variable.\n    :returns: A JAX array holding the variable's current value.\n    \"\"\"\n    return self.fg.variables[nid].value\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.init_active_template","title":"<code>init_active_template(template)</code>","text":"<p>Initialize a fixed-capacity active factor graph template for JIT-stable operation. All variables and factors are preallocated; structure is fixed.</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def init_active_template(self, template: ActiveWindowTemplate) -&gt; None:\n    \"\"\"Initialize a fixed-capacity active factor graph template for JIT-stable operation.\n    All variables and factors are preallocated; structure is fixed.\n    \"\"\"\n    # Reset the factor graph and slot bookkeeping.\n    self.fg = FactorGraph()\n    self._active_template = template\n    self._var_slots.clear()\n    self._factor_slots.clear()\n    self._active_factor_mask.clear()\n    # Pre-allocate variable slots.\n    for var_type, slot_idx, dim in template.variable_slots:\n        init_val = jnp.zeros((dim,), dtype=jnp.float32)\n        node_id = self.add_variable(var_type, init_val)\n        slot_key = (var_type, slot_idx)\n        self._var_slots[slot_key] = VarSlot(var_type, slot_idx, node_id, dim)\n    # Pre-allocate factor slots (inactive by default).\n    for factor_type, slot_idx, var_slot_keys in template.factor_slots:\n        var_ids = tuple(self._var_slots[vk].node_id for vk in var_slot_keys)\n\n        # Compute the stacked state dimension for this factor slot.\n        stacked_dim = 0\n        for vk in var_slot_keys:\n            stacked_dim += int(self._var_slots[vk].dim)\n\n        # IMPORTANT: In slot-based mode we rely on vmap + tree stacking.\n        # That requires that all factors within a batched group have the\n        # same params keys and compatible shapes.\n        if factor_type == \"prior\":\n            # Prior residual typically expects a 6D target for SE(3) poses.\n            # We default to zeros and unit weight.\n            params: Dict[str, Any] = {\n                \"target\": jnp.zeros((stacked_dim,), dtype=jnp.float32),\n                \"weight\": jnp.array(1.0, dtype=jnp.float32),\n                \"active\": jnp.array(0.0, dtype=jnp.float32),\n            }\n        elif factor_type == \"odom_se3\":\n            # Odometry measurement lives in the se(3) tangent space (6D),\n            # even though the stacked state for two poses is 12D.\n            params = {\n                \"measurement\": jnp.zeros((6,), dtype=jnp.float32),\n                \"weight\": jnp.array(1.0, dtype=jnp.float32),\n                \"active\": jnp.array(0.0, dtype=jnp.float32),\n            }\n        elif factor_type == \"marginal_prior\":\n            # Dense Gaussian prior induced by marginalization.\n            params = {\n                \"mean\": jnp.zeros((stacked_dim,), dtype=jnp.float32),\n                \"sqrt_info\": jnp.eye(stacked_dim, dtype=jnp.float32),\n                \"weight\": jnp.array(1.0, dtype=jnp.float32),\n                \"active\": jnp.array(0.0, dtype=jnp.float32),\n            }\n        else:\n            # Generic fallback: only active + weight.\n            # Callers can override/extend keys via configure_factor_slot.\n            params = {\n                \"weight\": jnp.array(1.0, dtype=jnp.float32),\n                \"active\": jnp.array(0.0, dtype=jnp.float32),\n            }\n\n        factor_id = self.add_factor(factor_type, var_ids, params)\n        slot_key = (factor_type, slot_idx)\n        self._factor_slots[slot_key] = FactorSlot(factor_type, slot_idx, factor_id, var_slot_keys)\n        self._active_factor_mask[factor_id] = False\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.list_residual_types","title":"<code>list_residual_types()</code>","text":"<p>List all factor types with registered residual functions.</p> <p>This is a convenience helper for debugging, diagnostics, and tests to verify that the WorldModel has been configured with the expected residuals for the current application.</p>"},{"location":"api/world/#world.model.WorldModel.list_residual_types--returns","title":"Returns","text":"<p>list of str     Sorted list of factor type strings for which residuals have     been registered.</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def list_residual_types(self) -&gt; List[str]:\n    \"\"\"List all factor types with registered residual functions.\n\n    This is a convenience helper for debugging, diagnostics, and tests\n    to verify that the WorldModel has been configured with the expected\n    residuals for the current application.\n\n    Returns\n    -------\n    list of str\n        Sorted list of factor type strings for which residuals have\n        been registered.\n    \"\"\"\n    return sorted(self._residual_registry.keys())\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.marginalize_variables","title":"<code>marginalize_variables(marginalized_ids, damping=1e-06)</code>","text":"<p>Disabled: Marginalization is not supported in active template mode. Use bounded active templates for fixed-lag smoothing instead.</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def marginalize_variables(\n    self,\n    marginalized_ids: List[NodeId],\n    damping: float = 1e-6,\n) -&gt; None:\n    \"\"\"\n    Disabled: Marginalization is not supported in active template mode.\n    Use bounded active templates for fixed-lag smoothing instead.\n    \"\"\"\n    # If in active template mode, do nothing and explain.\n    if self._active_template is not None:\n        # Fixed-lag smoothing is handled via bounded active templates.\n        # This method is disabled in slot-based mode.\n        return\n    # (Legacy code for dynamic mode could be restored here if needed.)\n    pass\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.optimize","title":"<code>optimize(lr=0.1, iters=300, method='gd', damping=0.001, max_step_norm=1.0)</code>","text":"<p>Run a local optimizer on the current world state.</p> <p>This method packs the current variables into a flat state vector, constructs an appropriate objective or residual function, runs one of the supported optimizers, and writes the optimized state back into :attr:<code>fg.variables</code>.</p> <p>Supported methods:</p> <ul> <li><code>\"gd\"</code>: vanilla gradient descent on the scalar objective   :math:<code>\\|r(x)\\|^2</code>.</li> <li><code>\"newton\"</code>: damped Newton on the same scalar objective.</li> <li><code>\"gn\"</code>: Gauss--Newton on the stacked residual vector assuming   Euclidean variables.</li> <li><code>\"manifold_gn\"</code>: manifold-aware Gauss--Newton that uses   :func:<code>slam.manifold.build_manifold_metadata</code> to handle SE(3)   and Euclidean blocks differently.</li> <li><code>\"gn_jit\"</code>: JIT-compiled Gauss--Newton using   :class:<code>optimization.jit_wrappers.JittedGN</code>.</li> </ul> <p>:param lr: Learning rate for gradient-descent-based methods     (currently used when <code>method == \"gd\"</code>). :param iters: Maximum number of iterations for the chosen optimizer. :param method: Name of the optimization method to use. See the list     above for supported values. :param damping: Damping / regularization parameter used by the     Newton and Gauss--Newton variants. :param max_step_norm: Maximum allowed step norm for Gauss--Newton     methods; steps larger than this are clamped to improve stability. :returns: <code>None</code>. The world model is updated in place.</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def optimize(\n    self,\n    lr: float = 0.1,\n    iters: int = 300,\n    method: str = \"gd\",\n    damping: float = 1e-3,\n    max_step_norm: float = 1.0,\n) -&gt; None:\n    \"\"\"Run a local optimizer on the current world state.\n\n    This method packs the current variables into a flat state vector,\n    constructs an appropriate objective or residual function, runs one\n    of the supported optimizers, and writes the optimized state back\n    into :attr:`fg.variables`.\n\n    Supported methods:\n\n    - ``\"gd\"``: vanilla gradient descent on the scalar objective\n      :math:`\\\\|r(x)\\\\|^2`.\n    - ``\"newton\"``: damped Newton on the same scalar objective.\n    - ``\"gn\"``: Gauss--Newton on the stacked residual vector assuming\n      Euclidean variables.\n    - ``\"manifold_gn\"``: manifold-aware Gauss--Newton that uses\n      :func:`slam.manifold.build_manifold_metadata` to handle SE(3)\n      and Euclidean blocks differently.\n    - ``\"gn_jit\"``: JIT-compiled Gauss--Newton using\n      :class:`optimization.jit_wrappers.JittedGN`.\n\n    :param lr: Learning rate for gradient-descent-based methods\n        (currently used when ``method == \"gd\"``).\n    :param iters: Maximum number of iterations for the chosen optimizer.\n    :param method: Name of the optimization method to use. See the list\n        above for supported values.\n    :param damping: Damping / regularization parameter used by the\n        Newton and Gauss--Newton variants.\n    :param max_step_norm: Maximum allowed step norm for Gauss--Newton\n        methods; steps larger than this are clamped to improve stability.\n    :returns: ``None``. The world model is updated in place.\n    \"\"\"\n    x_init, index = self.pack_state()\n    residual_fn = self.build_residual()\n\n    if method == \"gd\":\n        obj = self.build_objective()\n        cfg = GDConfig(learning_rate=lr, max_iters=iters)\n        x_opt = gradient_descent(obj, x_init, cfg)\n\n    elif method == \"newton\":\n        obj = self.build_objective()\n        cfg = NewtonConfig(max_iters=iters, damping=damping)\n        x_opt = damped_newton(obj, x_init, cfg)\n\n    elif method == \"gn\":\n        cfg = GNConfig(max_iters=iters, damping=damping, max_step_norm=max_step_norm)\n        x_opt = gauss_newton(residual_fn, x_init, cfg)\n\n    elif method == \"manifold_gn\":\n        block_slices, manifold_types = build_manifold_metadata(packed_state=self.pack_state(),fg=self.fg)\n        cfg = GNConfig(max_iters=iters, damping=damping, max_step_norm=max_step_norm)\n        x_opt = gauss_newton_manifold(\n            residual_fn, x_init, block_slices, manifold_types, cfg\n        )\n\n    elif method == \"gn_jit\":\n        cfg = GNConfig(max_iters=iters, damping=damping, max_step_norm=max_step_norm)\n        jgn = JittedGN.from_residual(residual_fn, cfg)\n        x_opt = jgn(x_init)\n    else:\n        raise ValueError(f\"Unknown optimization method '{method}'\")\n\n    # Write back\n    values = self.unpack_state(x_opt, index)\n    for nid, val in values.items():\n        self.fg.variables[nid].value = val\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.pack_state","title":"<code>pack_state()</code>","text":"<p>Pack all variable values into a single flat JAX array.</p> <p>The variables are ordered by sorted :class:<code>NodeId</code> to ensure stable indexing across calls.</p> <p>:return: Tuple of <code>(x, index)</code> where <code>x</code> is the concatenated     state vector and <code>index</code> is the mapping produced by     :meth:<code>_build_state_index</code>. :rtype: Tuple[jnp.ndarray, Dict[NodeId, Tuple[int, int]]]</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def pack_state(self) -&gt; jnp.ndarray:\n    \"\"\"Pack all variable values into a single flat JAX array.\n\n    The variables are ordered by sorted :class:`NodeId` to ensure stable\n    indexing across calls.\n\n    :return: Tuple of ``(x, index)`` where ``x`` is the concatenated\n        state vector and ``index`` is the mapping produced by\n        :meth:`_build_state_index`.\n    :rtype: Tuple[jnp.ndarray, Dict[NodeId, Tuple[int, int]]]\n    \"\"\"\n    index = self._build_state_index()\n    chunks = []\n    for node_id in sorted(self.fg.variables.keys()):\n        var = self.fg.variables[node_id]\n        chunks.append(jnp.asarray(var.value))\n    return jnp.concatenate(chunks), index\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.register_residual","title":"<code>register_residual(factor_type, fn)</code>","text":"<p>Register a residual function for a given factor type.</p> <p>This is the WorldModel-level registry that associates factor type strings (e.g. <code>\"odom_se3\"</code>, <code>\"voxel_point_obs\"</code>) with JAX-compatible residual functions. The registered functions are consumed by higher-level residual builders such as :meth:<code>build_residual</code>.</p>"},{"location":"api/world/#world.model.WorldModel.register_residual--parameters","title":"Parameters","text":"<p>factor_type : str     String identifier for the factor type. This must match the     <code>type</code> field stored in :class:<code>Factor</code> instances in the     underlying :class:<code>FactorGraph</code>. fn : Callable     Residual function implementing the measurement model. The     exact signature is intentionally flexible, but it is expected     to be compatible with the unified residual builder returned by     :meth:<code>build_residual</code> (e.g. it may be vmapped across factors     of a given type).</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def register_residual(self, factor_type: str, fn: Callable[..., Any]) -&gt; None:\n    \"\"\"Register a residual function for a given factor type.\n\n    This is the WorldModel-level registry that associates factor type\n    strings (e.g. ``\"odom_se3\"``, ``\"voxel_point_obs\"``) with\n    JAX-compatible residual functions. The registered functions are\n    consumed by higher-level residual builders such as\n    :meth:`build_residual`.\n\n    Parameters\n    ----------\n    factor_type : str\n        String identifier for the factor type. This must match the\n        ``type`` field stored in :class:`Factor` instances in the\n        underlying :class:`FactorGraph`.\n    fn : Callable\n        Residual function implementing the measurement model. The\n        exact signature is intentionally flexible, but it is expected\n        to be compatible with the unified residual builder returned by\n        :meth:`build_residual` (e.g. it may be vmapped across factors\n        of a given type).\n    \"\"\"\n    self._residual_registry[factor_type] = fn\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.set_variable_slot","title":"<code>set_variable_slot(var_type, slot_idx, value)</code>","text":"<p>Set the value of a variable slot in the active template.</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def set_variable_slot(self, var_type: str, slot_idx: int, value: jnp.ndarray) -&gt; NodeId:\n    \"\"\"Set the value of a variable slot in the active template.\"\"\"\n    slot_key = (var_type, slot_idx)\n    slot = self._var_slots.get(slot_key)\n    if slot is None:\n        raise KeyError(f\"Variable slot {slot_key} not found in active template.\")\n    if value.shape[0] != slot.dim:\n        raise ValueError(f\"Value shape {value.shape} does not match slot dim {slot.dim}\")\n    self.fg.variables[slot.node_id].value = value\n    return slot.node_id\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.snapshot_state","title":"<code>snapshot_state()</code>","text":"<p>Capture a shallow snapshot of the current world state.</p> <p>The snapshot maps integer node ids to their current values. This is intentionally simple and serialization-friendly, and is meant to be consumed by higher-level dynamic scene graph structures that want to record the evolution of the world over time.</p> <p>:returns: A dictionary mapping <code>int(NodeId)</code> to JAX arrays.</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def snapshot_state(self) -&gt; Dict[int, jnp.ndarray]:\n    \"\"\"Capture a shallow snapshot of the current world state.\n\n    The snapshot maps integer node ids to their current values. This is\n    intentionally simple and serialization-friendly, and is meant to be\n    consumed by higher-level dynamic scene graph structures that want to\n    record the evolution of the world over time.\n\n    :returns: A dictionary mapping ``int(NodeId)`` to JAX arrays.\n    \"\"\"\n    return {int(nid): jnp.array(var.value) for nid, var in self.fg.variables.items()}\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.unpack_state","title":"<code>unpack_state(x, index)</code>","text":"<p>Unpack a flat state vector back into per-variable arrays.</p> <p>:param x: Flattened state vector produced by :meth:<code>pack_state</code> or     produced by an optimizer. :type x: jnp.ndarray :param index: Mapping from :class:<code>NodeId</code> to <code>(start, dim)</code> blocks     as returned by :meth:<code>_build_state_index</code>. :type index: Dict[NodeId, Tuple[int, int]] :return: Mapping from node id to its corresponding slice of <code>x</code>. :rtype: Dict[NodeId, jnp.ndarray]</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def unpack_state(self, x: jnp.ndarray, index: Dict[NodeId, Tuple[int, int]]) -&gt; Dict[NodeId, jnp.ndarray]:\n    \"\"\"Unpack a flat state vector back into per-variable arrays.\n\n    :param x: Flattened state vector produced by :meth:`pack_state` or\n        produced by an optimizer.\n    :type x: jnp.ndarray\n    :param index: Mapping from :class:`NodeId` to ``(start, dim)`` blocks\n        as returned by :meth:`_build_state_index`.\n    :type index: Dict[NodeId, Tuple[int, int]]\n    :return: Mapping from node id to its corresponding slice of ``x``.\n    :rtype: Dict[NodeId, jnp.ndarray]\n    \"\"\"\n    result: Dict[NodeId, jnp.ndarray] = {}\n    for node_id, (start, dim) in index.items():\n        result[node_id] = x[start:start+dim]\n    return result\n</code></pre>"},{"location":"api/world/#world.model.WorldModel.unpack_state_inplace","title":"<code>unpack_state_inplace(x_opt)</code>","text":"<p>Write the optimized state vector back into the FactorGraph variable table.</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def unpack_state_inplace(self, x_opt: jnp.ndarray) -&gt; None:\n    \"\"\"\n    Write the optimized state vector back into the FactorGraph variable table.\n    \"\"\"\n    _, index = self.pack_state()  # index maps node_id -&gt; (start, end)\n\n    for node_id, (start, end) in index.items():\n        block = x_opt[start:end]\n        var = self.fg.variables[node_id]\n        var.value = block  # overwrite stored variable value\n</code></pre>"},{"location":"api/world/#world.model.marginal_prior_residual","title":"<code>marginal_prior_residual(stacked, params)</code>","text":"<p>Residual for a dense Gaussian prior induced by marginalization.</p> <p>This residual encodes a quadratic term of the form</p> <pre><code>1/2 (x - \u03bc)^T H (x - \u03bc)\n</code></pre> <p>via a Cholesky factorization H = L^T L. The parameters are:</p> <pre><code>mean       : \u03bc, a 1D array of the same shape as ``stacked``.\nsqrt_info  : L, a square matrix such that L^T L \u2248 H.\n</code></pre> <p>The returned residual is L @ (x - \u03bc), so that the overall contribution to the objective is 1/2 ||L (x - \u03bc)||^2.</p> Source code in <code>dsg-jit/dsg_jit/world/model.py</code> <pre><code>def marginal_prior_residual(stacked: jnp.ndarray, params: Dict[str, Any]) -&gt; jnp.ndarray:\n    \"\"\"Residual for a dense Gaussian prior induced by marginalization.\n\n    This residual encodes a quadratic term of the form\n\n        1/2 (x - \u03bc)^T H (x - \u03bc)\n\n    via a Cholesky factorization H = L^T L. The parameters are:\n\n        mean       : \u03bc, a 1D array of the same shape as ``stacked``.\n        sqrt_info  : L, a square matrix such that L^T L \u2248 H.\n\n    The returned residual is L @ (x - \u03bc), so that the overall contribution\n    to the objective is 1/2 ||L (x - \u03bc)||^2.\n    \"\"\"\n    mean = params[\"mean\"]\n    sqrt_info = params[\"sqrt_info\"]\n    return sqrt_info @ (stacked - mean)\n</code></pre>"},{"location":"api/world/#worldscene_graph","title":"<code>world.scene_graph</code>","text":"<p>Dynamic 3D scene graph utilities built on top of the world model.</p> <p>This module provides a <code>SceneGraphWorld</code> abstraction that organizes poses, places, rooms, objects, and agents into a dynamic scene graph backed by the differentiable factor graph.</p> <p>Conceptually, this layer is responsible for:</p> <pre><code>\u2022 Creating typed nodes:\n    - Robot / agent poses (SE3)\n    - Places / topological nodes (1D)\n    - Rooms / regions\n    - Objects (points / positions in space)\n\u2022 Adding semantic and metric relationships between them via factors:\n    - Pose priors\n    - SE3 odometry / loop closures\n    - Pose\u2013place attachments\n    - Pose\u2013object / object\u2013place relations\n\u2022 Maintaining lightweight indexing:\n    - Maps from (agent, time) \u2192 pose NodeId\n    - Collections of place / room / object node ids\n    - Optional trajectory dictionaries\n</code></pre> <p>What it does not do:     \u2022 It does not implement the optimizer itself.     \u2022 It does not hard-code SE3 math or Jacobians.     \u2022 It does not perform rendering or perception.</p> <p>All numerical optimization is delegated to:</p> <pre><code>- `world.model.WorldModel` (and its `FactorGraph`)\n- `optimization.solvers` (Gauss\u2013Newton / manifold variants)\n- `slam.manifold` and `slam.measurements` for geometry and residuals\n</code></pre>"},{"location":"api/world/#world.scene_graph--typical-usage","title":"Typical usage","text":"<p>Experiments in <code>experiments/exp0X_*.py</code> follow a common pattern:</p> <pre><code>1. Construct a `SceneGraphWorld`.\n2. Add a small chain of poses, places, and objects.\n3. Attach priors and odometry factors.\n4. Optionally attach voxel or observation factors.\n5. Optimize via Gauss\u2013Newton (JIT or non-JIT).\n6. Inspect the resulting scene graph state.\n</code></pre>"},{"location":"api/world/#world.scene_graph--design-goals","title":"Design goals","text":"<ul> <li>Ergonomics: hide raw <code>NodeId</code> and factor wiring behind friendly   helpers like \u201cadd pose\u201d, \u201cadd agent pose\u201d, \u201cattach place\u201d, etc.</li> <li>Differentiable backbone: everything created here remains compatible   with JAX JIT and automatic differentiation downstream.</li> <li>Extensibility: easy to add new relation types and node types   without changing the optimizer or lower-level infrastructure.</li> </ul>"},{"location":"api/world/#world.scene_graph.SceneGraphNoiseConfig","title":"<code>SceneGraphNoiseConfig(prior_pose_sigma=0.001, odom_se3_sigma=0.05, smooth_pose_sigma=0.5, pose_place_sigma=0.05, object_at_pose_sigma=0.05, pose_landmark_sigma=0.05, pose_landmark_bearing_sigma=0.05, pose_voxel_point_sigma=0.05, voxel_smoothness_sigma=0.1, voxel_point_obs_sigma=0.05)</code>  <code>dataclass</code>","text":"<p>Default noise (standard deviation) per factor type.</p> These are in the same units as the residuals <ul> <li>prior / odom / smoothness: R^6 pose (m, m, m, rad, rad, rad)</li> <li>pose_place / object_at_pose: R^1 or R^3 (m)</li> </ul>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld","title":"<code>SceneGraphWorld()</code>","text":"<p>World-level dynamic scene graph wrapper that manages typed nodes and semantic relationships, built atop the WorldModel. Provides ergonomic helpers for creating and connecting SE(3) poses, places, rooms, objects, and agents, and maintains convenient indexing for scene-graph experiments.</p> <p>In addition to delegating numerical optimization to the underlying WorldModel, SceneGraphWorld maintains its own lightweight memory of node states. This persistent cache decouples the scene graph from the FactorGraph so that sliding-window marginalization or variable removal at the optimization level does not cause information loss at the scene-graph level.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def __init__(self) -&gt; None:\n    self.wm = WorldModel()\n    self.pose_trajectory = {}\n    self.noise = SceneGraphNoiseConfig()\n\n    # --- Named semantic node indexes ---\n    self.room_nodes = {}\n    self.place_nodes = {}\n    self.object_nodes = {}\n\n    # --- Semantic adjacency (for visualization / topology) ---\n    self.room_place_edges = []\n    self.object_room_edges = []\n\n    # --- Persistent scene-graph memory of node states ---\n    self._memory: Dict[int, SceneNodeState] = {}\n    self._factor_memory: Dict[int, SGFactorRecord] = {}\n    self._next_factor_id: int = 0\n\n    # --- Active-template mode (bounded FG / single-JIT) ---\n    self._active_template_enabled: bool = False\n\n    # var_type -&gt; capacity (# slots)\n    self._slot_capacity: Dict[str, int] = {}\n    # node_id -&gt; (var_type, slot_idx)\n    self._slot_assign: Dict[int, Tuple[str, int]] = {}\n    # var_type -&gt; FIFO list of node_ids assigned (for eviction)\n    self._slot_fifo: DefaultDict[str, Deque[int]] = defaultdict(deque)\n\n    # factor_type -&gt; capacity (# slots)\n    self._factor_slot_capacity: Dict[str, int] = {}\n    # factor_type -&gt; next slot index (round-robin)\n    self._factor_slot_next: DefaultDict[str, int] = defaultdict(int)\n\n    # --- Global residuals registry ---\n    self.wm.register_residual(\"prior\", prior_residual)\n    self.wm.register_residual(\"odom_se3\", odom_se3_residual)\n    self.wm.register_residual(\"odom_se3_geodesic\", odom_se3_geodesic_residual)\n    self.wm.register_residual(\"pose_place_attachment\", pose_place_attachment_residual)\n    self.wm.register_residual(\"object_at_pose\", object_at_pose_residual)\n    self.wm.register_residual(\"pose_temporal_smoothness\", pose_temporal_smoothness_residual)\n    self.wm.register_residual(\"pose_landmark_relative\", pose_landmark_relative_residual)\n    self.wm.register_residual(\"pose_landmark_bearing\", pose_landmark_bearing_residual)\n    self.wm.register_residual(\"pose_voxel_point\", pose_voxel_point_residual)\n    self.wm.register_residual(\"voxel_smoothness\", voxel_smoothness_residual)\n    self.wm.register_residual(\"voxel_point_obs\", voxel_point_observation_residual)\n    self.wm.register_residual(\"range\", range_residual)\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_agent_pose_landmark_bearing","title":"<code>add_agent_pose_landmark_bearing(agent, t, landmark_id, bearing, sigma=None)</code>","text":"<p>Add a bearing-only pose\u2013landmark constraint for an agent at time <code>t</code>.</p> <p>This wraps :meth:<code>add_pose_landmark_bearing</code> and resolves the pose id from :attr:<code>pose_trajectory</code>.</p> <p>:param agent: Agent identifier. :param t: Timestep index for the pose. :param landmark_id: Node id of the 3D landmark variable. :param bearing: Iterable of length 3 giving the bearing vector in the     pose frame (it will be normalized internally). :param sigma: Optional noise standard deviation. If <code>None</code>, falls back     to :attr:<code>SceneGraphNoiseConfig.pose_landmark_bearing_sigma</code>. :return: Integer factor id of the created bearing constraint. :raises KeyError: If no pose has been registered for <code>(agent, t)</code>.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_agent_pose_landmark_bearing(\n    self,\n    agent: str,\n    t: int,\n    landmark_id: int,\n    bearing,\n    sigma: float | None = None,\n) -&gt; int:\n    \"\"\"\n    Add a bearing-only pose\u2013landmark constraint for an agent at time ``t``.\n\n    This wraps :meth:`add_pose_landmark_bearing` and resolves the pose id\n    from :attr:`pose_trajectory`.\n\n    :param agent: Agent identifier.\n    :param t: Timestep index for the pose.\n    :param landmark_id: Node id of the 3D landmark variable.\n    :param bearing: Iterable of length 3 giving the bearing vector in the\n        pose frame (it will be normalized internally).\n    :param sigma: Optional noise standard deviation. If ``None``, falls back\n        to :attr:`SceneGraphNoiseConfig.pose_landmark_bearing_sigma`.\n    :return: Integer factor id of the created bearing constraint.\n    :raises KeyError: If no pose has been registered for ``(agent, t)``.\n    \"\"\"\n    key = (agent, t)\n    if key not in self.pose_trajectory:\n        raise KeyError(f\"No pose registered for agent={agent!r}, t={t}\")\n\n    pose_id = self.pose_trajectory[key]\n    return self.add_pose_landmark_bearing(\n        pose_id=pose_id,\n        landmark_id=landmark_id,\n        bearing=bearing,\n        sigma=sigma,\n    )\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_agent_pose_landmark_relative","title":"<code>add_agent_pose_landmark_relative(agent, t, landmark_id, measurement, sigma=None)</code>","text":"<p>Add a relative pose\u2013landmark constraint for an agent at time <code>t</code>.</p> <p>This is a small ergonomic wrapper around :meth:<code>add_pose_landmark_relative</code> that resolves the pose id using :attr:<code>pose_trajectory</code>.</p> <p>:param agent: Agent identifier. :param t: Timestep index for the pose. :param landmark_id: Node id of the 3D landmark variable. :param measurement: Iterable of length 3 giving the expected landmark     position in the pose frame. :param sigma: Optional noise standard deviation. If <code>None</code>, falls back     to :attr:<code>SceneGraphNoiseConfig.pose_landmark_sigma</code>. :return: Integer factor id of the created relative landmark constraint. :raises KeyError: If no pose has been registered for <code>(agent, t)</code>.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_agent_pose_landmark_relative(\n    self,\n    agent: str,\n    t: int,\n    landmark_id: int,\n    measurement,\n    sigma: float | None = None,\n) -&gt; int:\n    \"\"\"\n    Add a relative pose\u2013landmark constraint for an agent at time ``t``.\n\n    This is a small ergonomic wrapper around\n    :meth:`add_pose_landmark_relative` that resolves the pose id using\n    :attr:`pose_trajectory`.\n\n    :param agent: Agent identifier.\n    :param t: Timestep index for the pose.\n    :param landmark_id: Node id of the 3D landmark variable.\n    :param measurement: Iterable of length 3 giving the expected landmark\n        position in the pose frame.\n    :param sigma: Optional noise standard deviation. If ``None``, falls back\n        to :attr:`SceneGraphNoiseConfig.pose_landmark_sigma`.\n    :return: Integer factor id of the created relative landmark constraint.\n    :raises KeyError: If no pose has been registered for ``(agent, t)``.\n    \"\"\"\n    key = (agent, t)\n    if key not in self.pose_trajectory:\n        raise KeyError(f\"No pose registered for agent={agent!r}, t={t}\")\n\n    pose_id = self.pose_trajectory[key]\n    return self.add_pose_landmark_relative(\n        pose_id=pose_id,\n        landmark_id=landmark_id,\n        measurement=measurement,\n        sigma=sigma,\n    )\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_agent_pose_place_attachment","title":"<code>add_agent_pose_place_attachment(agent, t, place_id, coord_index=0, sigma=None)</code>","text":"<p>Attach an agent pose at time <code>t</code> to a place node.</p> <p>This is a higher-level wrapper around :meth:<code>add_place_attachment</code> which resolves the pose id via :attr:<code>pose_trajectory</code>.</p> <p>:param agent: Agent identifier. :param t: Integer timestep index. :param place_id: Node id of the place variable (1D or 3D). :param coord_index: Index of the pose coordinate to tie to the place     (typically 0 for x, 1 for y, etc.). Defaults to 0. :param sigma: Optional noise standard deviation. If <code>None</code>, falls back     to :attr:<code>SceneGraphNoiseConfig.pose_place_sigma</code>. :return: Integer factor id of the created attachment constraint. :raises KeyError: If no pose has been registered for <code>(agent, t)</code>.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_agent_pose_place_attachment(\n    self,\n    agent: str,\n    t: int,\n    place_id: int,\n    coord_index: int = 0,\n    sigma: float | None = None,\n) -&gt; int:\n    \"\"\"\n    Attach an agent pose at time ``t`` to a place node.\n\n    This is a higher-level wrapper around :meth:`add_place_attachment`\n    which resolves the pose id via :attr:`pose_trajectory`.\n\n    :param agent: Agent identifier.\n    :param t: Integer timestep index.\n    :param place_id: Node id of the place variable (1D or 3D).\n    :param coord_index: Index of the pose coordinate to tie to the place\n        (typically 0 for x, 1 for y, etc.). Defaults to 0.\n    :param sigma: Optional noise standard deviation. If ``None``, falls back\n        to :attr:`SceneGraphNoiseConfig.pose_place_sigma`.\n    :return: Integer factor id of the created attachment constraint.\n    :raises KeyError: If no pose has been registered for ``(agent, t)``.\n    \"\"\"\n    pose_key = (agent, t)\n    if pose_key not in self.pose_trajectory:\n        raise KeyError(f\"No pose registered for agent={agent!r}, t={t}\")\n\n    pose_id = self.pose_trajectory[pose_key]\n    return self.add_place_attachment(\n        pose_id=pose_id,\n        place_id=place_id,\n        coord_index=coord_index,\n        sigma=sigma,\n    )\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_agent_pose_se3","title":"<code>add_agent_pose_se3(agent, t, value)</code>","text":"<p>Add an SE(3) pose for a given agent at a specific timestep.</p> <p>:param agent: Agent identifier (for example, a robot name). :param t: Integer timestep index. :param value: Length-6 array-like se(3) vector for the pose. :return: Integer node id of the created pose variable.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_agent_pose_se3(self, agent: str, t: int, value: jnp.ndarray) -&gt; int:\n    \"\"\"\n    Add an SE(3) pose for a given agent at a specific timestep.\n\n    :param agent: Agent identifier (for example, a robot name).\n    :param t: Integer timestep index.\n    :param value: Length-6 array-like se(3) vector for the pose.\n    :return: Integer node id of the created pose variable.\n    \"\"\"\n    if self._active_template_enabled:\n        nid_int = int(self._assign_var_slot(\"pose_se3\", jnp.asarray(value)))\n    else:\n        nid_int = int(self.wm.add_variable(\"pose_se3\", value))\n    self._remember_node(nid_int, \"pose_se3\", jnp.asarray(value))\n    self.pose_trajectory[(agent, t)] = nid_int\n    return nid_int\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_agent_pose_voxel_point","title":"<code>add_agent_pose_voxel_point(agent, t, voxel_id, point_meas, sigma=None)</code>","text":"<p>Constrain a voxel cell using a point measurement from an agent pose.</p> <p>This wraps :meth:<code>add_pose_voxel_point</code> and resolves the pose id from :attr:<code>pose_trajectory</code>.</p> <p>:param agent: Agent identifier. :param t: Timestep index for the pose. :param voxel_id: Node id of the voxel cell variable. :param point_meas: Iterable of length 3 giving a point in the pose     frame (for example, a back-projected LiDAR or depth sample). :param sigma: Optional noise standard deviation. If <code>None</code>, falls     back to :attr:<code>SceneGraphNoiseConfig.pose_voxel_point_sigma</code>. :return: Integer factor id of the created voxel-point constraint. :raises KeyError: If no pose has been registered for <code>(agent, t)</code>.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_agent_pose_voxel_point(\n    self,\n    agent: str,\n    t: int,\n    voxel_id: int,\n    point_meas,\n    sigma: float | None = None,\n) -&gt; int:\n    \"\"\"\n    Constrain a voxel cell using a point measurement from an agent pose.\n\n    This wraps :meth:`add_pose_voxel_point` and resolves the pose id from\n    :attr:`pose_trajectory`.\n\n    :param agent: Agent identifier.\n    :param t: Timestep index for the pose.\n    :param voxel_id: Node id of the voxel cell variable.\n    :param point_meas: Iterable of length 3 giving a point in the pose\n        frame (for example, a back-projected LiDAR or depth sample).\n    :param sigma: Optional noise standard deviation. If ``None``, falls\n        back to :attr:`SceneGraphNoiseConfig.pose_voxel_point_sigma`.\n    :return: Integer factor id of the created voxel-point constraint.\n    :raises KeyError: If no pose has been registered for ``(agent, t)``.\n    \"\"\"\n    key = (agent, t)\n    if key not in self.pose_trajectory:\n        raise KeyError(f\"No pose registered for agent={agent!r}, t={t}\")\n\n    pose_id = self.pose_trajectory[key]\n    return self.add_pose_voxel_point(\n        pose_id=pose_id,\n        voxel_id=voxel_id,\n        point_meas=point_meas,\n        sigma=sigma,\n    )\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_agent_range_measurement","title":"<code>add_agent_range_measurement(agent, t, target_nid, measured_range, sigma=None, weight=None)</code>","text":"<p>Add a range-only factor using an agent's pose at a given timestep.</p> <p>This is a convenience wrapper around :meth:<code>add_range_measurement</code> that looks up the pose node id from :attr:<code>pose_trajectory</code> using <code>(agent, t)</code> and then creates a <code>\"range\"</code> factor to a target node.</p> <p>:param agent: Agent identifier (for example, a robot name). :param t: Integer timestep index for the agent pose. :param target_nid: NodeId of the target variable (for example, <code>place3d</code>,     <code>voxel_cell</code> or <code>object3d</code>). :param measured_range: Observed distance (same units as the world coordinates). :param sigma: Optional standard deviation of the measurement noise. If     provided (and <code>weight</code> is <code>None</code>), it is converted to a weight via     :func:<code>slam.measurements.sigma_to_weight</code>. :param weight: Optional explicit weight. If both <code>sigma</code> and <code>weight</code>     are given, <code>weight</code> takes precedence. :return: Integer factor id of the created range factor. :raises KeyError: If no pose has been registered for <code>(agent, t)</code>.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_agent_range_measurement(\n    self,\n    agent: str,\n    t: int,\n    target_nid: int,\n    measured_range: float,\n    sigma: float | None = None,\n    weight: float | None = None,\n) -&gt; int:\n    \"\"\"\n    Add a range-only factor using an agent's pose at a given timestep.\n\n    This is a convenience wrapper around :meth:`add_range_measurement`\n    that looks up the pose node id from :attr:`pose_trajectory` using\n    ``(agent, t)`` and then creates a ``\"range\"`` factor to a target node.\n\n    :param agent: Agent identifier (for example, a robot name).\n    :param t: Integer timestep index for the agent pose.\n    :param target_nid: NodeId of the target variable (for example, ``place3d``,\n        ``voxel_cell`` or ``object3d``).\n    :param measured_range: Observed distance (same units as the world coordinates).\n    :param sigma: Optional standard deviation of the measurement noise. If\n        provided (and ``weight`` is ``None``), it is converted to a weight via\n        :func:`slam.measurements.sigma_to_weight`.\n    :param weight: Optional explicit weight. If both ``sigma`` and ``weight``\n        are given, ``weight`` takes precedence.\n    :return: Integer factor id of the created range factor.\n    :raises KeyError: If no pose has been registered for ``(agent, t)``.\n    \"\"\"\n    pose_key = (agent, t)\n    if pose_key not in self.pose_trajectory:\n        raise KeyError(f\"No pose registered for agent={agent!r}, t={t}\")\n\n    pose_nid = self.pose_trajectory[pose_key]\n    return self.add_range_measurement(\n        pose_nid=pose_nid,\n        target_nid=target_nid,\n        measured_range=measured_range,\n        sigma=sigma,\n        weight=weight,\n    )\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_agent_temporal_smoothness","title":"<code>add_agent_temporal_smoothness(agent, t, sigma=None)</code>","text":"<p>Enforce temporal smoothness between successive poses of a given agent.</p> <p>This enforces a smoothness constraint between the poses at timesteps <code>t</code> and <code>t+1</code> for the specified agent, using :meth:<code>add_temporal_smoothness</code> internally.</p> <p>:param agent: Agent identifier. :param t: Timestep index for the first pose in the pair. :param sigma: Optional standard deviation controlling smoothness. If     <code>None</code>, falls back to :attr:<code>SceneGraphNoiseConfig.smooth_pose_sigma</code>. :return: Integer factor id of the created smoothness constraint. :raises KeyError: If either pose <code>(agent, t)</code> or <code>(agent, t+1)</code> has     not been registered.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_agent_temporal_smoothness(\n    self,\n    agent: str,\n    t: int,\n    sigma: float | None = None,\n) -&gt; int:\n    \"\"\"\n    Enforce temporal smoothness between successive poses of a given agent.\n\n    This enforces a smoothness constraint between the poses at timesteps\n    ``t`` and ``t+1`` for the specified agent, using\n    :meth:`add_temporal_smoothness` internally.\n\n    :param agent: Agent identifier.\n    :param t: Timestep index for the first pose in the pair.\n    :param sigma: Optional standard deviation controlling smoothness. If\n        ``None``, falls back to :attr:`SceneGraphNoiseConfig.smooth_pose_sigma`.\n    :return: Integer factor id of the created smoothness constraint.\n    :raises KeyError: If either pose ``(agent, t)`` or ``(agent, t+1)`` has\n        not been registered.\n    \"\"\"\n    key_t = (agent, t)\n    key_t1 = (agent, t + 1)\n\n    if key_t not in self.pose_trajectory:\n        raise KeyError(f\"No pose registered for agent={agent!r}, t={t}\")\n    if key_t1 not in self.pose_trajectory:\n        raise KeyError(f\"No pose registered for agent={agent!r}, t={t+1}\")\n\n    pose_id_t = self.pose_trajectory[key_t]\n    pose_id_t1 = self.pose_trajectory[key_t1]\n    return self.add_temporal_smoothness(\n        pose_id_t=pose_id_t,\n        pose_id_t1=pose_id_t1,\n        sigma=sigma,\n    )\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_landmark3d","title":"<code>add_landmark3d(xyz)</code>","text":"<p>Add a 3D landmark node (R^3).</p> <p>:param xyz: Iterable of length 3 giving world coordinates. :return: Integer node id of the created landmark variable.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_landmark3d(self, xyz) -&gt; int:\n    \"\"\"\n    Add a 3D landmark node (R^3).\n\n    :param xyz: Iterable of length 3 giving world coordinates.\n    :return: Integer node id of the created landmark variable.\n    \"\"\"\n    value = jnp.array(xyz, dtype=jnp.float32).reshape(3,)\n    if self._active_template_enabled:\n        nid_int = int(self._assign_var_slot(\"landmark3d\", value))\n    else:\n        nid_int = int(self.wm.add_variable(\"landmark3d\", value))\n    self._remember_node(nid_int, \"landmark3d\", value)\n    return nid_int\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_named_object3d","title":"<code>add_named_object3d(name, xyz)</code>","text":"<p>Add a 3D object and register it under a semantic name.</p> <p>:param name: Identifier for the object (for example, <code>\"chair_1\"</code>). :param xyz: Iterable of length 3 giving the world-frame position. :return: Integer node id of the created object variable.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_named_object3d(self, name: str, xyz) -&gt; int:\n    \"\"\"\n    Add a 3D object and register it under a semantic name.\n\n    :param name: Identifier for the object (for example, ``\"chair_1\"``).\n    :param xyz: Iterable of length 3 giving the world-frame position.\n    :return: Integer node id of the created object variable.\n    \"\"\"\n    obj_id = self.add_object3d(xyz)\n    self.object_nodes[name] = obj_id\n    return obj_id\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_object3d","title":"<code>add_object3d(xyz)</code>","text":"<p>Add an object with 3D position (R^3).</p> <p>:param xyz: Iterable of length 3 giving the object position in     world coordinates. :return: Integer node id of the created object variable.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_object3d(self, xyz) -&gt; int:\n    \"\"\"\n    Add an object with 3D position (R^3).\n\n    :param xyz: Iterable of length 3 giving the object position in\n        world coordinates.\n    :return: Integer node id of the created object variable.\n    \"\"\"\n    xyz = jnp.array(xyz, dtype=jnp.float32).reshape(3,)\n    if self._active_template_enabled:\n        nid_int = int(self._assign_var_slot(\"object3d\", xyz))\n    else:\n        nid_int = int(self.wm.add_variable(\"object3d\", xyz))\n    self._remember_node(nid_int, \"object3d\", xyz)\n    return nid_int\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_object_room_edge","title":"<code>add_object_room_edge(object_id, room_id)</code>","text":"<p>Register a semantic edge between an object node and a room node.</p> <p>This helper is intentionally lightweight: it does not add a numeric factor to the underlying factor graph. Instead it records topological connectivity for visualization and higher-level reasoning, similar to classic dynamic scene-graph frameworks.</p> <p>:param object_id: Integer node id of the object variable. :param room_id: Integer node id of the room variable. :return: None.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_object_room_edge(self, object_id: int, room_id: int) -&gt; None:\n    \"\"\"\n    Register a semantic edge between an object node and a room node.\n\n    This helper is intentionally lightweight: it does *not* add a numeric\n    factor to the underlying factor graph. Instead it records topological\n    connectivity for visualization and higher-level reasoning, similar to\n    classic dynamic scene-graph frameworks.\n\n    :param object_id: Integer node id of the object variable.\n    :param room_id: Integer node id of the room variable.\n    :return: None.\n    \"\"\"\n    self.object_room_edges.append((int(object_id), int(room_id)))\n    # Also register in the SceneGraph's factor memory for visualization.\n    self._remember_factor(\n        f_type=\"semantic_object_room\",\n        var_ids=(int(object_id), int(room_id)),\n        params={},\n        relation=\"object-room\",\n    )\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_odom_se3_additive","title":"<code>add_odom_se3_additive(pose_i, pose_j, dx, sigma=None)</code>","text":"<p>Add an additive SE(3) odometry factor in R^6.</p> <p>The measurement is a translation along the x-axis plus zero rotation.</p> <p>:param pose_i: Node id of the source pose. :param pose_j: Node id of the destination pose. :param dx: Translation along the x-axis in meters. :param sigma: Optional standard deviation for the odometry noise. If     <code>None</code>, :attr:<code>SceneGraphNoiseConfig.odom_se3_sigma</code> is used. :return: Integer factor id of the created odometry constraint.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_odom_se3_additive(\n    self,\n    pose_i: int,\n    pose_j: int,\n    dx: float,\n    sigma: float | None = None,\n) -&gt; int:\n    \"\"\"\n    Add an additive SE(3) odometry factor in R^6.\n\n    The measurement is a translation along the x-axis plus zero rotation.\n\n    :param pose_i: Node id of the source pose.\n    :param pose_j: Node id of the destination pose.\n    :param dx: Translation along the x-axis in meters.\n    :param sigma: Optional standard deviation for the odometry noise. If\n        ``None``, :attr:`SceneGraphNoiseConfig.odom_se3_sigma` is used.\n    :return: Integer factor id of the created odometry constraint.\n    \"\"\"\n    meas = jnp.array([dx, 0.0, 0.0, 0.0, 0.0, 0.0])\n\n    if sigma is None:\n        sigma = self.noise.odom_se3_sigma\n\n    weight = sigma_to_weight(sigma)\n\n    params = {\n        \"measurement\": meas,\n        \"weight\": weight,\n    }\n    remembered = self._remember_factor(\n        f_type=\"odom_se3\",\n        var_ids=(pose_i, pose_j),\n        params=params,\n        relation=\"factor:odom_se3\",\n    )\n    if self._active_template_enabled:\n        self._assign_factor_slot(\"odom_se3\", (pose_i, pose_j), params, active=True)\n        return int(remembered)\n\n    fid = self.wm.add_factor(\n        \"odom_se3\",\n        (pose_i, pose_j),\n        params,\n    )\n    return int(fid)\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_odom_se3_geodesic","title":"<code>add_odom_se3_geodesic(pose_i, pose_j, dx, yaw=0.0, sigma=None)</code>","text":"<p>Add a geodesic SE(3) odometry factor.</p> <p>The measurement is parameterized as translation + yaw in se(3).</p> <p>:param pose_i: Node id of the source pose. :param pose_j: Node id of the destination pose. :param dx: Translation along the x-axis in meters. :param yaw: Heading change around the z-axis in radians. :param sigma: Optional standard deviation for the odometry noise. If     <code>None</code>, :attr:<code>SceneGraphNoiseConfig.odom_se3_sigma</code> is used. :return: Integer factor id of the created odometry constraint.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_odom_se3_geodesic(\n    self,\n    pose_i: int,\n    pose_j: int,\n    dx: float,\n    yaw: float = 0.0,\n    sigma: float | None = None,\n) -&gt; int:\n    \"\"\"\n    Add a geodesic SE(3) odometry factor.\n\n    The measurement is parameterized as translation + yaw in se(3).\n\n    :param pose_i: Node id of the source pose.\n    :param pose_j: Node id of the destination pose.\n    :param dx: Translation along the x-axis in meters.\n    :param yaw: Heading change around the z-axis in radians.\n    :param sigma: Optional standard deviation for the odometry noise. If\n        ``None``, :attr:`SceneGraphNoiseConfig.odom_se3_sigma` is used.\n    :return: Integer factor id of the created odometry constraint.\n    \"\"\"\n    meas = jnp.array([dx, 0.0, 0.0, 0.0, 0.0, yaw])\n\n    if sigma is None:\n        sigma = self.noise.odom_se3_sigma\n\n    weight = sigma_to_weight(sigma)\n\n    params = {\n        \"measurement\": meas,\n        \"weight\": weight,\n    }\n    remembered = self._remember_factor(\n        f_type=\"odom_se3_geodesic\",\n        var_ids=(pose_i, pose_j),\n        params=params,\n        relation=\"factor:odom_se3_geodesic\",\n    )\n    if self._active_template_enabled:\n        self._assign_factor_slot(\"odom_se3_geodesic\", (pose_i, pose_j), params, active=True)\n        return int(remembered)\n\n    fid = self.wm.add_factor(\n        \"odom_se3_geodesic\",\n        (pose_i, pose_j),\n        params,\n    )\n    return int(fid)\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_place1d","title":"<code>add_place1d(x)</code>","text":"<p>Add a 1D place variable.</p> <p>:param x: Scalar position along a 1D axis (e.g. corridor coordinate). :return: Integer node id of the created place variable.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_place1d(self, x: float) -&gt; int:\n    \"\"\"\n    Add a 1D place variable.\n\n    :param x: Scalar position along a 1D axis (e.g. corridor coordinate).\n    :return: Integer node id of the created place variable.\n    \"\"\"\n    value = jnp.array([x], dtype=jnp.float32)\n    if self._active_template_enabled:\n        nid = int(self._assign_var_slot(\"place1d\", value))\n    else:\n        nid = int(self.wm.add_variable(\"place1d\", value))\n    self._remember_node(nid, \"place1d\", value)\n    return nid\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_place3d","title":"<code>add_place3d(name, xyz)</code>","text":"<p>Add a 3D place node (R^3) with a human-readable name.</p> <p>This is a semantic helper for dynamic scene-graph style usage.</p> <p>:param name: Identifier for the place (for example, <code>\"place_A\"</code>). :param xyz: Iterable of length 3 giving the world-frame position. :return: Integer node id of the created place variable.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_place3d(self, name: str, xyz) -&gt; int:\n    \"\"\"\n    Add a 3D place node (R^3) with a human-readable name.\n\n    This is a semantic helper for dynamic scene-graph style usage.\n\n    :param name: Identifier for the place (for example, ``\"place_A\"``).\n    :param xyz: Iterable of length 3 giving the world-frame position.\n    :return: Integer node id of the created place variable.\n    \"\"\"\n    value = jnp.array(xyz, dtype=jnp.float32).reshape(3,)\n    if self._active_template_enabled:\n        nid_int = int(self._assign_var_slot(\"place3d\", value))\n    else:\n        nid_int = int(self.wm.add_variable(\"place3d\", value))\n    self._remember_node(nid_int, \"place3d\", value)\n    self.place_nodes[name] = nid_int\n    return nid_int\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_place_attachment","title":"<code>add_place_attachment(pose_id, place_id, coord_index=0, sigma=None)</code>","text":"<p>Attach a SE(3) pose to a place node (1D or 3D).</p> <p>This is a higher-level, dimension-aware wrapper around the <code>pose_place_attachment</code> residual, and is intended for scene-graph style experiments where places may be either 1D (topological) or 3D (metric positions).</p> <p>:param pose_id: Node id of the SE(3) pose variable. :param place_id: Node id of the place variable. The underlying state     dimension is inferred at runtime from the factor graph (for     example, 1 for <code>place1d</code> or 3 for <code>place3d</code>). :param coord_index: Index of the pose coordinate to tie to the place     (typically 0 for x, 1 for y, etc.). Defaults to 0. :param sigma: Optional noise standard deviation. If <code>None</code>, falls     back to :attr:<code>SceneGraphNoiseConfig.pose_place_sigma</code>. :return: Integer factor id of the created attachment constraint.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_place_attachment(\n    self,\n    pose_id: int,\n    place_id: int,\n    coord_index: int = 0,\n    sigma: float | None = None,\n) -&gt; int:\n    \"\"\"\n    Attach a SE(3) pose to a place node (1D or 3D).\n\n    This is a higher-level, dimension-aware wrapper around the\n    ``pose_place_attachment`` residual, and is intended for scene-graph\n    style experiments where places may be either 1D (topological) or\n    3D (metric positions).\n\n    :param pose_id: Node id of the SE(3) pose variable.\n    :param place_id: Node id of the place variable. The underlying state\n        dimension is inferred at runtime from the factor graph (for\n        example, 1 for ``place1d`` or 3 for ``place3d``).\n    :param coord_index: Index of the pose coordinate to tie to the place\n        (typically 0 for x, 1 for y, etc.). Defaults to 0.\n    :param sigma: Optional noise standard deviation. If ``None``, falls\n        back to :attr:`SceneGraphNoiseConfig.pose_place_sigma`.\n    :return: Integer factor id of the created attachment constraint.\n    \"\"\"\n    # Infer place dimensionality from the underlying variable.\n    place_nid = NodeId(place_id)\n    place_var = self.wm.fg.variables[place_nid]\n    place_dim_val = place_var.value.shape[0]\n\n    pose_dim = jnp.array(6)\n    place_dim = jnp.array(place_dim_val)\n    pose_coord_index = jnp.array(coord_index)\n\n    if sigma is None:\n        sigma = self.noise.pose_place_sigma\n    weight = sigma_to_weight(sigma)\n\n    params = {\n        \"pose_dim\": pose_dim,\n        \"place_dim\": place_dim,\n        \"pose_coord_index\": pose_coord_index,\n        \"weight\": weight,\n    }\n    remembered = self._remember_factor(\n        f_type=\"pose_place_attachment\",\n        var_ids=(pose_id, place_id),\n        params=params,\n        relation=\"pose-place\",\n    )\n    if self._active_template_enabled:\n        self._assign_factor_slot(\"pose_place_attachment\", (pose_id, place_id), params, active=True)\n        return int(remembered)\n\n    fid = self.wm.add_factor(\n        \"pose_place_attachment\",\n        (pose_id, place_id),\n        params,\n    )\n    return int(fid)\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_pose_landmark_bearing","title":"<code>add_pose_landmark_bearing(pose_id, landmark_id, bearing, sigma=None)</code>","text":"<p>Add a bearing-only constraint from pose to landmark.</p> <p>:param pose_id: Node id of the SE(3) pose variable. :param landmark_id: Node id of the 3D landmark variable. :param bearing: Iterable of length 3 giving the bearing vector in the     pose frame (will be normalized internally). :param sigma: Optional noise standard deviation. If <code>None</code>,     :attr:<code>SceneGraphNoiseConfig.pose_landmark_bearing_sigma</code> is used. :return: Integer factor id of the created bearing constraint.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_pose_landmark_bearing(\n    self,\n    pose_id: int,\n    landmark_id: int,\n    bearing,\n    sigma: float | None = None,\n) -&gt; int:\n    \"\"\"\n    Add a bearing-only constraint from pose to landmark.\n\n    :param pose_id: Node id of the SE(3) pose variable.\n    :param landmark_id: Node id of the 3D landmark variable.\n    :param bearing: Iterable of length 3 giving the bearing vector in the\n        pose frame (will be normalized internally).\n    :param sigma: Optional noise standard deviation. If ``None``,\n        :attr:`SceneGraphNoiseConfig.pose_landmark_bearing_sigma` is used.\n    :return: Integer factor id of the created bearing constraint.\n    \"\"\"\n    b = jnp.array(bearing, dtype=jnp.float32).reshape(3,)\n    b = b / (jnp.linalg.norm(b) + 1e-8)\n\n    if sigma is None:\n        sigma = self.noise.pose_landmark_bearing_sigma\n    weight = sigma_to_weight(sigma)\n\n    params = {\n        \"bearing_meas\": b,\n        \"weight\": weight,\n    }\n    remembered = self._remember_factor(\n        f_type=\"pose_landmark_bearing\",\n        var_ids=(pose_id, landmark_id),\n        params=params,\n        relation=\"factor:pose_landmark_bearing\",\n    )\n    if self._active_template_enabled:\n        self._assign_factor_slot(\"pose_landmark_bearing\", (pose_id, landmark_id), params, active=True)\n        return int(remembered)\n\n    fid = self.wm.add_factor(\n        \"pose_landmark_bearing\",\n        (pose_id, landmark_id),\n        params,\n    )\n    return int(fid)\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_pose_landmark_relative","title":"<code>add_pose_landmark_relative(pose_id, landmark_id, measurement, sigma=None)</code>","text":"<p>Add a relative measurement between a pose and a 3D landmark.</p> <p>The measurement is expressed in the pose frame.</p> <p>:param pose_id: Node id of the SE(3) pose variable. :param landmark_id: Node id of the 3D landmark variable. :param measurement: Iterable of length 3 giving the expected landmark     position in the pose frame. :param sigma: Optional noise standard deviation. If <code>None</code>,     :attr:<code>SceneGraphNoiseConfig.pose_landmark_sigma</code> is used. :return: Integer factor id of the created relative landmark constraint.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_pose_landmark_relative(\n    self,\n    pose_id: int,\n    landmark_id: int,\n    measurement,\n    sigma: float | None = None,\n) -&gt; int:\n    \"\"\"\n    Add a relative measurement between a pose and a 3D landmark.\n\n    The measurement is expressed in the pose frame.\n\n    :param pose_id: Node id of the SE(3) pose variable.\n    :param landmark_id: Node id of the 3D landmark variable.\n    :param measurement: Iterable of length 3 giving the expected landmark\n        position in the pose frame.\n    :param sigma: Optional noise standard deviation. If ``None``,\n        :attr:`SceneGraphNoiseConfig.pose_landmark_sigma` is used.\n    :return: Integer factor id of the created relative landmark constraint.\n    \"\"\"\n    meas = jnp.array(measurement, dtype=jnp.float32).reshape(3,)\n\n    if sigma is None:\n        sigma = self.noise.pose_landmark_sigma\n    weight = sigma_to_weight(sigma)\n\n    params = {\n        \"measurement\": meas,\n        \"weight\": weight,\n    }\n    remembered = self._remember_factor(\n        f_type=\"pose_landmark_relative\",\n        var_ids=(pose_id, landmark_id),\n        params=params,\n        relation=\"factor:pose_landmark_relative\",\n    )\n    if self._active_template_enabled:\n        self._assign_factor_slot(\"pose_landmark_relative\", (pose_id, landmark_id), params, active=True)\n        return int(remembered)\n\n    fid = self.wm.add_factor(\n        \"pose_landmark_relative\",\n        (pose_id, landmark_id),\n        params,\n    )\n    return int(fid)\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_pose_se3","title":"<code>add_pose_se3(value)</code>","text":"<p>Add a generic SE(3) pose variable.</p> <p>:param value: Length-6 array-like se(3) vector [tx, ty, tz, rx, ry, rz]. :return: Integer node id of the created pose variable.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_pose_se3(self, value: jnp.ndarray) -&gt; int:\n    \"\"\"\n    Add a generic SE(3) pose variable.\n\n    :param value: Length-6 array-like se(3) vector [tx, ty, tz, rx, ry, rz].\n    :return: Integer node id of the created pose variable.\n    \"\"\"\n    if self._active_template_enabled:\n        nid = int(self._assign_var_slot(\"pose_se3\", jnp.asarray(value)))\n    else:\n        nid = int(self.wm.add_variable(\"pose_se3\", value))\n    self._remember_node(nid, \"pose_se3\", jnp.asarray(value))\n    return nid\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_pose_voxel_point","title":"<code>add_pose_voxel_point(pose_id, voxel_id, point_meas, sigma=None)</code>","text":"<p>Constrain a voxel cell to align with a point measurement seen from a pose.</p> <p>:param pose_id: Node id of the SE(3) pose variable. :param voxel_id: Node id of the voxel cell variable. :param point_meas: Iterable of length 3 giving a point in the pose     frame (for example, a back-projected depth sample). :param sigma: Optional noise standard deviation. If <code>None</code>,     :attr:<code>SceneGraphNoiseConfig.pose_voxel_point_sigma</code> is used. :return: Integer factor id of the created voxel-point constraint.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_pose_voxel_point(\n    self,\n    pose_id: int,\n    voxel_id: int,\n    point_meas,\n    sigma: float | None = None,\n) -&gt; int:\n    \"\"\"\n    Constrain a voxel cell to align with a point measurement seen from a pose.\n\n    :param pose_id: Node id of the SE(3) pose variable.\n    :param voxel_id: Node id of the voxel cell variable.\n    :param point_meas: Iterable of length 3 giving a point in the pose\n        frame (for example, a back-projected depth sample).\n    :param sigma: Optional noise standard deviation. If ``None``,\n        :attr:`SceneGraphNoiseConfig.pose_voxel_point_sigma` is used.\n    :return: Integer factor id of the created voxel-point constraint.\n    \"\"\"\n    point_meas = jnp.array(point_meas, dtype=jnp.float32).reshape(3,)\n\n    if sigma is None:\n        sigma = self.noise.pose_voxel_point_sigma\n    weight = sigma_to_weight(sigma)\n\n    params = {\n        \"point_meas\": point_meas,\n        \"weight\": weight,\n    }\n    remembered = self._remember_factor(\n        f_type=\"pose_voxel_point\",\n        var_ids=(pose_id, voxel_id),\n        params=params,\n        relation=\"factor:pose_voxel_point\",\n    )\n    if self._active_template_enabled:\n        self._assign_factor_slot(\"pose_voxel_point\", (pose_id, voxel_id), params, active=True)\n        return int(remembered)\n\n    fid = self.wm.add_factor(\n        \"pose_voxel_point\",\n        (pose_id, voxel_id),\n        params,\n    )\n    return int(fid)\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_range_measurement","title":"<code>add_range_measurement(pose_nid, target_nid, measured_range, sigma=None, weight=None)</code>","text":"<p>Add a range-only sensor factor between a pose and a 3D target.</p> <p>This creates a factor of type <code>\"range\"</code> whose residual is:</p> <pre><code>r = ||target - pose|| - measured_range\n</code></pre> <p>The underlying residual is implemented in <code>slam.measurements.range_residual</code>.</p> <p>:param pose_nid: NodeId of the pose (pose_se3) variable. :param target_nid: NodeId of the target variable (e.g. place3d, voxel_cell, object3d). :param measured_range: Observed distance (same units as world coordinates). :param sigma: Optional standard deviation of the measurement noise. If provided,               it will be converted to a weight as 1 / sigma^2. :param weight: Optional explicit weight. If both <code>sigma</code> and <code>weight</code> are given,                <code>weight</code> takes precedence. :return: Integer factor id of the created range factor.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_range_measurement(\n    self,\n    pose_nid: int,\n    target_nid: int,\n    measured_range: float,\n    sigma: float | None = None,\n    weight: float | None = None,\n) -&gt; int:\n    \"\"\"\n    Add a range-only sensor factor between a pose and a 3D target.\n\n    This creates a factor of type ``\"range\"`` whose residual is:\n\n        r = ||target - pose|| - measured_range\n\n    The underlying residual is implemented in ``slam.measurements.range_residual``.\n\n    :param pose_nid: NodeId of the pose (pose_se3) variable.\n    :param target_nid: NodeId of the target variable (e.g. place3d, voxel_cell, object3d).\n    :param measured_range: Observed distance (same units as world coordinates).\n    :param sigma: Optional standard deviation of the measurement noise. If provided,\n                  it will be converted to a weight as 1 / sigma^2.\n    :param weight: Optional explicit weight. If both ``sigma`` and ``weight`` are given,\n                   ``weight`` takes precedence.\n    :return: Integer factor id of the created range factor.\n    \"\"\"\n    if weight is not None:\n        w = float(weight)\n    elif sigma is not None:\n        w = sigma_to_weight(sigma)\n    else:\n        w = 1.0\n\n    meas = jnp.array([float(measured_range)], dtype=jnp.float32)\n    params = {\"range\": meas, \"weight\": w}\n    remembered = self._remember_factor(\n        f_type=\"range\",\n        var_ids=(pose_nid, target_nid),\n        params=params,\n        relation=\"factor:range\",\n    )\n    if self._active_template_enabled:\n        self._assign_factor_slot(\"range\", (pose_nid, target_nid), params, active=True)\n        return int(remembered)\n\n    fid = self.wm.add_factor(\n        \"range\",\n        (pose_nid, target_nid),\n        params,\n    )\n    return int(fid)\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_room","title":"<code>add_room(name, center)</code>","text":"<p>Add a 3D room node (R^3 center) with a semantic name.</p> <p>This is a thin wrapper around a Euclidean variable, but exposes a room-level abstraction for dynamic scene-graph experiments.</p> <p>:param name: Identifier for the room (for example, <code>\"room_A\"</code>). :param center: Iterable of length 3 giving the approximate room     centroid in world coordinates. :return: Integer node id of the created room variable.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_room(self, name: str, center) -&gt; int:\n    \"\"\"\n    Add a 3D room node (R^3 center) with a semantic name.\n\n    This is a thin wrapper around a Euclidean variable, but exposes a\n    room-level abstraction for dynamic scene-graph experiments.\n\n    :param name: Identifier for the room (for example, ``\"room_A\"``).\n    :param center: Iterable of length 3 giving the approximate room\n        centroid in world coordinates.\n    :return: Integer node id of the created room variable.\n    \"\"\"\n    value = jnp.array(center, dtype=jnp.float32).reshape(3,)\n    if self._active_template_enabled:\n        nid_int = int(self._assign_var_slot(\"room3d\", value))\n    else:\n        nid_int = int(self.wm.add_variable(\"room3d\", value))\n    self._remember_node(nid_int, \"room3d\", value)\n    self.room_nodes[name] = nid_int\n    return nid_int\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_room1d","title":"<code>add_room1d(x)</code>","text":"<p>Add a 1D 'room' variable (just a scalar, wrapped as a length-1 vector).</p> <p>The room is stored in :attr:<code>room_nodes</code> using an auto-generated string key of the form <code>\"room1d_{k}\"</code> where <code>k</code> is the current number of rooms.</p> <p>:param x: 1D coordinate, shape <code>(1,)</code> or a scalar float. :return: Integer node id of the created room variable.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_room1d(self, x: jnp.ndarray) -&gt; int:\n    \"\"\"\n    Add a 1D 'room' variable (just a scalar, wrapped as a length-1 vector).\n\n    The room is stored in :attr:`room_nodes` using an auto-generated\n    string key of the form ``\"room1d_{k}\"`` where ``k`` is the current\n    number of rooms.\n\n    :param x: 1D coordinate, shape ``(1,)`` or a scalar float.\n    :return: Integer node id of the created room variable.\n    \"\"\"\n    # Normalize to a length-1 float32 vector.\n    if isinstance(x, float) or (hasattr(x, \"ndim\") and x.ndim == 0):\n        x = jnp.array([float(x)], dtype=jnp.float32)\n\n    x = jnp.array(x, dtype=jnp.float32).reshape((1,))\n\n    if self._active_template_enabled:\n        nid = int(self._assign_var_slot(\"room1d\", x))\n    else:\n        nid = int(self.wm.add_variable(\"room1d\", x))  # after normalizing x\n    self._remember_node(nid, \"room1d\", x)\n    name = f\"room1d_{len(self.room_nodes)}\"\n    self.room_nodes[name] = nid\n    return nid\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_room_place_edge","title":"<code>add_room_place_edge(room_id, place_id)</code>","text":"<p>Register a semantic edge between a room node and a place node.</p> <p>This helper is intentionally lightweight: it does not add a numeric factor to the underlying factor graph. Instead it records topological connectivity for visualization and higher-level reasoning, similar to classic dynamic scene-graph frameworks.</p> <p>:param room_id: Integer node id of the room variable. :param place_id: Integer node id of the place variable. :return: None.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_room_place_edge(self, room_id: int, place_id: int) -&gt; None:\n    \"\"\"\n    Register a semantic edge between a room node and a place node.\n\n    This helper is intentionally lightweight: it does *not* add a numeric\n    factor to the underlying factor graph. Instead it records topological\n    connectivity for visualization and higher-level reasoning, similar to\n    classic dynamic scene-graph frameworks.\n\n    :param room_id: Integer node id of the room variable.\n    :param place_id: Integer node id of the place variable.\n    :return: None.\n    \"\"\"\n    self.room_place_edges.append((int(room_id), int(place_id)))\n    # Also register in the SceneGraph's factor memory for visualization.\n    self._remember_factor(\n        f_type=\"semantic_room_place\",\n        var_ids=(int(room_id), int(place_id)),\n        params={},\n        relation=\"room-place\",\n    )\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_temporal_smoothness","title":"<code>add_temporal_smoothness(pose_id_t, pose_id_t1, sigma=None)</code>","text":"<p>Enforce smoothness between successive poses.</p> <p>:param pose_id_t: Node id of the pose at time <code>t</code>. :param pose_id_t1: Node id of the pose at time <code>t+1</code>. :param sigma: Optional standard deviation of the pose difference; a     larger value gives weaker smoothness. If <code>None</code>,     :attr:<code>SceneGraphNoiseConfig.smooth_pose_sigma</code> is used. :return: Integer factor id of the created smoothness constraint.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_temporal_smoothness(\n    self,\n    pose_id_t: int,\n    pose_id_t1: int,\n    sigma: float | None = None,\n) -&gt; int:\n    \"\"\"\n    Enforce smoothness between successive poses.\n\n    :param pose_id_t: Node id of the pose at time ``t``.\n    :param pose_id_t1: Node id of the pose at time ``t+1``.\n    :param sigma: Optional standard deviation of the pose difference; a\n        larger value gives weaker smoothness. If ``None``,\n        :attr:`SceneGraphNoiseConfig.smooth_pose_sigma` is used.\n    :return: Integer factor id of the created smoothness constraint.\n    \"\"\"\n    if sigma is None:\n        sigma = self.noise.smooth_pose_sigma\n    weight = sigma_to_weight(sigma)\n\n    params = {\"weight\": weight}\n    remembered = self._remember_factor(\n        f_type=\"pose_temporal_smoothness\",\n        var_ids=(pose_id_t, pose_id_t1),\n        params=params,\n        relation=\"factor:pose_temporal_smoothness\",\n    )\n    if self._active_template_enabled:\n        self._assign_factor_slot(\"pose_temporal_smoothness\", (pose_id_t, pose_id_t1), params, active=True)\n        return int(remembered)\n\n    fid = self.wm.add_factor(\n        \"pose_temporal_smoothness\",\n        (pose_id_t, pose_id_t1),\n        params,\n    )\n    return int(fid)\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_voxel_cell","title":"<code>add_voxel_cell(xyz)</code>","text":"<p>Add a voxel cell center in world coordinates (R^3).</p> <p>:param xyz: Iterable of length 3 giving the voxel center position. :return: Integer node id of the created voxel variable.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_voxel_cell(self, xyz) -&gt; int:\n    \"\"\"\n    Add a voxel cell center in world coordinates (R^3).\n\n    :param xyz: Iterable of length 3 giving the voxel center position.\n    :return: Integer node id of the created voxel variable.\n    \"\"\"\n    value = jnp.array(xyz, dtype=jnp.float32).reshape(3,)\n    if self._active_template_enabled:\n        nid_int = int(self._assign_var_slot(\"voxel_cell\", value))\n    else:\n        nid_int = int(self.wm.add_variable(\"voxel_cell\", value))\n    self._remember_node(nid_int, \"voxel_cell\", value)\n    return nid_int\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_voxel_point_observation","title":"<code>add_voxel_point_observation(voxel_id, point_world, sigma=None)</code>","text":"<p>Add an observation tying a voxel center to a 3D point in world coordinates.</p> <p>:param voxel_id: Node id of the voxel cell variable. :param point_world: Iterable of length 3 giving a world-frame point     (for example, from fused depth or a point cloud). :param sigma: Optional noise standard deviation. If <code>None</code>,     :attr:<code>SceneGraphNoiseConfig.voxel_point_obs_sigma</code> is used. :return: Integer factor id of the created observation constraint.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_voxel_point_observation(\n    self,\n    voxel_id: int,\n    point_world,\n    sigma: float | None = None,\n) -&gt; int:\n    \"\"\"\n    Add an observation tying a voxel center to a 3D point in world coordinates.\n\n    :param voxel_id: Node id of the voxel cell variable.\n    :param point_world: Iterable of length 3 giving a world-frame point\n        (for example, from fused depth or a point cloud).\n    :param sigma: Optional noise standard deviation. If ``None``,\n        :attr:`SceneGraphNoiseConfig.voxel_point_obs_sigma` is used.\n    :return: Integer factor id of the created observation constraint.\n    \"\"\"\n    point_world = jnp.array(point_world, dtype=jnp.float32).reshape(3,)\n\n    if sigma is None:\n        sigma = self.noise.voxel_point_obs_sigma\n    weight = sigma_to_weight(sigma)\n\n    params = {\n        \"point_world\": point_world,\n        \"weight\": weight,\n    }\n    remembered = self._remember_factor(\n        f_type=\"voxel_point_obs\",\n        var_ids=(voxel_id,),\n        params=params,\n        relation=\"factor:voxel_point_obs\",\n    )\n    if self._active_template_enabled:\n        self._assign_factor_slot(\"voxel_point_obs\", (voxel_id,), params, active=True)\n        return int(remembered)\n\n    fid = self.wm.add_factor(\n        \"voxel_point_obs\",\n        (voxel_id,),\n        params,\n    )\n    return int(fid)\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.add_voxel_smoothness","title":"<code>add_voxel_smoothness(voxel_i_id, voxel_j_id, offset, sigma=None)</code>","text":"<p>Enforce grid-like spacing between two voxel centers.</p> <p>:param voxel_i_id: Node id of the first voxel cell. :param voxel_j_id: Node id of the second voxel cell. :param offset: Iterable of length 3 giving the expected vector from     voxel <code>i</code> to voxel <code>j</code> (for example, <code>[dx, 0, 0]</code>). :param sigma: Optional noise standard deviation. If <code>None</code>,     :attr:<code>SceneGraphNoiseConfig.voxel_smoothness_sigma</code> is used. :return: Integer factor id of the created smoothness constraint.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def add_voxel_smoothness(\n    self,\n    voxel_i_id: int,\n    voxel_j_id: int,\n    offset,\n    sigma: float | None = None,\n) -&gt; int:\n    \"\"\"\n    Enforce grid-like spacing between two voxel centers.\n\n    :param voxel_i_id: Node id of the first voxel cell.\n    :param voxel_j_id: Node id of the second voxel cell.\n    :param offset: Iterable of length 3 giving the expected vector from\n        voxel ``i`` to voxel ``j`` (for example, ``[dx, 0, 0]``).\n    :param sigma: Optional noise standard deviation. If ``None``,\n        :attr:`SceneGraphNoiseConfig.voxel_smoothness_sigma` is used.\n    :return: Integer factor id of the created smoothness constraint.\n    \"\"\"\n    offset = jnp.array(offset, dtype=jnp.float32).reshape(3,)\n\n    if sigma is None:\n        sigma = self.noise.voxel_smoothness_sigma\n    weight = sigma_to_weight(sigma)\n\n    params = {\n        \"offset\": offset,\n        \"weight\": weight,\n    }\n    remembered = self._remember_factor(\n        f_type=\"voxel_smoothness\",\n        var_ids=(voxel_i_id, voxel_j_id),\n        params=params,\n        relation=\"factor:voxel_smoothness\",\n    )\n    if self._active_template_enabled:\n        self._assign_factor_slot(\"voxel_smoothness\", (voxel_i_id, voxel_j_id), params, active=True)\n        return int(remembered)\n\n    fid = self.wm.add_factor(\n        \"voxel_smoothness\",\n        (voxel_i_id, voxel_j_id),\n        params,\n    )\n    return int(fid)\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.attach_object_to_pose","title":"<code>attach_object_to_pose(pose_id, obj_id, offset=(0.0, 0.0, 0.0), sigma=None)</code>","text":"<p>Attach an object to a pose with an optional 3D offset.</p> <p>:param pose_id: Node id of the SE(3) pose variable. :param obj_id: Node id of the 3D object variable. :param offset: Iterable of length 3 giving the offset from the pose     frame to the object in pose coordinates. :param sigma: Optional noise standard deviation. If <code>None</code>, falls     back to :attr:<code>SceneGraphNoiseConfig.object_at_pose_sigma</code>. :return: Integer factor id of the created object-at-pose constraint.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def attach_object_to_pose(\n    self,\n    pose_id: int,\n    obj_id: int,\n    offset=(0.0, 0.0, 0.0),\n    sigma: float | None = None,\n) -&gt; int:\n    \"\"\"\n    Attach an object to a pose with an optional 3D offset.\n\n    :param pose_id: Node id of the SE(3) pose variable.\n    :param obj_id: Node id of the 3D object variable.\n    :param offset: Iterable of length 3 giving the offset from the pose\n        frame to the object in pose coordinates.\n    :param sigma: Optional noise standard deviation. If ``None``, falls\n        back to :attr:`SceneGraphNoiseConfig.object_at_pose_sigma`.\n    :return: Integer factor id of the created object-at-pose constraint.\n    \"\"\"\n    pose_dim = jnp.array(6)\n    obj_dim = jnp.array(3)\n    offset_arr = jnp.array(offset, dtype=jnp.float32).reshape(3,)\n\n    if sigma is None:\n        sigma = self.noise.object_at_pose_sigma\n    weight = sigma_to_weight(sigma)\n\n    params = {\n        \"pose_dim\": pose_dim,\n        \"obj_dim\": obj_dim,\n        \"offset\": offset_arr,\n        \"weight\": weight,\n    }\n    remembered = self._remember_factor(\n        f_type=\"object_at_pose\",\n        var_ids=(pose_id, obj_id),\n        params=params,\n        relation=\"factor:object_at_pose\",\n    )\n    if self._active_template_enabled:\n        self._assign_factor_slot(\"object_at_pose\", (pose_id, obj_id), params, active=True)\n        return int(remembered)\n\n    fid = self.wm.add_factor(\n        \"object_at_pose\",\n        (pose_id, obj_id),\n        params,\n    )\n    return int(fid)\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.attach_pose_to_place_x","title":"<code>attach_pose_to_place_x(pose_id, place_id)</code>","text":"<p>Attach a pose to a 1D place along the x-coordinate.</p> <p>This is a low-level helper that assumes a 6D pose and 1D place.</p> <p>:param pose_id: Node id of the SE(3) pose variable. :param place_id: Node id of the 1D place variable. :return: Integer factor id of the created attachment constraint.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def attach_pose_to_place_x(self, pose_id: int, place_id: int) -&gt; int:\n    \"\"\"\n    Attach a pose to a 1D place along the x-coordinate.\n\n    This is a low-level helper that assumes a 6D pose and 1D place.\n\n    :param pose_id: Node id of the SE(3) pose variable.\n    :param place_id: Node id of the 1D place variable.\n    :return: Integer factor id of the created attachment constraint.\n    \"\"\"\n    pose_dim = jnp.array(6)\n    place_dim = jnp.array(1)\n    pose_coord_index = jnp.array(0)\n\n    sigma = self.noise.pose_place_sigma\n    weight = sigma_to_weight(sigma)\n\n    params = {\n        \"pose_dim\": pose_dim,\n        \"place_dim\": place_dim,\n        \"pose_coord_index\": pose_coord_index,\n        \"weight\": weight,\n    }\n    remembered = self._remember_factor(\n        f_type=\"pose_place_attachment\",\n        var_ids=(pose_id, place_id),\n        params=params,\n        relation=\"pose-place\",\n    )\n    if self._active_template_enabled:\n        self._assign_factor_slot(\"pose_place_attachment\", (pose_id, place_id), params, active=True)\n        return int(remembered)\n\n    fid = self.wm.add_factor(\n        \"pose_place_attachment\",\n        (pose_id, place_id),\n        params,\n    )\n    return int(fid)\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.attach_pose_to_room_x","title":"<code>attach_pose_to_room_x(pose_id, room_id)</code>","text":"<p>Attach a pose to a 1D room along the x-coordinate.</p> <p>This is analogous to :meth:<code>attach_pose_to_place_x</code> but uses a room node instead of a place node.</p> <p>:param pose_id: Node id of the SE(3) pose variable. :param room_id: Node id of the 1D room variable. :return: Integer factor id of the created attachment constraint.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def attach_pose_to_room_x(self, pose_id: int, room_id: int) -&gt; int:\n    \"\"\"\n    Attach a pose to a 1D room along the x-coordinate.\n\n    This is analogous to :meth:`attach_pose_to_place_x` but uses a room\n    node instead of a place node.\n\n    :param pose_id: Node id of the SE(3) pose variable.\n    :param room_id: Node id of the 1D room variable.\n    :return: Integer factor id of the created attachment constraint.\n    \"\"\"\n    pose_dim = jnp.array(6)\n    place_dim = jnp.array(1)\n    pose_coord_index = jnp.array(0)\n\n    sigma = self.noise.pose_place_sigma\n    weight = sigma_to_weight(sigma)\n\n    params = {\n        \"pose_dim\": pose_dim,\n        \"place_dim\": place_dim,\n        \"pose_coord_index\": pose_coord_index,\n        \"weight\": weight,\n    }\n    remembered = self._remember_factor(\n        f_type=\"pose_place_attachment\",\n        var_ids=(pose_id, room_id),\n        params=params,\n        relation=\"pose-place\",\n    )\n    if self._active_template_enabled:\n        self._assign_factor_slot(\"pose_place_attachment\", (pose_id, room_id), params, active=True)\n        return int(remembered)\n\n    fid = self.wm.add_factor(\n        \"pose_place_attachment\",\n        (pose_id, room_id),\n        params,\n    )\n    return int(fid)\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.dump_state","title":"<code>dump_state()</code>","text":"<p>Return a snapshot of all variable values in the world.</p> <p>:return: Dictionary mapping integer node ids to JAX arrays of values.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def dump_state(self) -&gt; Dict[int, jnp.ndarray]:\n    \"\"\"\n    Return a snapshot of all variable values in the world.\n\n    :return: Dictionary mapping integer node ids to JAX arrays of values.\n    \"\"\"\n    return {nid: state.value for nid, state in self._memory.items()}\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.enable_active_template","title":"<code>enable_active_template(template)</code>","text":"<p>Enable fixed-capacity active-template mode.</p> <p>In this mode, SceneGraphWorld retains full persistent memory, but only a bounded active subset is mapped into the WorldModel slots. This enables a single stable JIT compilation and constant-latency solves.</p> <p>:param template: ActiveWindowTemplate instance (from world.model).</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def enable_active_template(self, template) -&gt; None:\n    \"\"\"Enable fixed-capacity active-template mode.\n\n    In this mode, SceneGraphWorld retains full persistent memory, but\n    only a bounded active subset is mapped into the WorldModel slots.\n    This enables a single stable JIT compilation and constant-latency solves.\n\n    :param template: ActiveWindowTemplate instance (from world.model).\n    \"\"\"\n    self.wm.init_active_template(template)\n    self._active_template_enabled = True\n\n    self._slot_capacity = {vs.var_type: int(vs.count) for vs in template.var_slots}\n    self._factor_slot_capacity = {fs.factor_type: int(fs.count) for fs in template.factor_slots}\n\n    # reset assignment state (SceneGraph memory remains intact)\n    self._slot_assign.clear()\n    self._slot_fifo.clear()\n    self._factor_slot_next.clear()\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.get_object3d","title":"<code>get_object3d(obj_id)</code>","text":"<p>Return the current 3D position of an object.</p> <p>:param obj_id: Integer node id of the object variable. :return: JAX array of shape <code>(3,)</code> giving the object position.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def get_object3d(self, obj_id: int) -&gt; jnp.ndarray:\n    \"\"\"\n    Return the current 3D position of an object.\n\n    :param obj_id: Integer node id of the object variable.\n    :return: JAX array of shape ``(3,)`` giving the object position.\n    \"\"\"\n    oid = int(obj_id)\n    if oid not in self._memory:\n        raise KeyError(f\"No object registered in SceneGraph memory for id={oid}\")\n    return self._memory[oid].value\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.get_place","title":"<code>get_place(place_id)</code>","text":"<p>Return the current scalar value of a 1D place.</p> <p>:param place_id: Integer node id of the place variable. :return: Floating-point scalar position.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def get_place(self, place_id: int) -&gt; float:\n    \"\"\"\n    Return the current scalar value of a 1D place.\n\n    :param place_id: Integer node id of the place variable.\n    :return: Floating-point scalar position.\n    \"\"\"\n    pid = int(place_id)\n    if pid not in self._memory:\n        raise KeyError(f\"No place registered in SceneGraph memory for id={pid}\")\n    return float(self._memory[pid].value[0])\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.get_pose","title":"<code>get_pose(pose_id)</code>","text":"<p>Return the current SE(3) pose value.</p> <p>:param pose_id: Integer node id of the pose variable. :return: JAX array of shape <code>(6,)</code> containing the se(3) vector.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def get_pose(self, pose_id: int) -&gt; jnp.ndarray:\n    \"\"\"\n    Return the current SE(3) pose value.\n\n    :param pose_id: Integer node id of the pose variable.\n    :return: JAX array of shape ``(6,)`` containing the se(3) vector.\n    \"\"\"\n    pid = int(pose_id)\n    if pid not in self._memory:\n        raise KeyError(f\"No pose registered in SceneGraph memory for id={pid}\")\n    return self._memory[pid].value\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.optimize","title":"<code>optimize(method='gn', iters=40)</code>","text":"<p>Run nonlinear optimization over the current factor graph. This optimizes the current WorldModel factor graph (which may be bounded active-template or unbounded, depending on configuration).</p> <p>:param method: Optimization method name (currently <code>\"gn\"</code> for     Gauss\u2013Newton). :param iters: Maximum number of iterations to run. :return: <code>None</code>. The internal world model state is updated in-place.</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def optimize(self, method: str = \"gn\", iters: int = 40) -&gt; None:\n    \"\"\"\n    Run nonlinear optimization over the current factor graph.\n    This optimizes the current WorldModel factor graph (which may be bounded active-template or unbounded, depending on configuration).\n\n    :param method: Optimization method name (currently ``\"gn\"`` for\n        Gauss\u2013Newton).\n    :param iters: Maximum number of iterations to run.\n    :return: ``None``. The internal world model state is updated in-place.\n    \"\"\"\n    self.wm.optimize(method=method, iters=iters, damping=1e-3, max_step_norm=0.5)\n\n    for nid, var in self.wm.fg.variables.items():\n        nid_int = int(nid)\n        if nid_int in self._memory:\n            self._memory[nid_int].value = var.value\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.optimize_active_batch","title":"<code>optimize_active_batch(iters=5, damping=0.001)</code>","text":"<p>Optimize only the currently active bounded FG (active-template mode).</p> <p>:param iters: An integer representing the maximum number of iterations for an optimization :param damping: The minimum precision for a solve</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def optimize_active_batch(self, iters: int = 5, damping: float = 1e-3) -&gt; None:\n    \"\"\"Optimize only the currently active bounded FG (active-template mode).\n\n    :param iters: An integer representing the maximum number of iterations for an optimization\n    :param damping: The minimum precision for a solve\n    \"\"\"\n    if not self._active_template_enabled:\n        raise RuntimeError(\n            \"Active-template mode not enabled. Call enable_active_template(...)\"\n        )\n\n    self.wm.optimize(\n        method=\"gn\",\n        iters=int(iters),\n        damping=float(damping),\n        max_step_norm=0.5,\n    )\n\n    # Pull optimized values back into SG memory for active slot variables\n    for nid, var in self.wm.fg.variables.items():\n        nid_int = int(nid)\n        if nid_int in self._memory:\n            self._memory[nid_int].value = var.value\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.optimize_global_offline","title":"<code>optimize_global_offline(iters=40, damping=0.001)</code>","text":"<p>Full batch optimization over the entire persistent SceneGraph memory.</p> <p>:param iters: An integer representing the maximum number of iterations for an optimization :param damping: The minimum precision for a solve</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def optimize_global_offline(self, iters: int = 40, damping: float = 1e-3) -&gt; None:\n    \"\"\"Full batch optimization over the entire persistent SceneGraph memory.\n\n    :param iters: An integer representing the maximum number of iterations for an optimization\n    :param damping: The minimum precision for a solve\n    \"\"\"\n    tmp = WorldModel()\n\n    # Register residuals from this SceneGraphWorld\n    for k, fn in self.wm._residual_registry.items():\n        tmp.register_residual(k, fn)\n\n    # Replay variables and keep remap\n    remap: Dict[int, int] = {}\n    for nid, st in self._memory.items():\n        new_id = int(tmp.add_variable(st.var_type, st.value))\n        remap[int(nid)] = new_id\n\n    # Replay factors (skip semantic-only and inactive)\n    for rec in self._factor_memory.values():\n        if not rec.active:\n            continue\n        if rec.f_type.startswith(\"semantic_\"):\n            continue\n\n        mapped = tuple(remap[v] for v in rec.var_ids if v in remap)\n        if len(mapped) != len(rec.var_ids):\n            continue\n\n        tmp.add_factor(rec.f_type, mapped, dict(rec.params))\n\n    tmp.optimize(method=\"gn\", iters=int(iters), damping=float(damping), max_step_norm=0.5)\n\n    inv = {v: k for k, v in remap.items()}\n    for nid, var in tmp.fg.variables.items():\n        nid_int = int(nid)\n        if nid_int in inv:\n            orig = inv[nid_int]\n            if orig in self._memory:\n                self._memory[orig].value = var.value\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneGraphWorld.visualize_web","title":"<code>visualize_web(host='127.0.0.1', port=8000, open_browser=True)</code>","text":"<p>Launch a local Three.js-based 3D viewer for this SceneGraph.</p> <p>:param host: A string representing the Host IP, is configured for LocalHost by default :param port: An integer representing a target host port to expose the webviewer</p> Source code in <code>dsg-jit/dsg_jit/world/scene_graph.py</code> <pre><code>def visualize_web(\n    self,\n    host: str = \"127.0.0.1\",\n    port: int = 8000,\n    open_browser: bool = True,\n) -&gt; None:\n    \"\"\"Launch a local Three.js-based 3D viewer for this SceneGraph.\n\n    :param host: A string representing the Host IP, is configured for LocalHost by default\n    :param port: An integer representing a target host port to expose the webviewer \"\"\"\n    from dsg_jit.world.web_viewer import run_scenegraph_web_viewer\n\n    run_scenegraph_web_viewer(self, host=host, port=port, open_browser=open_browser)\n</code></pre>"},{"location":"api/world/#world.scene_graph.SceneNodeState","title":"<code>SceneNodeState(node_id, var_type, value)</code>  <code>dataclass</code>","text":"<p>Lightweight cache of a scene-graph node's latest value.</p> <p>This decouples the persistent scene graph from the underlying optimization FactorGraph: even if a variable is marginalized or removed from the FactorGraph (for example, in a sliding-window setup), the SceneGraph can still serve its last optimized value.</p>"},{"location":"api/world/#worldvoxel_grid","title":"<code>world.voxel_grid</code>","text":"<p>Voxel grid utilities for differentiable volumetric scene representations.</p> <p>This module defines helpers for constructing voxel-level variables and their associated factors on top of the DSG-JIT world model.</p>"},{"location":"api/world/#world.voxel_grid--key-responsibilities","title":"Key responsibilities","text":"<ul> <li>Create voxel chains or grids:     \u2022 1D voxel chains (for smooth curves or \u201clines\u201d in space).     \u2022 Higher-dimensional voxel layouts (as needed by experiments).</li> <li> <p>Register and attach voxel-related factors:     \u2022 Smoothness factors between neighboring voxels       (using <code>voxel_smoothness_residual</code>).     \u2022 Point-observation factors tying voxels to measurements in world       coordinates (using <code>voxel_point_observation_residual</code>).     \u2022 Optional voxel priors for regularization or supervision.</p> </li> <li> <p>Provide convenience routines for:     \u2022 Initializing voxel positions (e.g. along an axis).     \u2022 Accessing the optimized voxel centers from the packed state.</p> </li> </ul>"},{"location":"api/world/#world.voxel_grid--role-in-the-dsg-jit-stack","title":"Role in the DSG-JIT stack","text":"<p>Voxel grids are a key piece of the volumetric side of the engine. They allow us to:</p> <pre><code>\u2022 Represent surfaces or occupancy with a differentiable structure.\n\u2022 Run Gauss\u2013Newton over large chains / grids of voxels.\n\u2022 Jointly optimize voxels with SE3 poses and other scene graph nodes\n  (hybrid SE3 + voxel experiments and benchmarks).\n</code></pre>"},{"location":"api/world/#world.voxel_grid--integration-points","title":"Integration points","text":"<ul> <li>Uses <code>world.model.WorldModel</code> to create voxel variables and factors.</li> <li>Relies on residuals defined in <code>slam.measurements</code> for:<ul> <li>smoothness,</li> <li>point observations,</li> <li>and priors.</li> </ul> </li> <li>Works seamlessly with <code>optimization.solvers.gauss_newton_manifold</code>   and related JIT-compiled solvers.</li> </ul>"},{"location":"api/world/#world.voxel_grid--design-goals","title":"Design goals","text":"<ul> <li>Scalable:     Able to create hundreds or thousands of voxel nodes and factors that     still admit fast, JIT-compiled optimization.</li> <li>Composable:     Plays nicely with SE3 poses, places, and other world entities in a     single factor graph.</li> <li>Experiment-oriented:     Keeps the voxel construction boilerplate out of experiment scripts,     making it easier to design new voxel-based learning tasks.</li> </ul>"},{"location":"api/world/#world.voxel_grid.VoxelGridSpec","title":"<code>VoxelGridSpec(origin, dims, resolution)</code>  <code>dataclass</code>","text":"<p>Specification for constructing a regular voxel grid.</p> <p>This lightweight container defines the spatial layout of a voxel grid, including its world-space origin, discrete grid dimensions, and the physical resolution of each voxel cell.</p> <p>:param origin: A 3-element array giving the world-space center of voxel     coordinate (0, 0, 0). This is the reference point from which all voxel     centers are computed. :param dims: A tuple <code>(nx, ny, nz)</code> representing the number of voxels     along the x-, y-, and z-axes respectively. :param resolution: The edge length of each voxel cell in world units.     The spacing between voxel centers is equal to this resolution.</p>"},{"location":"api/world/#world.voxel_grid.build_voxel_grid","title":"<code>build_voxel_grid(sg, spec)</code>","text":"<p>Construct a regular voxel grid inside the SceneGraphWorld.</p> <p>This allocates one <code>voxel_cell</code> variable per grid coordinate <code>(ix, iy, iz)</code> using the voxel resolution and origin defined in <code>spec</code>. Each voxel is positioned at:</p> <pre><code>center = origin + [ix * res, iy * res, iz * res]\n</code></pre> <p>The resulting mapping enables downstream creation of voxel smoothness constraints and scene-graph integration.</p> <p>:param sg: The active <code>SceneGraphWorld</code> instance where voxel nodes will be     created. Must expose <code>add_voxel_cell(center)</code> which returns a node ID. :param spec: Voxel grid specification containing:     - <code>spec.origin</code>: 3D world origin of the grid.     - <code>spec.dims</code>: Tuple <code>(nx, ny, nz)</code> specifying grid dimensions.     - <code>spec.resolution</code>: Edge length of each voxel cell. :return: A dictionary mapping each grid index <code>(ix, iy, iz)</code> to the     corresponding voxel node ID allocated within the scene graph.</p> Source code in <code>dsg-jit/dsg_jit/world/voxel_grid.py</code> <pre><code>def build_voxel_grid(\n    sg: SceneGraphWorld,\n    spec: VoxelGridSpec,\n) -&gt; Dict[GridIndex, int]:\n    \"\"\"\n    Construct a regular voxel grid inside the SceneGraphWorld.\n\n    This allocates one `voxel_cell` variable per grid coordinate `(ix, iy, iz)`\n    using the voxel resolution and origin defined in `spec`. Each voxel is\n    positioned at:\n\n        center = origin + [ix * res, iy * res, iz * res]\n\n    The resulting mapping enables downstream creation of voxel smoothness\n    constraints and scene-graph integration.\n\n    :param sg: The active `SceneGraphWorld` instance where voxel nodes will be\n        created. Must expose `add_voxel_cell(center)` which returns a node ID.\n    :param spec: Voxel grid specification containing:\n        - `spec.origin`: 3D world origin of the grid.\n        - `spec.dims`: Tuple `(nx, ny, nz)` specifying grid dimensions.\n        - `spec.resolution`: Edge length of each voxel cell.\n    :return: A dictionary mapping each grid index `(ix, iy, iz)` to the\n        corresponding voxel node ID allocated within the scene graph.\n    \"\"\"\n    origin = jnp.array(spec.origin, dtype=jnp.float32).reshape(3,)\n    nx, ny, nz = spec.dims\n    res = float(spec.resolution)\n\n    index_to_id: Dict[GridIndex, int] = {}\n\n    for ix in range(nx):\n        for iy in range(ny):\n            for iz in range(nz):\n                offset = jnp.array([ix * res, iy * res, iz * res], dtype=jnp.float32)\n                center = origin + offset\n                nid = sg.add_voxel_cell(center)\n                index_to_id[(ix, iy, iz)] = nid\n\n    return index_to_id\n</code></pre>"},{"location":"api/world/#world.voxel_grid.connect_grid_neighbors_1d_x","title":"<code>connect_grid_neighbors_1d_x(sg, index_to_id, spec, sigma=None)</code>","text":"<p>Connect 3D voxel grid nodes along the +x direction using smoothness factors.</p> <p>This function iterates over all voxel indices <code>(ix, iy, iz)</code> such that <code>ix + 1 &lt; nx</code>, and adds a voxel smoothness constraint between each voxel and its +x neighbor. The enforced residual encourages:</p> <pre><code>voxel(ix+1, iy, iz) - voxel(ix, iy, iz) \u2248 [resolution, 0, 0]\n</code></pre> <p>This is sufficient to enforce a 1D chain structure along the x-axis and is used when constructing structured voxel grids for optimization.</p> <p>:param sg: The active <code>SceneGraphWorld</code> instance to which smoothness     factors will be added. Must expose <code>add_voxel_smoothness(i, j, offset, sigma)</code>. :param index_to_id: Mapping from grid index <code>(ix, iy, iz)</code> to the corresponding     node ID in the scene graph or factor graph. :param spec: Voxel grid specification containing dimensions and voxel resolution.     Expected to provide:         - <code>spec.dims</code>: Tuple <code>(nx, ny, nz)</code> with number of voxels.         - <code>spec.resolution</code>: Voxel edge length in world units. :param sigma: Optional noise standard deviation for the smoothness factor.     If <code>None</code>, the default sigma inside <code>sg.add_voxel_smoothness</code> is used. :return: None. This function mutates the scene graph world in-place by     adding smoothness edges between neighboring x-axis voxels.</p> Source code in <code>dsg-jit/dsg_jit/world/voxel_grid.py</code> <pre><code>def connect_grid_neighbors_1d_x(\n    sg: SceneGraphWorld,\n    index_to_id: Dict[GridIndex, int],\n    spec: VoxelGridSpec,\n    sigma: float | None = None,\n) -&gt; None:\n    \"\"\"\n    Connect 3D voxel grid nodes along the +x direction using smoothness factors.\n\n    This function iterates over all voxel indices `(ix, iy, iz)` such that\n    `ix + 1 &lt; nx`, and adds a voxel smoothness constraint between each voxel\n    and its +x neighbor. The enforced residual encourages:\n\n        voxel(ix+1, iy, iz) - voxel(ix, iy, iz) \u2248 [resolution, 0, 0]\n\n    This is sufficient to enforce a 1D chain structure along the x-axis\n    and is used when constructing structured voxel grids for optimization.\n\n    :param sg: The active `SceneGraphWorld` instance to which smoothness\n        factors will be added. Must expose `add_voxel_smoothness(i, j, offset, sigma)`.\n    :param index_to_id: Mapping from grid index `(ix, iy, iz)` to the corresponding\n        node ID in the scene graph or factor graph.\n    :param spec: Voxel grid specification containing dimensions and voxel resolution.\n        Expected to provide:\n            - `spec.dims`: Tuple `(nx, ny, nz)` with number of voxels.\n            - `spec.resolution`: Voxel edge length in world units.\n    :param sigma: Optional noise standard deviation for the smoothness factor.\n        If `None`, the default sigma inside `sg.add_voxel_smoothness` is used.\n    :return: None. This function mutates the scene graph world in-place by\n        adding smoothness edges between neighboring x-axis voxels.\n    \"\"\"\n    nx, ny, nz = spec.dims\n    res = float(spec.resolution)\n\n    offset = jnp.array([res, 0.0, 0.0], dtype=jnp.float32)\n\n    for ix in range(nx - 1):\n        for iy in range(ny):\n            for iz in range(nz):\n                vid_i = index_to_id[(ix, iy, iz)]\n                vid_j = index_to_id[(ix + 1, iy, iz)]\n                sg.add_voxel_smoothness(vid_i, vid_j, offset, sigma=sigma)\n</code></pre>"},{"location":"api/world/#worldtraining","title":"<code>world.training</code>","text":"<p>High-level training utilities for differentiable scene graph experiments.</p> <p>This module provides a small training harness that sits on top of:</p> <pre><code>\u2022 `world.model.WorldModel` / `world.scene_graph.SceneGraphWorld`\n\u2022 JAX-based optimizers and Gauss\u2013Newton solvers\n\u2022 Residual functions from `slam.measurements`\n</code></pre> <p>Its main role is to support meta-learning and hyperparameter learning over the differentiable DSG-JIT engine. Examples include:</p> <pre><code>\u2022 Learning factor-type weights (e.g. odometry vs. observation).\n\u2022 Learning measurement parameters (odom SE3 chains, voxel obs).\n\u2022 Running outer-loop gradient descent over:\n    - log-scale weights,\n    - observation locations,\n    - or other \u201ctheta\u201d parameters that influence the inner solve.\n</code></pre>"},{"location":"api/world/#world.training--typical-structure","title":"Typical structure","text":"<p>A typical training loop implemented here follows this pattern:</p> <pre><code>1. Build a world / scene graph for a given scenario.\n2. Build a residual function that depends both on:\n       - the state x (poses, voxels, etc.), and\n       - learnable parameters \u03b8 (e.g. measurements, log-scales).\n3. Run an inner optimization (Gauss\u2013Newton or gradient descent)\n   to obtain x*(\u03b8).\n4. Compute a supervised loss L(x*(\u03b8), target).\n5. Differentiate L w.r.t. \u03b8 using JAX (`jax.grad` or `jax.value_and_grad`).\n6. Update \u03b8 with an outer optimizer step.\n</code></pre> <p>The <code>DSGTrainer</code> (or equivalent helper) encapsulates this pattern, exposing <code>step</code> / <code>train_step</code>\u2013style methods that return both the new parameters and useful diagnostics (loss, gradient norms, etc.).</p>"},{"location":"api/world/#world.training--design-goals","title":"Design goals","text":"<ul> <li>Keep experiments small:     Training logic lives here so individual experiments can focus on     constructing the world and defining the supervision signal.</li> <li>JAX-first design:     Training functions are written to be JIT-able and differentiable,     allowing seamless scaling from toy experiments to larger graphs.</li> <li>Research-friendly:     The code is intentionally lightweight and easy to modify for new     research ideas around learnable costs, priors, and structure.</li> </ul>"},{"location":"api/world/#world.training.DSGTrainer","title":"<code>DSGTrainer(wm, factor_type_order, inner_cfg)</code>  <code>dataclass</code>","text":"<p>High-level trainer for differentiable DSG experiments.</p> <p>This class encapsulates a simple bi-level optimization pattern where: an inner loop solves for the scene graph state x, and an outer loop optimizes meta-parameters such as factor-type weights.</p> <p>:param wm: World model containing the factor graph and scene graph. :param factor_type_order: Ordered list of factor type names; each entry corresponds to a log-scale entry in the weight vector. :param inner_cfg: Configuration for the inner gradient\u2013descent solver applied to the state.</p>"},{"location":"api/world/#world.training.DSGTrainer.__post_init__","title":"<code>__post_init__()</code>","text":"<p>Post-initialization hook.</p> <p>This method caches the underlying factor graph from the world model and builds a residual function that accepts per-factor-type log-scales.</p> Source code in <code>dsg-jit/dsg_jit/world/training.py</code> <pre><code>def __post_init__(self):\n    \"\"\"\n    Post-initialization hook.\n\n    This method caches the underlying factor graph from the world model\n    and builds a residual function that accepts per-factor-type log-scales.\n    \"\"\"\n    self.fg: FactorGraph = self.wm.fg\n    self.residual_w = self.fg.build_residual_function_with_type_weights(\n        self.factor_type_order\n    )\n</code></pre>"},{"location":"api/world/#world.training.DSGTrainer.solve_state","title":"<code>solve_state(log_scales)</code>","text":"<p>Run the inner optimization to solve for the state vector.</p> <p>Given a vector of log-scales for factor types, this method performs explicit gradient descent on the objective</p> <pre><code>0.5 * || r(x, log_scales) ||^2,\n</code></pre> <p>where r is the weighted residual function built from the factor graph.</p> <p>:param log_scales: Array of shape <code>(T,)</code> containing per-factor-type log-scale weights. :return: Optimized flat state vector <code>x</code> after the inner GD loop.</p> Source code in <code>dsg-jit/dsg_jit/world/training.py</code> <pre><code>def solve_state(self, log_scales: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"\n    Run the inner optimization to solve for the state vector.\n\n    Given a vector of log-scales for factor types, this method performs\n    explicit gradient descent on the objective\n\n        0.5 * || r(x, log_scales) ||^2,\n\n    where r is the weighted residual function built from the factor graph.\n\n    :param log_scales: Array of shape ``(T,)`` containing per-factor-type log-scale weights.\n    :return: Optimized flat state vector ``x`` after the inner GD loop.\n    \"\"\"\n    x0, _ = self.wm.pack_state()\n\n    def loss_x(x, log_scales):\n        r = self.residual_w(x, log_scales)\n        return 0.5 * jnp.sum(r * r)\n\n    grad_loss_x = jax.grad(loss_x)\n\n    # plain Python loop (no jax.lax.while_loop, easier to debug)\n    x = x0\n    for _ in range(self.inner_cfg.max_iters):\n        g = grad_loss_x(x, log_scales)\n\n        # gradient may be large; clamp the step\n        step = -self.inner_cfg.learning_rate * g\n        step_norm = jnp.linalg.norm(step)\n        max_norm = self.inner_cfg.max_step_norm\n\n        def clamp_step(step, step_norm, max_norm):\n            scale = max_norm / (step_norm + 1e-8)\n            return step * scale\n\n        step = jax.lax.cond(\n            step_norm &gt; max_norm,\n            lambda _: clamp_step(step, step_norm, max_norm),\n            lambda _: step,\n            operand=None,\n        )\n\n        x = x + step\n\n    return x\n</code></pre>"},{"location":"api/world/#world.training.DSGTrainer.unpack_state","title":"<code>unpack_state(x)</code>","text":"<p>Unpack a flat state vector into a NodeId-keyed dictionary.</p> <p>This is a thin wrapper around the factor graph's <code>unpack_state</code> that uses the index structure implied by the current world model.</p> <p>:param x: Flat state vector to be unpacked. :return: Mapping from <code>NodeId</code> to the corresponding slice of <code>x</code> as a JAX array.</p> Source code in <code>dsg-jit/dsg_jit/world/training.py</code> <pre><code>def unpack_state(self, x: jnp.ndarray):\n    \"\"\"\n    Unpack a flat state vector into a NodeId-keyed dictionary.\n\n    This is a thin wrapper around the factor graph's ``unpack_state``\n    that uses the index structure implied by the current world model.\n\n    :param x: Flat state vector to be unpacked.\n    :return: Mapping from ``NodeId`` to the corresponding slice of ``x`` as a JAX array.\n    \"\"\"\n    _, index = self.wm.pack_state()\n    return self.wm.unpack_state(x, index)\n</code></pre>"},{"location":"api/world/#world.training.InnerGDConfig","title":"<code>InnerGDConfig(learning_rate=0.01, max_iters=40, max_step_norm=1.0)</code>  <code>dataclass</code>","text":"<p>Configuration for the inner gradient\u2013descent solver.</p> <p>:param learning_rate: Step size used for each inner GD update on the state. :param max_iters: Maximum number of inner GD iterations. :param max_step_norm: Maximum allowed L2 norm of a single GD step; used to clamp overly large updates for numerical stability.</p>"},{"location":"api/world/#worldvisualization","title":"<code>world.visualization</code>","text":"<p>Visualization utilities for DSG-JIT.</p> <p>This module provides lightweight 2D and 3D rendering tools for visualizing factor graphs, scene graphs, and mixed-level semantic structures. It is designed to support both debugging and demonstration of DSG-JIT\u2019s hierarchical representations, including robot poses, voxel cells, places, rooms, and arbitrary semantic objects.</p> <p>The visualization pipeline follows three main steps:</p> <ol> <li> <p>Exporting graph data <code>export_factor_graph_for_vis()</code> converts an internal <code>FactorGraph</code> into    color-coded <code>VisNode</code> and <code>VisEdge</code> lists. Variable types such as    <code>pose_se3</code>, <code>voxel_cell</code>, <code>place1d</code>, and <code>room1d</code> are mapped to coarse    visualization categories, and heuristic 3D positions are extracted for    rendering.</p> </li> <li> <p>2D top-down rendering <code>plot_factor_graph_2d()</code> produces a Matplotlib top-down view (x\u2013y plane)    with automatically computed bounds, node type coloring, and optional label    rendering. This is especially useful for SE(3) SLAM chains, grid-based    voxel fields, and planar semantic graphs.</p> </li> <li> <p>Full 3D scene graph rendering <code>plot_factor_graph_3d()</code> draws a complete 3D view of poses, voxels, places,    rooms, and objects. Edges between nodes represent geometric or semantic    relationships. Aspect ratios are normalized so spatial structure remains    visually meaningful regardless of scale.</p> </li> </ol> <p>These visualizers are intentionally decoupled from the high-level world model (<code>SceneGraphWorld</code>) so they can be used directly on raw factor graphs produced by optimization procedures or experiment scripts.</p> <p>Example usage is provided in: - <code>experiments/exp17_visual_factor_graph.py</code> (basic 2D + 3D factor graph) - <code>experiments/exp18_scenegraph_3d.py</code> (HYDRA-style multi-level scene graph) - <code>experiments/exp18_scenegraph_demo.py</code> (HYDRA-style 2D + 3D scene graph) - <code>experiments/exp19_dynamic_scene_graph_demo.py</code> (dynamic agent trajectories)</p> Module contents <ul> <li><code>VisNode</code>: Lightweight typed node container for visualization.</li> <li><code>VisEdge</code>: Lightweight edge container (factor connections).</li> <li><code>_infer_node_type()</code>: Maps variable types \u2192 canonical visualization types.</li> <li><code>_extract_position()</code>: Extracts a 3D coordinate from variable states.</li> <li><code>export_factor_graph_for_vis()</code>: Converts a FactorGraph \u2192 vis nodes &amp; edges.</li> <li><code>plot_factor_graph_2d()</code>: Renders a 2D top-down view of the graph.</li> <li><code>plot_factor_graph_3d()</code>: Renders a full 3D scene graph with semantic layers.</li> <li><code>plot_scenegraph_3d()</code>: Renders a scene graph with semantic layers and (optionally) agent trajectories.</li> <li><code>plot_dynamic_trajectories_3d()</code>: Renders 3D agent trajectories with time-encoded color.</li> </ul> <p>This module is designed to be extendable\u2014for example: - Additional node types can be added via <code>_infer_node_type</code>. - SceneGraphWorld can later provide richer semantic annotations. - Future versions may support interactive or WebGL visualizations.</p>"},{"location":"api/world/#world.visualization.VisEdge","title":"<code>VisEdge(var_ids, factor_type)</code>  <code>dataclass</code>","text":"<p>Lightweight edge representation for visualization.</p>"},{"location":"api/world/#world.visualization.VisNode","title":"<code>VisNode(id, type, position, label)</code>  <code>dataclass</code>","text":"<p>Lightweight node representation for visualization.</p>"},{"location":"api/world/#world.visualization.export_factor_graph_for_vis","title":"<code>export_factor_graph_for_vis(fg)</code>","text":"<p>Export a FactorGraph into a visualization-friendly node/edge list.</p> <p>This does not require any SceneGraphWorld; it just uses variables/factors.</p> <p>:param fg: The factor graph to visualize. :return: (nodes, edges) where nodes is a list of VisNode and edges is a list of VisEdge.</p> Source code in <code>dsg-jit/dsg_jit/world/visualization.py</code> <pre><code>def export_factor_graph_for_vis(fg: FactorGraph) -&gt; Tuple[List[VisNode], List[VisEdge]]:\n    \"\"\"\n    Export a FactorGraph into a visualization-friendly node/edge list.\n\n    This does *not* require any SceneGraphWorld; it just uses variables/factors.\n\n    :param fg: The factor graph to visualize.\n    :return: (nodes, edges) where nodes is a list of VisNode and edges is a list of VisEdge.\n    \"\"\"\n    nodes: List[VisNode] = []\n    edges: List[VisEdge] = []\n\n    # Nodes\n    for nid, var in fg.variables.items():\n        ntype = _infer_node_type(var.type)\n        pos = _extract_position(var.type, var.value)\n        nodes.append(\n            VisNode(\n                id=nid,\n                type=ntype,\n                position=pos,\n                label=f\"{ntype}:{int(nid)}\",\n            )\n        )\n\n    # Edges (one edge per factor, between all its variables)\n    for f in fg.factors.values():\n        edges.append(VisEdge(var_ids=tuple(f.var_ids), factor_type=f.type))\n\n    return nodes, edges\n</code></pre>"},{"location":"api/world/#world.visualization.plot_dynamic_trajectories_3d","title":"<code>plot_dynamic_trajectories_3d(dsg, x_opt, index, title='Dynamic 3D Scene Graph', color_by_time=True)</code>","text":"<p>Render 3D agent trajectories with time encoded as color.</p> <p>This helper is intended for <code>DynamicSceneGraph</code>-style structures where agents move through time. It treats time as an implicit fourth dimension and visualizes it via either a color gradient or a solid color per agent.</p> <p>:param dsg: Dynamic scene graph object exposing an iterable     <code>agents</code> attribute and a     <code>get_agent_trajectory(agent, x_opt, index)</code> method that returns     an array of shape <code>(T, 6)</code> or <code>(T, 3)</code>. Only the translational     components <code>(x, y, z)</code> are visualized. :param x_opt: Optimized flat state vector used to decode agent poses. :param index: Mapping from node identifier to slice or <code>(start, dim)</code>     describing how to extract each node\u2019s state from <code>x_opt</code>. This is     passed through to <code>dsg.get_agent_trajectory</code>. :param title: Optional figure title for the 3D plot. :param color_by_time: If <code>True</code>, encode time as a colormap gradient     along each trajectory; if <code>False</code>, use a single solid color per     agent. :return: None. The function creates and displays a Matplotlib 3D figure.</p> Source code in <code>dsg-jit/dsg_jit/world/visualization.py</code> <pre><code>def plot_dynamic_trajectories_3d(\n    dsg: Any,\n    x_opt: Any,\n    index: Dict[Any, Union[slice, tuple]],\n    title: str = \"Dynamic 3D Scene Graph\",\n    color_by_time: bool = True,\n) -&gt; None:\n    \"\"\"\n    Render 3D agent trajectories with time encoded as color.\n\n    This helper is intended for ``DynamicSceneGraph``-style structures where\n    agents move through time. It treats time as an implicit fourth\n    dimension and visualizes it via either a color gradient or a solid\n    color per agent.\n\n    :param dsg: Dynamic scene graph object exposing an iterable\n        ``agents`` attribute and a\n        ``get_agent_trajectory(agent, x_opt, index)`` method that returns\n        an array of shape ``(T, 6)`` or ``(T, 3)``. Only the translational\n        components ``(x, y, z)`` are visualized.\n    :param x_opt: Optimized flat state vector used to decode agent poses.\n    :param index: Mapping from node identifier to slice or ``(start, dim)``\n        describing how to extract each node\u2019s state from ``x_opt``. This is\n        passed through to ``dsg.get_agent_trajectory``.\n    :param title: Optional figure title for the 3D plot.\n    :param color_by_time: If ``True``, encode time as a colormap gradient\n        along each trajectory; if ``False``, use a single solid color per\n        agent.\n    :return: None. The function creates and displays a Matplotlib 3D figure.\n    \"\"\"\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection=\"3d\")\n    ax.set_title(title)\n\n    all_pts: List[np.ndarray] = []\n\n    if not hasattr(dsg, \"agents\"):\n        raise ValueError(\"Dynamic scene graph object must expose an 'agents' attribute\")\n\n    # Use a base list of colors when not color-coding by time.\n    base_colors = plt.rcParams[\"axes.prop_cycle\"].by_key().get(\"color\", [\"C0\", \"C1\", \"C2\", \"C3\"])  # type: ignore[index]\n\n    for i, agent in enumerate(dsg.agents):\n        traj = dsg.get_agent_trajectory(agent, x_opt, index)\n        traj = np.asarray(traj)\n        if traj.ndim != 2 or traj.shape[1] &lt; 3:\n            continue\n\n        xyz = traj[:, :3]\n        all_pts.append(xyz)\n\n        if color_by_time and xyz.shape[0] &gt; 1:\n            # Encode time as a gradient along the trajectory\n            t = np.linspace(0.0, 1.0, xyz.shape[0])\n            cmap = plt.get_cmap(\"viridis\")\n            for j in range(xyz.shape[0] - 1):\n                c = cmap(t[j])\n                ax.plot(\n                    xyz[j : j + 2, 0],\n                    xyz[j : j + 2, 1],\n                    xyz[j : j + 2, 2],\n                    color=c,\n                    linewidth=2.0,\n                )\n        else:\n            color = base_colors[i % len(base_colors)]\n            ax.plot(\n                xyz[:, 0],\n                xyz[:, 1],\n                xyz[:, 2],\n                linewidth=2.0,\n                label=f\"{agent}_traj\",\n                color=color,\n            )\n\n    # Autoscale axes to include all trajectories\n    if all_pts:\n        stacked = np.vstack(all_pts)\n        mins = stacked.min(axis=0)\n        maxs = stacked.max(axis=0)\n        center = 0.5 * (mins + maxs)\n        extent = float((maxs - mins).max())\n        if extent &lt;= 0.0:\n            extent = 1.0\n        scale = 0.6 * extent\n        ax.set_xlim(center[0] - scale, center[0] + scale)\n        ax.set_ylim(center[1] - scale, center[1] + scale)\n        ax.set_zlim(center[2] - scale, center[2] + scale)\n\n    ax.set_xlabel(\"x\")\n    ax.set_ylabel(\"y\")\n    ax.set_zlabel(\"z\")\n\n    # Only show legend entries when not using per-segment colors.\n    if not color_by_time:\n        handles, labels = ax.get_legend_handles_labels()\n        if labels:\n            uniq = {}\n            for h, l in zip(handles, labels):\n                if l and l not in uniq:\n                    uniq[l] = h\n            ax.legend(uniq.values(), uniq.keys(), loc=\"best\")\n\n    plt.tight_layout()\n    plt.show()\n</code></pre>"},{"location":"api/world/#world.visualization.plot_factor_graph_2d","title":"<code>plot_factor_graph_2d(fg, show_labels=True)</code>","text":"<p>Simple top-down 2D visualization of the factor graph.</p> <ul> <li>nodes colored by type</li> <li>edges drawn between connected variable nodes (projected to x\u2013y)</li> <li>dynamic aspect ratio and bounds based on node extents</li> </ul> <p>:param fg: The factor graph to visualize. :param show_labels: Whether to draw node labels.</p> Source code in <code>dsg-jit/dsg_jit/world/visualization.py</code> <pre><code>def plot_factor_graph_2d(fg: FactorGraph, show_labels: bool = True) -&gt; None:\n    \"\"\"\n    Simple top-down 2D visualization of the factor graph.\n\n    - nodes colored by type\n    - edges drawn between connected variable nodes (projected to x\u2013y)\n    - dynamic aspect ratio and bounds based on node extents\n\n    :param fg: The factor graph to visualize.\n    :param show_labels: Whether to draw node labels.\n    \"\"\"\n    nodes, edges = export_factor_graph_for_vis(fg)\n\n    # color palette per node type\n    type_to_color: Dict[NodeType, str] = {\n        \"pose\": \"C0\",\n        \"voxel\": \"C1\",\n        \"place\": \"C2\",\n        \"room\": \"C3\",\n        \"other\": \"C4\",\n    }\n\n    # Build quick lookup for positions and types\n    node_pos: Dict[NodeId, jnp.ndarray] = {n.id: n.position for n in nodes}\n    node_type: Dict[NodeId, NodeType] = {n.id: n.type for n in nodes}\n\n    fig, ax = plt.subplots()\n    ax.set_aspect(\"equal\")\n\n    # Draw edges (as lines between all pairs in each factor)\n    for e in edges:\n        var_ids = list(e.var_ids)\n        if len(var_ids) &lt; 2:\n            continue\n        for i in range(len(var_ids) - 1):\n            ida = var_ids[i]\n            idb = var_ids[i + 1]\n            a = node_pos.get(ida)\n            b = node_pos.get(idb)\n            if a is None or b is None:\n                continue\n\n            kind = _classify_edge_kind(node_type.get(ida, \"other\"),\n                                       node_type.get(idb, \"other\"))\n\n            if kind == \"room-place\":\n                color, ls, lw, alpha = \"magenta\", \"-\", 1.5, 0.6\n            elif kind == \"place-object\":\n                color, ls, lw, alpha = \"magenta\", \":\", 1.2, 0.6\n            elif kind == \"pose-edge\":\n                color, ls, lw, alpha = \"gray\", \"--\", 0.8, 0.4\n            else:\n                color, ls, lw, alpha = \"k\", \":\", 0.5, 0.2\n\n            ax.plot(\n                [float(a[0]), float(b[0])],\n                [float(a[1]), float(b[1])],\n                linewidth=lw,\n                alpha=alpha,\n                linestyle=ls,\n                color=color,\n            )\n\n    # Draw nodes\n    xs, ys = [], []\n    for n in nodes:\n        c = type_to_color.get(n.type, \"k\")\n        x, y = float(n.position[0]), float(n.position[1])\n        xs.append(x)\n        ys.append(y)\n        ax.scatter(x, y, s=25, c=c)\n        if show_labels:\n            ax.text(x + 0.05, y + 0.05, n.label, fontsize=6)\n\n    ax.set_xlabel(\"x [m]\")\n    ax.set_ylabel(\"y [m]\")\n    ax.set_title(\"DSG-JIT Factor Graph (2D / top-down)\")\n\n    # Dynamic bounds with equal aspect\n    if xs and ys:\n        min_x, max_x = min(xs), max(xs)\n        min_y, max_y = min(ys), max(ys)\n        max_range = max(max_x - min_x, max_y - min_y) / 2.0\n        if max_range &lt; 1e-3:\n            max_range = 1.0\n        mid_x = 0.5 * (max_x + min_x)\n        mid_y = 0.5 * (max_y + min_y)\n        ax.set_xlim(mid_x - max_range * 1.1, mid_x + max_range * 1.1)\n        ax.set_ylim(mid_y - max_range * 1.1, mid_y + max_range * 1.1)\n\n    fig.tight_layout()\n    plt.show()\n</code></pre>"},{"location":"api/world/#world.visualization.plot_factor_graph_3d","title":"<code>plot_factor_graph_3d(fg, show_labels=True)</code>","text":"<p>3D visualization of the factor graph.</p> <ul> <li>Nodes plotted as (x, y, z)</li> <li>Edges drawn as 3D line segments</li> <li>Colors by node type</li> </ul> <p>:param fg: The factor graph to visualize. :param show_labels: Whether to draw node labels in 3D.</p> Source code in <code>dsg-jit/dsg_jit/world/visualization.py</code> <pre><code>def plot_factor_graph_3d(fg: FactorGraph, show_labels: bool = True) -&gt; None:\n    \"\"\"\n    3D visualization of the factor graph.\n\n    - Nodes plotted as (x, y, z)\n    - Edges drawn as 3D line segments\n    - Colors by node type\n\n    :param fg: The factor graph to visualize.\n    :param show_labels: Whether to draw node labels in 3D.\n    \"\"\"\n    nodes, edges = export_factor_graph_for_vis(fg)\n\n    type_to_color: Dict[NodeType, str] = {\n        \"pose\": \"C0\",\n        \"voxel\": \"C1\",\n        \"place\": \"C2\",\n        \"room\": \"C3\",\n        \"other\": \"C4\",\n    }\n\n    node_pos: Dict[NodeId, jnp.ndarray] = {n.id: n.position for n in nodes}\n    node_type: Dict[NodeId, NodeType] = {n.id: n.type for n in nodes}\n\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection=\"3d\")\n\n    # Draw edges\n    for e in edges:\n        var_ids = list(e.var_ids)\n        if len(var_ids) &lt; 2:\n            continue\n        for i in range(len(var_ids) - 1):\n            ida = var_ids[i]\n            idb = var_ids[i + 1]\n            a = node_pos.get(ida)\n            b = node_pos.get(idb)\n            if a is None or b is None:\n                continue\n\n            kind = _classify_edge_kind(node_type.get(ida, \"other\"),\n                                       node_type.get(idb, \"other\"))\n\n            if kind == \"room-place\":\n                color, ls, lw, alpha = \"magenta\", \"-\", 1.5, 0.6\n            elif kind == \"place-object\":\n                color, ls, lw, alpha = \"magenta\", \":\", 1.2, 0.6\n            elif kind == \"pose-edge\":\n                color, ls, lw, alpha = \"gray\", \"--\", 0.8, 0.4\n            else:\n                color, ls, lw, alpha = \"k\", \":\", 0.5, 0.2\n\n            ax.plot(\n                [float(a[0]), float(b[0])],\n                [float(a[1]), float(b[1])],\n                [float(a[2]), float(b[2])],\n                linewidth=lw,\n                alpha=alpha,\n                linestyle=ls,\n                color=color,\n            )\n\n    # Draw nodes\n    xs, ys, zs = [], [], []\n    for n in nodes:\n        c = type_to_color.get(n.type, \"k\")\n        x, y, z = map(float, n.position[:3])\n        xs.append(x)\n        ys.append(y)\n        zs.append(z)\n        ax.scatter(x, y, z, s=30, c=c)\n        if show_labels:\n            ax.text(x, y, z, n.label, fontsize=6)\n\n    ax.set_xlabel(\"x [m]\")\n    ax.set_ylabel(\"y [m]\")\n    ax.set_zlabel(\"z [m]\")\n    ax.set_title(\"DSG-JIT Factor Graph (3D)\")\n\n    # Make aspect ratio equal in 3D\n    if xs and ys and zs:\n        min_x, max_x = min(xs), max(xs)\n        min_y, max_y = min(ys), max(ys)\n        min_z, max_z = min(zs), max(zs)\n        max_range = max(max_x - min_x, max_y - min_y, max_z - min_z) / 2.0\n        if max_range &lt; 1e-3:\n            max_range = 1.0\n        mid_x = 0.5 * (max_x + min_x)\n        mid_y = 0.5 * (max_y + min_y)\n        mid_z = 0.5 * (max_z + min_z)\n        ax.set_xlim(mid_x - max_range * 1.1, mid_x + max_range * 1.1)\n        ax.set_ylim(mid_y - max_range * 1.1, mid_y + max_range * 1.1)\n        ax.set_zlim(mid_z - max_range * 1.1, mid_z + max_range * 1.1)\n\n    plt.show()\n</code></pre>"},{"location":"api/world/#world.visualization.plot_scenegraph_3d","title":"<code>plot_scenegraph_3d(sg, x_opt=None, index=None, title='Scene Graph 3D', dsg=None)</code>","text":"<p>Render a 3D scene graph with rooms, places, objects, place attachments, and optional agent trajectories.</p> <p>This function supports two modes: - If <code>sg</code> exposes a <code>_memory</code> attribute (the SceneGraph memory layer introduced in <code>SceneGraphWorld</code>),   node positions are read from this memory and <code>x_opt</code> and <code>index</code> are ignored. - If no memory is present, the function falls back to the previous behavior using <code>x_opt</code> and <code>index</code>   to decode node states.</p> <p>:param sg: Scene-graph world instance. It is expected to expose     attributes such as <code>rooms</code>, <code>places</code>, <code>objects</code>,     <code>place_parents</code>, <code>object_parents</code>, and <code>place_attachments</code>,     following the conventions used by :class:<code>SceneGraphWorld</code>. :param x_opt: (Optional) Optimized flat state vector (e.g. from     :meth:<code>WorldModel.pack_state</code>), containing the current estimates     of all node states. Not required if <code>sg</code> exposes a <code>_memory</code> layer. :param index: (Optional) Mapping from node identifier to either a slice or     <code>(start, dim)</code> tuple describing where that node\u2019s state lives     inside <code>x_opt</code>. Not required if <code>sg</code> exposes a <code>_memory</code> layer. :param title: Optional figure title for the Matplotlib 3D axes. :param dsg: Optional dynamic scene graph used to overlay agent     trajectories. It should expose an iterable <code>agents</code> attribute     and a <code>get_agent_trajectory(agent, x_opt, index)</code> method that     returns an array of shape <code>(T, 6)</code> or <code>(T, 3)</code>. :return: None. The function creates and displays a Matplotlib 3D figure.</p> Source code in <code>dsg-jit/dsg_jit/world/visualization.py</code> <pre><code>def plot_scenegraph_3d(\n    sg: Any,\n    x_opt: Any = None,\n    index: Optional[Dict[Any, Union[slice, tuple]]] = None,\n    title: str = \"Scene Graph 3D\",\n    dsg: Optional[Any] = None,\n) -&gt; None:\n    \"\"\"\n    Render a 3D scene graph with rooms, places, objects, place attachments,\n    and optional agent trajectories.\n\n    This function supports two modes:\n    - If ``sg`` exposes a ``_memory`` attribute (the SceneGraph memory layer introduced in ``SceneGraphWorld``),\n      node positions are read from this memory and ``x_opt`` and ``index`` are ignored.\n    - If no memory is present, the function falls back to the previous behavior using ``x_opt`` and ``index``\n      to decode node states.\n\n    :param sg: Scene-graph world instance. It is expected to expose\n        attributes such as ``rooms``, ``places``, ``objects``,\n        ``place_parents``, ``object_parents``, and ``place_attachments``,\n        following the conventions used by :class:`SceneGraphWorld`.\n    :param x_opt: (Optional) Optimized flat state vector (e.g. from\n        :meth:`WorldModel.pack_state`), containing the current estimates\n        of all node states. Not required if ``sg`` exposes a ``_memory`` layer.\n    :param index: (Optional) Mapping from node identifier to either a slice or\n        ``(start, dim)`` tuple describing where that node\u2019s state lives\n        inside ``x_opt``. Not required if ``sg`` exposes a ``_memory`` layer.\n    :param title: Optional figure title for the Matplotlib 3D axes.\n    :param dsg: Optional dynamic scene graph used to overlay agent\n        trajectories. It should expose an iterable ``agents`` attribute\n        and a ``get_agent_trajectory(agent, x_opt, index)`` method that\n        returns an array of shape ``(T, 6)`` or ``(T, 3)``.\n    :return: None. The function creates and displays a Matplotlib 3D figure.\n    \"\"\"\n    has_memory = hasattr(sg, \"_memory\")\n    mem = getattr(sg, \"_memory\", None)\n\n    def _partition_memory_by_type() -&gt; Tuple[Dict[str, Any], Dict[str, Any], Dict[str, Any]]:\n        \"\"\"\n        Derive rooms / places / objects mappings from the SceneGraphWorld\n        memory layer when explicit dictionaries (sg.rooms, sg.places,\n        sg.objects) are not available or are empty.\n\n        This assumes each memory entry is a small dataclass-like object\n        exposing ``node_id`` and ``var_type`` attributes, where\n        ``var_type`` starts with e.g. ``\"room\"``, ``\"place\"``, or\n        ``\"object\"`` / ``\"voxel\"``.\n        \"\"\"\n        rooms_m: Dict[str, Any] = {}\n        places_m: Dict[str, Any] = {}\n        objects_m: Dict[str, Any] = {}\n        if not has_memory or mem is None:\n            return rooms_m, places_m, objects_m\n\n        # Iterate over stored node states and group by var_type prefix.\n        for state in getattr(mem, \"values\", lambda: [])():\n            vt = getattr(state, \"var_type\", \"\")\n            nid = getattr(state, \"node_id\", None)\n            if nid is None:\n                continue\n            # Construct simple human-readable names when no explicit names exist.\n            if vt.startswith(\"room\"):\n                key = f\"room_{nid}\"\n                rooms_m[key] = nid\n            elif vt.startswith(\"place\"):\n                key = f\"place_{nid}\"\n                places_m[key] = nid\n            elif vt.startswith(\"object\") or vt.startswith(\"voxel\"):\n                key = f\"obj_{nid}\"\n                objects_m[key] = nid\n        return rooms_m, places_m, objects_m\n\n    def _has_state(nid: Any) -&gt; bool:\n        \"\"\"\n        Check whether we have a stored state for the given node id.\n\n        When using SceneGraphWorld memory, we support both integer keys\n        and arbitrary NodeId-like keys by trying ``nid`` directly first\n        and then falling back to ``int(nid)`` if conversion is possible.\n        \"\"\"\n        if has_memory:\n            # Try raw key as-is\n            try:\n                if nid in mem:\n                    return True\n            except TypeError:\n                # Some key types may not support `in` with this nid\n                pass\n            # Fallback: try integer-cast key\n            try:\n                nid_int = int(nid)\n            except (TypeError, ValueError):\n                return False\n            return nid_int in mem\n        if index is None:\n            return False\n        return nid in index\n\n    def _vec(nid: Any) -&gt; np.ndarray:\n        if has_memory:\n            # Support both direct nid keys and integer-cast keys.\n            state = None\n            # Try raw nid first\n            try:\n                state = mem.get(nid)  # type: ignore[call-arg]\n            except AttributeError:\n                # If _memory is not a Mapping, fall back to direct indexing\n                try:\n                    state = mem[nid]  # type: ignore[index]\n                except Exception:\n                    state = None\n            if state is None:\n                # Fallback: try integer-cast key\n                try:\n                    nid_int = int(nid)\n                except (TypeError, ValueError):\n                    raise KeyError(f\"No state in SceneGraph memory for node id={nid!r}\")\n                try:\n                    state = mem.get(nid_int)  # type: ignore[call-arg]\n                except AttributeError:\n                    state = mem[nid_int]  # type: ignore[index]\n            if state is None:\n                raise KeyError(f\"No state in SceneGraph memory for node id={nid!r}\")\n            v = np.asarray(state.value).reshape(-1)\n            return v\n        if index is None or x_opt is None:\n            raise ValueError(\"x_opt and index must be provided when SceneGraph memory is not available\")\n        idx = index[nid]\n        if isinstance(idx, slice):\n            sl = idx\n        else:\n            start, length = idx\n            sl = slice(start, start + length)\n        v = np.asarray(x_opt[sl]).reshape(-1)\n        return v\n\n    # Safely grab scene-graph structures (with defaults if missing).\n    rooms = getattr(sg, \"rooms\", {}) or {}\n    places = getattr(sg, \"places\", {}) or {}\n    objects = getattr(sg, \"objects\", {}) or {}\n\n    # If we have a memory layer but no explicit named dicts, derive them from memory.\n    if has_memory and mem is not None:\n        if not rooms or not isinstance(rooms, dict):\n            mem_rooms, mem_places, mem_objects = _partition_memory_by_type()\n            # Only fill in from memory when each layer is empty; this way,\n            # user-provided names (if any) take precedence.\n            if not rooms:\n                rooms = mem_rooms\n            if not places:\n                places = mem_places\n            if not objects:\n                objects = mem_objects\n\n    place_parents = getattr(sg, \"place_parents\", {}) or {}\n    object_parents = getattr(sg, \"object_parents\", {}) or {}\n    attachments = getattr(sg, \"place_attachments\", []) or []\n\n    # -------------------------------------------------\n    # Collect pose node ids (for rendering trajectories / agent poses).\n    # We look in both the memory layer and the place-attachment edges.\n    pose_ids: set[Any] = set()\n\n    # From attachments: first element of each tuple is assumed to be a pose node id.\n    for pose_nid, _ in attachments:\n        pose_ids.add(pose_nid)\n\n    # From memory: any node whose var_type starts with \"pose\" is treated as a pose.\n    if has_memory and mem is not None:\n        for state in getattr(mem, \"values\", lambda: [])():\n            vt = getattr(state, \"var_type\", \"\")\n            if vt.startswith(\"pose\"):\n                nid = getattr(state, \"node_id\", None)\n                if nid is not None:\n                    pose_ids.add(nid)\n\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection=\"3d\")\n    ax.set_title(title)\n\n    all_pts = []\n\n    # ------------------------------\n    # Rooms: large semi-transparent markers\n    # ------------------------------\n    first_room = next(iter(rooms), None)\n    for name, nid in rooms.items():\n        if not _has_state(nid):\n            continue\n        p = _vec(nid)\n        if p.shape[0] &lt; 3:\n            # If we only have 1D, pad to 3D for visualization\n            p = np.pad(p, (0, 3 - p.shape[0]), mode=\"constant\")\n        all_pts.append(p[:3])\n        label = \"room\" if name == first_room else \"\"\n        ax.scatter(\n            p[0],\n            p[1],\n            p[2],\n            s=200,\n            marker=\"s\",\n            alpha=0.3,\n            edgecolor=\"k\",\n            label=label,\n        )\n\n    # ------------------------------\n    # Places: medium spheres\n    # ------------------------------\n    first_place = next(iter(places), None)\n    for name, nid in places.items():\n        if not _has_state(nid):\n            continue\n        p = _vec(nid)\n        if p.shape[0] &lt; 3:\n            p = np.pad(p, (0, 3 - p.shape[0]), mode=\"constant\")\n        all_pts.append(p[:3])\n        label = \"place\" if name == first_place else \"\"\n        ax.scatter(\n            p[0],\n            p[1],\n            p[2],\n            s=60,\n            marker=\"o\",\n            alpha=0.8,\n            label=label,\n        )\n\n    # ------------------------------\n    # Objects: small pyramids/triangles\n    # ------------------------------\n    first_obj = next(iter(objects), None)\n    for name, nid in objects.items():\n        if not _has_state(nid):\n            continue\n        p = _vec(nid)\n        if p.shape[0] &lt; 3:\n            p = np.pad(p, (0, 3 - p.shape[0]), mode=\"constant\")\n        all_pts.append(p[:3])\n        label = \"object\" if name == first_obj else \"\"\n        ax.scatter(\n            p[0],\n            p[1],\n            p[2],\n            s=40,\n            marker=\"^\",\n            alpha=0.9,\n            label=label,\n        )\n\n    # ------------------------------\n    # Poses: agent pose nodes (small spheres)\n    # ------------------------------\n    first_pose = next(iter(pose_ids), None)\n    for nid in pose_ids:\n        if not _has_state(nid):\n            continue\n        p = _vec(nid)\n        if p.shape[0] &lt; 3:\n            p = np.pad(p, (0, 3 - p.shape[0]), mode=\"constant\")\n        all_pts.append(p[:3])\n        label = \"pose\" if nid == first_pose else \"\"\n        ax.scatter(\n            p[0],\n            p[1],\n            p[2],\n            s=30,\n            marker=\"o\",\n            alpha=1.0,\n            label=label,\n        )\n\n    # ------------------------------\n    # Hierarchical edges: room -&gt; place, place -&gt; object\n    # ------------------------------\n    for place_nid, room_nid in place_parents.items():\n        if not (_has_state(place_nid) and _has_state(room_nid)):\n            continue\n        p = _vec(place_nid)\n        r = _vec(room_nid)\n        if p.shape[0] &lt; 3:\n            p = np.pad(p, (0, 3 - p.shape[0]), mode=\"constant\")\n        if r.shape[0] &lt; 3:\n            r = np.pad(r, (0, 3 - r.shape[0]), mode=\"constant\")\n        ax.plot(\n            [p[0], r[0]],\n            [p[1], r[1]],\n            [p[2], r[2]],\n            linestyle=\"-\",\n            linewidth=1.0,\n            alpha=0.5,\n        )\n\n    for obj_nid, place_nid in object_parents.items():\n        if not (_has_state(obj_nid) and _has_state(place_nid)):\n            continue\n        o = _vec(obj_nid)\n        p = _vec(place_nid)\n        if o.shape[0] &lt; 3:\n            o = np.pad(o, (0, 3 - o.shape[0]), mode=\"constant\")\n        if p.shape[0] &lt; 3:\n            p = np.pad(p, (0, 3 - p.shape[0]), mode=\"constant\")\n        ax.plot(\n            [o[0], p[0]],\n            [o[1], p[1]],\n            [o[2], p[2]],\n            linestyle=\"-\",\n            linewidth=1.0,\n            alpha=0.5,\n        )\n\n    # ------------------------------\n    # Place attachments: pose -&gt; place (dashed)\n    # ------------------------------\n    for pose_nid, place_nid in attachments:\n        if not (_has_state(pose_nid) and _has_state(place_nid)):\n            continue\n        pose = _vec(pose_nid)\n        plc = _vec(place_nid)\n        if pose.shape[0] &lt; 3:\n            pose = np.pad(pose, (0, 3 - pose.shape[0]), mode=\"constant\")\n        if plc.shape[0] &lt; 3:\n            plc = np.pad(plc, (0, 3 - plc.shape[0]), mode=\"constant\")\n        ax.plot(\n            [pose[0], plc[0]],\n            [pose[1], plc[1]],\n            [pose[2], plc[2]],\n            linestyle=\"--\",\n            linewidth=1.0,\n            alpha=0.7,\n        )\n\n    # ------------------------------\n    # Optional: agent trajectories from DynamicSceneGraph\n    # ------------------------------\n    if dsg is not None and hasattr(dsg, \"agents\"):\n        for agent in dsg.agents:\n            traj = dsg.get_agent_trajectory(agent, x_opt, index)\n            traj = np.asarray(traj)\n            if traj.ndim != 2 or traj.shape[1] &lt; 3:\n                continue\n            xs, ys, zs = traj[:, 0], traj[:, 1], traj[:, 2]\n            all_pts.extend(traj[:, :3])\n            ax.plot(xs, ys, zs, linewidth=2.0, alpha=0.9, label=f\"{agent}_traj\")\n\n    # ------------------------------\n    # Autoscale axes to fit everything\n    # ------------------------------\n    if all_pts:\n        all_pts_arr = np.vstack(all_pts)\n        mins = all_pts_arr.min(axis=0)\n        maxs = all_pts_arr.max(axis=0)\n        center = 0.5 * (mins + maxs)\n        extent = float((maxs - mins).max())\n        if extent &lt;= 0.0:\n            extent = 1.0\n        scale = 0.6 * extent\n        ax.set_xlim(center[0] - scale, center[0] + scale)\n        ax.set_ylim(center[1] - scale, center[1] + scale)\n        ax.set_zlim(center[2] - scale, center[2] + scale)\n\n    ax.set_xlabel(\"x\")\n    ax.set_ylabel(\"y\")\n    ax.set_zlabel(\"z\")\n\n    # Deduplicate legend entries\n    handles, labels = ax.get_legend_handles_labels()\n    if labels:\n        uniq = {}\n        for h, l in zip(handles, labels):\n            if l and l not in uniq:\n                uniq[l] = h\n        ax.legend(uniq.values(), uniq.keys(), loc=\"best\")\n\n    plt.tight_layout()\n    plt.show()\n</code></pre>"},{"location":"api/world/#worlddynamic_scene_graph","title":"<code>world.dynamic_scene_graph</code>","text":"<p>Dynamic scene-graph utilities built on top of :mod:<code>world.scene_graph</code>.</p> <p>This module provides a lightweight wrapper around :class:<code>world.scene_graph.SceneGraphWorld</code> that makes dynamic (time-indexed) scene graphs easier to build and reason about.</p> <p>The goal is to keep all of the optimization and factor-graph logic in the existing engine, while giving users a small, ergonomic API for working with trajectories and other time-varying entities.</p>"},{"location":"api/world/#world.dynamic_scene_graph--design-goals","title":"Design goals","text":"<ul> <li>Don't duplicate state: the underlying :class:<code>SceneGraphWorld</code> and   :class:<code>WorldModel</code> remain the single source of truth.</li> <li>Time-aware helpers: convenience functions for adding agent trajectories,   querying poses across time, and wiring odometry factors between consecutive   poses.</li> <li>Engine-friendly: everything ultimately calls into existing   <code>SceneGraphWorld</code> methods, so this module is safe to ignore if you want to   use the lower-level API directly.</li> </ul>"},{"location":"api/world/#world.dynamic_scene_graph--typical-usage","title":"Typical usage","text":"<p>.. code-block:: python</p> <pre><code>from world.scene_graph import SceneGraphWorld\nfrom world.dynamic_scene_graph import DynamicSceneGraph\nimport jax.numpy as jnp\n\nsg = SceneGraphWorld()\ndsg = DynamicSceneGraph(sg)\n\nagent = \"robot0\"\n\n# Add a short trajectory\ndsg.add_agent_pose(agent, t=0, pose_se3=jnp.zeros(6))\ndsg.add_agent_pose(agent, t=1, pose_se3=jnp.array([1.0, 0, 0, 0, 0, 0]))\n\n# Connect poses with odometry in the x-direction\ndsg.add_odom_tx(agent, t0=0, t1=1, dx=1.0, weight=10.0)\n\n# Later, after optimization, you can recover the optimized trajectory with\n# dsg.get_agent_trajectory(...).\n</code></pre>"},{"location":"api/world/#world.dynamic_scene_graph.DynamicSceneGraph","title":"<code>DynamicSceneGraph(world, agents=set())</code>  <code>dataclass</code>","text":"<p>Helper for building dynamic (time-indexed) scene graphs.</p> <p>This class is a thin fa\u00e7ade over :class:<code>world.scene_graph.SceneGraphWorld</code>. It does not introduce new optimization logic or state; instead it organizes common patterns for working with agent trajectories and other dynamic structures.</p>"},{"location":"api/world/#world.dynamic_scene_graph.DynamicSceneGraph--parameters","title":"Parameters","text":"<p>world:     The underlying :class:<code>SceneGraphWorld</code> instance. All variables and     factors are ultimately added to <code>world.wm</code>. agents:     Optional set of agent identifiers. You usually don't need to pass     this explicitly; agents are registered lazily when you call     :meth:<code>add_agent</code> or :meth:<code>add_agent_pose</code>.</p>"},{"location":"api/world/#world.dynamic_scene_graph.DynamicSceneGraph.add_agent","title":"<code>add_agent(agent_id)</code>","text":"<p>Register an agent identifier.</p> <p>This does not create any variables by itself; it simply tracks the identifier so you can discover which agents exist in the graph.</p> <p>:param agent_id: Hashable identifier for the agent (for example, <code>\"robot0\"</code>). :type agent_id: Hashable :return: The same <code>agent_id</code> that was passed in, for convenience. :rtype: Hashable</p> Source code in <code>dsg-jit/dsg_jit/world/dynamic_scene_graph.py</code> <pre><code>def add_agent(self, agent_id: Hashable) -&gt; Hashable:\n    \"\"\"Register an agent identifier.\n\n    This does not create any variables by itself; it simply tracks the\n    identifier so you can discover which agents exist in the graph.\n\n    :param agent_id: Hashable identifier for the agent (for example, ``\"robot0\"``).\n    :type agent_id: Hashable\n    :return: The same ``agent_id`` that was passed in, for convenience.\n    :rtype: Hashable\n    \"\"\"\n\n    self.agents.add(agent_id)\n    return agent_id\n</code></pre>"},{"location":"api/world/#world.dynamic_scene_graph.DynamicSceneGraph.add_agent_pose","title":"<code>add_agent_pose(agent_id, t, pose_se3)</code>","text":"<p>Add an SE(3) pose variable for a given agent and time.</p> <p>This delegates directly to :meth:<code>SceneGraphWorld.add_agent_pose_se3</code> and records the agent identifier in :attr:<code>agents</code>.</p> <p>:param agent_id: Identifier for the agent. :type agent_id: Hashable :param t: Discrete time index (for example, frame or step index). :type t: int :param pose_se3: 6D se(3) vector <code>[tx, ty, tz, rx, ry, rz]</code>. :type pose_se3: jax.numpy.ndarray :return: The node identifier of the newly created pose variable. :rtype: NodeId</p> Source code in <code>dsg-jit/dsg_jit/world/dynamic_scene_graph.py</code> <pre><code>def add_agent_pose(self, agent_id: Hashable, t: int, pose_se3: jnp.ndarray) -&gt; NodeId:\n    \"\"\"Add an SE(3) pose variable for a given agent and time.\n\n    This delegates directly to :meth:`SceneGraphWorld.add_agent_pose_se3`\n    and records the agent identifier in :attr:`agents`.\n\n    :param agent_id: Identifier for the agent.\n    :type agent_id: Hashable\n    :param t: Discrete time index (for example, frame or step index).\n    :type t: int\n    :param pose_se3: 6D se(3) vector ``[tx, ty, tz, rx, ry, rz]``.\n    :type pose_se3: jax.numpy.ndarray\n    :return: The node identifier of the newly created pose variable.\n    :rtype: NodeId\n    \"\"\"\n\n    self.agents.add(agent_id)\n    return self.world.add_agent_pose_se3(agent_id, t, pose_se3)\n</code></pre>"},{"location":"api/world/#world.dynamic_scene_graph.DynamicSceneGraph.add_agent_trajectory","title":"<code>add_agent_trajectory(agent_id, poses_se3, start_t=0, add_odom=True, default_dx=None, weight=1.0)</code>","text":"<p>Add a contiguous trajectory for one agent and optionally wire odometry.</p> <p>This is a convenience helper that repeatedly calls :meth:<code>add_agent_pose</code> and, if <code>add_odom</code> is <code>True</code>, :meth:<code>add_odom_tx</code> between consecutive time steps.</p> <p>:param agent_id: Identifier for the agent. :type agent_id: Hashable :param poses_se3: Iterable of se(3) pose vectors. The first element is     placed at <code>t = start_t</code>, the next at <code>t = start_t + 1</code>, and so on. :type poses_se3: Iterable[jax.numpy.ndarray] :param start_t: Time index to use for the first pose. :type start_t: int :param add_odom: If <code>True</code>, automatically connect consecutive poses with     a 1D odometry factor along <code>x</code> via :meth:<code>add_odom_tx</code>. :type add_odom: bool :param default_dx: If not <code>None</code>, use this value as the expected     displacement in <code>x</code> between each consecutive pair of poses. If     <code>None</code> and <code>add_odom</code> is <code>True</code>, the displacement is inferred as     <code>poses_se3[k+1][0] - poses_se3[k][0]</code>. :type default_dx: float | None :param weight: Scalar weight used for each odometry factor when     <code>add_odom</code> is enabled. :type weight: float :return: Node identifiers of all created pose variables, in temporal order. :rtype: list[NodeId]</p> Source code in <code>dsg-jit/dsg_jit/world/dynamic_scene_graph.py</code> <pre><code>def add_agent_trajectory(\n    self,\n    agent_id: Hashable,\n    poses_se3: Iterable[jnp.ndarray],\n    start_t: int = 0,\n    add_odom: bool = True,\n    default_dx: float | None = None,\n    weight: float = 1.0,\n) -&gt; List[NodeId]:\n    \"\"\"Add a contiguous trajectory for one agent and optionally wire odometry.\n\n    This is a convenience helper that repeatedly calls :meth:`add_agent_pose`\n    and, if ``add_odom`` is ``True``, :meth:`add_odom_tx` between consecutive\n    time steps.\n\n    :param agent_id: Identifier for the agent.\n    :type agent_id: Hashable\n    :param poses_se3: Iterable of se(3) pose vectors. The first element is\n        placed at ``t = start_t``, the next at ``t = start_t + 1``, and so on.\n    :type poses_se3: Iterable[jax.numpy.ndarray]\n    :param start_t: Time index to use for the first pose.\n    :type start_t: int\n    :param add_odom: If ``True``, automatically connect consecutive poses with\n        a 1D odometry factor along ``x`` via :meth:`add_odom_tx`.\n    :type add_odom: bool\n    :param default_dx: If not ``None``, use this value as the expected\n        displacement in ``x`` between each consecutive pair of poses. If\n        ``None`` and ``add_odom`` is ``True``, the displacement is inferred as\n        ``poses_se3[k+1][0] - poses_se3[k][0]``.\n    :type default_dx: float | None\n    :param weight: Scalar weight used for each odometry factor when\n        ``add_odom`` is enabled.\n    :type weight: float\n    :return: Node identifiers of all created pose variables, in temporal order.\n    :rtype: list[NodeId]\n    \"\"\"\n\n    node_ids: List[NodeId] = []\n    t = start_t\n    prev_t: int | None = None\n    prev_pose: jnp.ndarray | None = None\n\n    for pose in poses_se3:\n        nid = self.add_agent_pose(agent_id, t, pose)\n        node_ids.append(nid)\n\n        if add_odom and prev_t is not None:\n            if default_dx is not None:\n                dx = float(default_dx)\n            else:\n                # Infer displacement along x from the raw pose guesses\n                dx = float(pose[0] - prev_pose[0])\n            self.add_odom_tx(agent_id, prev_t, t, dx=dx, weight=weight)\n\n        prev_t = t\n        prev_pose = pose\n        t += 1\n\n    return node_ids\n</code></pre>"},{"location":"api/world/#world.dynamic_scene_graph.DynamicSceneGraph.add_odom_tx","title":"<code>add_odom_tx(agent_id, t0, t1, dx, weight=1.0)</code>","text":"<p>Connect two consecutive poses with a 1D odometry factor in <code>x</code>.</p> <p>This is a convenience wrapper around :meth:<code>SceneGraphWorld.add_odom_se3_additive</code>, which interprets <code>dx</code> as a translation along the <code>x</code> axis and assumes identity rotation.</p> <p>:param agent_id: Agent identifier. :type agent_id: Hashable :param t0: Time index of the from pose. :type t0: int :param t1: Time index of the to pose. :type t1: int :param dx: Expected displacement in <code>x</code> from pose <code>(agent_id, t0)</code> to     pose <code>(agent_id, t1)</code>. :type dx: float :param weight: Scalar weight applied to the odometry residual. :type weight: float :return: <code>None</code>. :rtype: None</p> Source code in <code>dsg-jit/dsg_jit/world/dynamic_scene_graph.py</code> <pre><code>def add_odom_tx(\n    self,\n    agent_id: Hashable,\n    t0: int,\n    t1: int,\n    dx: float,\n    weight: float = 1.0,\n) -&gt; None:\n    \"\"\"Connect two consecutive poses with a 1D odometry factor in ``x``.\n\n    This is a convenience wrapper around\n    :meth:`SceneGraphWorld.add_odom_se3_additive`, which interprets ``dx`` as a\n    translation along the ``x`` axis and assumes identity rotation.\n\n    :param agent_id: Agent identifier.\n    :type agent_id: Hashable\n    :param t0: Time index of the *from* pose.\n    :type t0: int\n    :param t1: Time index of the *to* pose.\n    :type t1: int\n    :param dx: Expected displacement in ``x`` from pose ``(agent_id, t0)`` to\n        pose ``(agent_id, t1)``.\n    :type dx: float\n    :param weight: Scalar weight applied to the odometry residual.\n    :type weight: float\n    :return: ``None``.\n    :rtype: None\n    \"\"\"\n\n    pose_i = self.world.pose_trajectory[(agent_id, t0)]\n    pose_j = self.world.pose_trajectory[(agent_id, t1)]\n    self.world.add_odom_se3_additive(pose_i, pose_j, dx=dx, sigma=weight)\n</code></pre>"},{"location":"api/world/#world.dynamic_scene_graph.DynamicSceneGraph.add_range_obs","title":"<code>add_range_obs(agent, t, target_nid, measured_range, sigma=0.1)</code>","text":"<p>Add a range measurement from an agent's pose at time t to a target node.</p> <p>This wraps :meth:<code>SceneGraphWorld.add_range_measurement</code>, using the pose node from <code>pose_trajectory[(agent, t)]</code>.</p> <p>:param agent: Agent key, e.g. <code>\"robot0\"</code>. :param t: Integer time step. :param target_nid: NodeId of the target (place3d, voxel_cell, object3d, etc.). :param measured_range: Observed distance. :param sigma: Optional measurement noise standard deviation.</p> Source code in <code>dsg-jit/dsg_jit/world/dynamic_scene_graph.py</code> <pre><code>def add_range_obs(\n    self,\n    agent: str,\n    t: int,\n    target_nid: int,\n    measured_range: float,\n    sigma: float | None = 0.1,\n) -&gt; None:\n    \"\"\"\n    Add a range measurement from an agent's pose at time t to a target node.\n\n    This wraps :meth:`SceneGraphWorld.add_range_measurement`, using the\n    pose node from ``pose_trajectory[(agent, t)]``.\n\n    :param agent: Agent key, e.g. ``\"robot0\"``.\n    :param t: Integer time step.\n    :param target_nid: NodeId of the target (place3d, voxel_cell, object3d, etc.).\n    :param measured_range: Observed distance.\n    :param sigma: Optional measurement noise standard deviation.\n    \"\"\"\n    pose_nid = self.world.pose_trajectory[(agent, t)]\n    self.world.add_range_measurement(\n        pose_nid=pose_nid,\n        target_nid=target_nid,\n        measured_range=measured_range,\n        sigma=sigma,\n    )\n</code></pre>"},{"location":"api/world/#world.dynamic_scene_graph.DynamicSceneGraph.all_pose_time_keys","title":"<code>all_pose_time_keys()</code>","text":"<p>Return all <code>(agent, t)</code> keys present in the underlying world.</p> <p>This is mainly useful for debugging or for building custom visualizations and exporters.</p> <p>:return: All time-index keys found in     :attr:<code>SceneGraphWorld.pose_trajectory</code>. :rtype: list[TimeKey]</p> Source code in <code>dsg-jit/dsg_jit/world/dynamic_scene_graph.py</code> <pre><code>def all_pose_time_keys(self) -&gt; List[TimeKey]:\n    \"\"\"Return all ``(agent, t)`` keys present in the underlying world.\n\n    This is mainly useful for debugging or for building custom visualizations\n    and exporters.\n\n    :return: All time-index keys found in\n        :attr:`SceneGraphWorld.pose_trajectory`.\n    :rtype: list[TimeKey]\n    \"\"\"\n\n    return list(self.world.pose_trajectory.keys())\n</code></pre>"},{"location":"api/world/#world.dynamic_scene_graph.DynamicSceneGraph.get_agent_pose_nodes","title":"<code>get_agent_pose_nodes(agent_id)</code>","text":"<p>Return the sequence of pose node IDs for an agent, ordered by time.</p> <p>:param agent_id: Agent identifier. :type agent_id: Hashable :return: Pose node IDs for the given agent, sorted by their time index. :rtype: list[NodeId]</p> Source code in <code>dsg-jit/dsg_jit/world/dynamic_scene_graph.py</code> <pre><code>def get_agent_pose_nodes(self, agent_id: Hashable) -&gt; List[NodeId]:\n    \"\"\"Return the sequence of pose node IDs for an agent, ordered by time.\n\n    :param agent_id: Agent identifier.\n    :type agent_id: Hashable\n    :return: Pose node IDs for the given agent, sorted by their time index.\n    :rtype: list[NodeId]\n    \"\"\"\n\n    times = self.get_agent_times(agent_id)\n    return [self.world.pose_trajectory[(agent_id, t)] for t in times]\n</code></pre>"},{"location":"api/world/#world.dynamic_scene_graph.DynamicSceneGraph.get_agent_times","title":"<code>get_agent_times(agent_id)</code>","text":"<p>Return the sorted list of time indices for which this agent has poses.</p> <p>:param agent_id: Agent identifier. :type agent_id: Hashable :return: Sorted time indices where <code>(agent_id, t)</code> exists in     :attr:<code>SceneGraphWorld.pose_trajectory</code>. :rtype: list[int]</p> Source code in <code>dsg-jit/dsg_jit/world/dynamic_scene_graph.py</code> <pre><code>def get_agent_times(self, agent_id: Hashable) -&gt; List[int]:\n    \"\"\"Return the sorted list of time indices for which this agent has poses.\n\n    :param agent_id: Agent identifier.\n    :type agent_id: Hashable\n    :return: Sorted time indices where ``(agent_id, t)`` exists in\n        :attr:`SceneGraphWorld.pose_trajectory`.\n    :rtype: list[int]\n    \"\"\"\n\n    times = [t for (a, t) in self.world.pose_trajectory.keys() if a == agent_id]\n    return sorted(times)\n</code></pre>"},{"location":"api/world/#world.dynamic_scene_graph.DynamicSceneGraph.get_agent_trajectory","title":"<code>get_agent_trajectory(agent_id, x_opt, index)</code>","text":"<p>Extract an optimized trajectory for one agent from a flat state vector.</p> <p>:param agent_id: Agent identifier. :type agent_id: Hashable :param x_opt: Optimized flat state vector produced by one of the     Gauss\u2013Newton solvers, such as     :func:<code>optimization.solvers.gauss_newton_manifold</code>. :type x_opt: jax.numpy.ndarray :param index: Mapping from :class:<code>NodeId</code> to <code>(start, dim)</code> tuples as     returned by :meth:<code>world.model.WorldModel.pack_state</code>. :type index: Mapping[NodeId, Tuple[int, int]] :return: Array of shape <code>(T, 6)</code> containing the se(3) vectors for each     time step in chronological order. :rtype: jax.numpy.ndarray</p> Source code in <code>dsg-jit/dsg_jit/world/dynamic_scene_graph.py</code> <pre><code>def get_agent_trajectory(\n    self,\n    agent_id: Hashable,\n    x_opt: jnp.ndarray,\n    index: Mapping[NodeId, Tuple[int, int]],\n) -&gt; jnp.ndarray:\n    \"\"\"Extract an optimized trajectory for one agent from a flat state vector.\n\n    :param agent_id: Agent identifier.\n    :type agent_id: Hashable\n    :param x_opt: Optimized flat state vector produced by one of the\n        Gauss\u2013Newton solvers, such as\n        :func:`optimization.solvers.gauss_newton_manifold`.\n    :type x_opt: jax.numpy.ndarray\n    :param index: Mapping from :class:`NodeId` to ``(start, dim)`` tuples as\n        returned by :meth:`world.model.WorldModel.pack_state`.\n    :type index: Mapping[NodeId, Tuple[int, int]]\n    :return: Array of shape ``(T, 6)`` containing the se(3) vectors for each\n        time step in chronological order.\n    :rtype: jax.numpy.ndarray\n    \"\"\"\n\n    nodes = self.get_agent_pose_nodes(agent_id)\n    traj = []\n    for nid in nodes:\n        start, dim = index[nid]\n        traj.append(x_opt[start : start + dim])\n    return jnp.stack(traj, axis=0)\n</code></pre>"},{"location":"api/world/#world.dynamic_scene_graph.DynamicSceneGraph.get_all_trajectories","title":"<code>get_all_trajectories(x_opt, index)</code>","text":"<p>Extract trajectories for all known agents from an optimized state.</p> <p>This is a convenience wrapper around :meth:<code>get_agent_trajectory</code> that iterates over :attr:<code>agents</code> and returns a mapping from agent identifier to a <code>(T_i, 6)</code> array of se(3) poses.</p> <p>:param x_opt: Optimized flat state vector produced by one of the     Gauss\u2013Newton solvers. :type x_opt: jax.numpy.ndarray :param index: Mapping from :class:<code>NodeId</code> to <code>(start, dim)</code> tuples as     returned by :meth:<code>world.model.WorldModel.pack_state</code>. :type index: Mapping[NodeId, Tuple[int, int]] :return: Dictionary mapping each agent identifier to its optimized     trajectory as an array of shape <code>(T_i, 6)</code>. :rtype: dict[Hashable, jax.numpy.ndarray]</p> Source code in <code>dsg-jit/dsg_jit/world/dynamic_scene_graph.py</code> <pre><code>def get_all_trajectories(\n    self,\n    x_opt: jnp.ndarray,\n    index: Mapping[NodeId, Tuple[int, int]],\n) -&gt; Dict[Hashable, jnp.ndarray]:\n    \"\"\"Extract trajectories for all known agents from an optimized state.\n\n    This is a convenience wrapper around :meth:`get_agent_trajectory` that\n    iterates over :attr:`agents` and returns a mapping from agent identifier\n    to a ``(T_i, 6)`` array of se(3) poses.\n\n    :param x_opt: Optimized flat state vector produced by one of the\n        Gauss\u2013Newton solvers.\n    :type x_opt: jax.numpy.ndarray\n    :param index: Mapping from :class:`NodeId` to ``(start, dim)`` tuples as\n        returned by :meth:`world.model.WorldModel.pack_state`.\n    :type index: Mapping[NodeId, Tuple[int, int]]\n    :return: Dictionary mapping each agent identifier to its optimized\n        trajectory as an array of shape ``(T_i, 6)``.\n    :rtype: dict[Hashable, jax.numpy.ndarray]\n    \"\"\"\n\n    trajectories: Dict[Hashable, jnp.ndarray] = {}\n    for agent_id in self.agents:\n        trajectories[agent_id] = self.get_agent_trajectory(agent_id, x_opt, index)\n    return trajectories\n</code></pre>"},{"location":"tutorials/","title":"DSG\u2011JIT Tutorials Overview","text":"<p>Welcome to the DSG\u2011JIT Tutorials Hub \u2014 a structured, hands\u2011on guide to understanding and using the Differentiable Scene Graph Just\u2011In\u2011Time (DSG\u2011JIT) framework.</p> <p>These tutorials are designed to move from foundational concepts toward advanced hybrid learning workflows, providing practical, minimal examples for every major subsystem in DSG\u2011JIT.</p>"},{"location":"tutorials/#what-youll-learn","title":"What You\u2019ll Learn","text":""},{"location":"tutorials/#core-concepts","title":"Core Concepts","text":"<p>Get familiar with the building blocks of DSG\u2011JIT: - How the WorldModel-backed factor graph works and how states are optimized. - The SE(3) manifold and Lie\u2011group operations. - How semantic scene graphs are constructed and maintained. - How objects, rooms, places, and agents form a unified spatial abstraction.</p>"},{"location":"tutorials/#se3-slam","title":"SE(3) &amp; SLAM","text":"<p>Dive into: - Differentiable odometry chains using the WorldModel residual architecture - Dynamic trajectories - Learnable factor\u2011type weights - Hybrid SE(3) + voxel optimization pipelines built on the WorldModel-backed factor graph - End\u2011to\u2011end differentiable SLAM examples  </p> <p>These tutorials bridge classical geometry with modern differentiable optimization.</p>"},{"location":"tutorials/#voxel-grids-spatial-fields","title":"Voxel Grids &amp; Spatial Fields","text":"<p>Learn how DSG\u2011JIT handles voxel and spatial field optimization through the WorldModel: - Voxel observation modeling - Multi\u2011voxel parameter learning - Differentiable spatial field estimation - Hybrid optimization using both geometric and volumetric cues  </p> <p>Ideal for researchers working on Neural Fields, occupancy mapping, or sensor\u2011fusion\u2011based perception.</p>"},{"location":"tutorials/#static-dynamic-scene-graphs","title":"Static &amp; Dynamic Scene Graphs","text":"<p>Understand hierarchical world modeling at scale: - Static scene graph construction - Object anchoring and semantic relations - Dynamic scene graphs with multi\u2011agent temporal layers - 3D visualization of complex DSGs  </p> <p>These tutorials show how DSG\u2011JIT organizes high\u2011level spatial semantics.</p>"},{"location":"tutorials/#sensors-fusion","title":"Sensors &amp; Fusion","text":"<p>Explore the sensor stack: - Synthetic Camera, LiDAR, and IMU simulators - Streaming, fusion callbacks, and measurement conversion - Range\u2011based DSG construction - End\u2011to\u2011end mapping from raw sensor samples  </p> <p>This layer demonstrates how sensors feed into the WorldModel, which manages the underlying factor graph and residual construction.</p>"},{"location":"tutorials/#learning-hybrid-modules","title":"Learning &amp; Hybrid Modules","text":"<p>Learn differentiable components tightly integrated into the WorldModel + DSG API: - Learnable factor-type weights - Multi\u2011modal learning (SE(3) + voxel) - Joint optimization of geometry and field representations - Trainer\u2011based workflows using JAX + JIT  </p> <p>Useful for machine\u2011learning\u2011based mapping and hybrid perception models.</p>"},{"location":"tutorials/#jax-jit-workflows","title":"JAX &amp; JIT Workflows","text":"<p>See how DSG\u2011JIT leverages JAX to: - Construct differentiable residuals - JIT\u2011compile optimization routines - Build training loops that interleave geometry and learning via the WorldModel's packed state and residual registry  </p>"},{"location":"tutorials/#how-to-use-these-tutorials","title":"How to Use These Tutorials","text":"<p>Each tutorial includes: - Categories (e.g., Core Concepts, Dynamic Scene Graphs) - Overview explaining the goal and context - Full code listing from the experiment - Step\u2011by\u2011step explanation of the logic - Summary capturing key takeaways  </p> <p>You can read them in order or jump directly to the area relevant to your research.</p>"},{"location":"tutorials/#recommended-starting-points","title":"Recommended Starting Points","text":"<p>If you're new to DSG\u2011JIT, begin here:</p> <ol> <li>Mini WorldModel &amp; Factor Graph Overview \u2014 foundational concepts  </li> <li>Manifold Geometry SE(3) \u2014 essential mathematical background  </li> <li>Scene Graph World \u2014 your first semantic world model  </li> <li>Dynamic Trajectories \u2014 motion estimation and odometry  </li> <li>Visualizing a Factor Graph in 3D \u2014 debugging and intuition  </li> </ol>"},{"location":"tutorials/#have-suggestions","title":"Have Suggestions?","text":"<p>If you'd like additional tutorials or expanded examples, feel free to open an issue on GitHub \u2014 contributions and requests are welcome!</p> <p>Continue exploring the tutorials using the navigation menu on the left.</p>"},{"location":"tutorials/differentiable_se3_odom_chain/","title":"Tutorial: Differentiable SE(3) Odometry Chain","text":"<p>Category: SE(3) &amp; SLAM, Learning &amp; Hybrid Modules</p>"},{"location":"tutorials/differentiable_se3_odom_chain/#overview","title":"Overview","text":"<p>This tutorial demonstrates how DSG\u2011JIT supports differentiable odometry, enabling SE(3)-based pose-graph optimization where the odometry measurements themselves are learnable parameters.  </p> <p>Unlike the Gauss\u2013Newton\u2013on\u2011manifold solvers used in earlier tutorials, this experiment uses a first\u2011order gradient descent (GD) optimizer. This avoids the numerical difficulty of backpropagating through repeated linear solves and ensures full differentiability end\u2011to\u2011end. Under the hood, we use a WorldModel\u2011backed factor graph, where residuals are registered with the WorldModel and state packing/unpacking is handled at the WorldModel layer.</p> <p>This experiment (based on <code>exp10_differentiable_se3_odom_chain.py</code>) walks through:</p> <ul> <li>Building a simple SE(3) chain of 3 poses  </li> <li>Adding parametric odometry factors, where the 6\u2011D odom deltas are parameters  </li> <li>Computing residuals:  </li> <li>a pose prior  </li> <li>additive SE(3) odometry factors  </li> <li>Running a differentiable \"solve\u2011then\u2011loss\" loop  </li> <li>Computing gradients with respect to the odometry measurements themselves </li> </ul> <p>This pattern is crucial for learning\u2011based odometry, self\u2011supervised calibration, and model\u2011based RL with differentiable state estimators.</p>"},{"location":"tutorials/differentiable_se3_odom_chain/#the-problem-setup","title":"The Problem Setup","text":"<p>We create three SE(3) poses, slightly perturbed from the ground truth:</p> <pre><code>pose0 = [0, 0, 0, 0, 0, 0]\npose1 = [1, 0, 0, 0, 0, 0]\npose2 = [2, 0, 0, 0, 0, 0]\n</code></pre> <p>The state lives in se(3) vector form: <code>[tx, ty, tz, wx, wy, wz]</code>.</p>"},{"location":"tutorials/differentiable_se3_odom_chain/#factors-used","title":"Factors Used","text":"Factor Meaning Notes <code>prior</code> Anchors pose0 at identity Strong prior <code>odom_se3</code> Additive odometry residual We parametrize the measurement <code>odom_se3</code> Second odometry (pose1 \u2192 pose2) Also parameterized"},{"location":"tutorials/differentiable_se3_odom_chain/#learnable-parameter","title":"Learnable Parameter","text":"<p>We stack the two odometry measurements into <code>theta</code>:</p> <pre><code>theta.shape = (2, 6)\ntheta[0] = meas(0\u21921)\ntheta[1] = meas(1\u21922)\n</code></pre> <p>These are the learnable inputs.</p>"},{"location":"tutorials/differentiable_se3_odom_chain/#build-the-worldmodelbacked-factor-graph","title":"Build the WorldModel\u2011Backed Factor Graph","text":"<p>We add the variables and factors exactly as in the experiment:</p> <pre><code>wm = WorldModel()\n\n# 1) Add pose variables (se(3) vectors)\np0_id = wm.add_variable(\n    var_type=\"pose_se3\",\n    value=jnp.array([0.1, 0.0, 0.0, 0.0, 0.0, 0.0]),\n)\np1_id = wm.add_variable(\n    var_type=\"pose_se3\",\n    value=jnp.array([0.8, 0.0, 0.0, 0.0, 0.0, 0.0]),\n)\np2_id = wm.add_variable(\n    var_type=\"pose_se3\",\n    value=jnp.array([1.7, 0.1, 0.0, 0.0, 0.0, 0.0]),\n)\n\n# 2) Add prior and odometry factors\nwm.add_factor(\n    f_type=\"prior\",\n    var_ids=(p0_id,),\n    params={\"target\": jnp.zeros(6), \"weight\": 1.0},\n)\n\n# Odometry between pose0 \u2192 pose1 and pose1 \u2192 pose2.\n# Their measurements will be parameterized by theta, so we start with placeholders.\nwm.add_factor(\n    f_type=\"odom_se3\",\n    var_ids=(p0_id, p1_id),\n    params={\"measurement\": jnp.zeros(6)},\n)\nwm.add_factor(\n    f_type=\"odom_se3\",\n    var_ids=(p1_id, p2_id),\n    params={\"measurement\": jnp.zeros(6)},\n)\n\n# 3) Register residuals at the WorldModel level\nwm.register_residual(\"prior\", prior_residual)\nwm.register_residual(\"odom_se3\", odom_se3_residual)\n</code></pre> <p>Next, we build the parametric residual function:</p> <pre><code># Helper from the experiment that builds a parametric residual\n# r(x, theta) using the WorldModel's residual registry.\nresidual_param_fn, x_init = build_param_residual(wm)\n</code></pre> <p>This yields:</p> <pre><code>residuals = r(x, theta)\n</code></pre> <p>where theta enters the odom factor residuals via the WorldModel\u2011backed builder, enabling full differentiability while keeping the graph structure and residual registry centralized in the WorldModel.</p>"},{"location":"tutorials/differentiable_se3_odom_chain/#defining-the-loss-function","title":"Defining the Loss Function","text":"<p>Here, <code>x_init</code> comes from the WorldModel via <code>build_param_residual(wm)</code>, which internally calls <code>wm.pack_state()</code> to get the initial stacked state.</p> <pre><code>def solve_and_loss(theta):\n    def objective_for_x(x):\n        r = residual_param_fn(x, theta)\n        return jnp.sum(r * r)\n\n    x_opt = gradient_descent(objective_for_x, x_init, gd_cfg)\n\n    p_stack = jnp.stack([...])\n    return jnp.sum((p_stack - gt_stack)**2)\n</code></pre>"},{"location":"tutorials/differentiable_se3_odom_chain/#differentiation-through-the-solver","title":"Differentiation Through the Solver","text":"<p>We JIT\u2011compile the loss &amp; compute gradients w.r.t theta:</p> <pre><code>loss_jit = jax.jit(solve_and_loss)\ngrad_fn = jax.jit(jax.grad(solve_and_loss))\n\nloss0 = loss_jit(theta0)\ng0 = grad_fn(theta0)\n</code></pre> <p>The key is:</p> <p>The entire SE3 optimization process is differentiable w.r.t. the odometry measurements.</p>"},{"location":"tutorials/differentiable_se3_odom_chain/#example-results","title":"Example Results","text":"<p>The experiment prints:</p> <ul> <li>Initial \u03b8 and loss  </li> <li>Gradient wrt \u03b8  </li> <li>Updated \u03b8 after one gradient step  </li> <li>Optimized poses for \u03b8\u2080 and \u03b8\u2081  </li> </ul> <p>You should see:</p> <ul> <li>The gradient pushes \u03b8 toward <code>[1,0,0,0,0,0]</code> for both odometry factors  </li> <li>The optimized poses become closer to <code>[0,1,2]</code> along x  </li> </ul>"},{"location":"tutorials/differentiable_se3_odom_chain/#summary","title":"Summary","text":"<p>In this tutorial, you learned:</p> <ul> <li>How to define parametric SE(3) odometry factors in DSG\u2011JIT  </li> <li>How to define a differentiable inner optimization loop  </li> <li>How to compute gradients wrt measurement parameters  </li> <li>Why first\u2011order solvers (like GD) are advantageous for differentiable pipelines  </li> </ul> <p>This pattern is foundational for:</p> <ul> <li>Learning odometry / motion models  </li> <li>Self-supervised robotics  </li> <li>Differentiable simulators  </li> <li>Hybrid neural\u2011optimization architectures  </li> </ul> <p>Continue to the next tutorial to extend differentiable SLAM to more complex SE(3) graphs and learned motion models.</p>"},{"location":"tutorials/differentiable_voxel_obs/","title":"Tutorial: Differentiable Voxel Observations","text":"<p>Categories: Voxel Grids &amp; Spatial Fields, JAX &amp; JIT, Core Concepts</p>"},{"location":"tutorials/differentiable_voxel_obs/#overview","title":"Overview","text":"<p>This tutorial demonstrates a core idea behind DSG-JIT:</p> <p>You can make the entire SLAM and spatial reasoning pipeline differentiable, including Gauss\u2013Newton optimization, voxel inference, and geometric factors.</p> <p>We walk through a minimal example where we optimize the position of a single voxel cell that is constrained by:</p> <p>Under the hood, this is represented as a WorldModel\u2011backed factor graph, where residuals are registered with the WorldModel and state packing/unpacking is handled at the WorldModel layer.</p> <ul> <li>A weak prior pulling it toward <code>[0, 0, 0]</code></li> <li>A strong voxel-point observation pulling it toward <code>[1, 0, 0]</code></li> </ul> <p>Then we show how to compute the gradient of the optimized voxel position with respect to the initial state, proving that the optimization is end\u2011to\u2011end differentiable.</p> <p>This type of differentiability is essential for: - Neural SLAM - Learned mapping systems - Differentiable robotics - Implicit neural fields - Calibration and meta\u2011optimization</p>"},{"location":"tutorials/differentiable_voxel_obs/#building-a-singlevoxel-optimization-problem","title":"Building a Single\u2011Voxel Optimization Problem","text":"<p>We start by constructing a tiny WorldModel\u2011backed factor graph containing:</p>"},{"location":"tutorials/differentiable_voxel_obs/#1-a-single-voxel-variable","title":"1. A single voxel variable","text":"<p>A voxel cell is simply a 3\u2011vector in (\\mathbb{R}^3). We intentionally place it incorrectly at:</p> <pre><code>[-0.5, 0.2, 0.0]\n</code></pre> <p>This allows the optimization to move it toward the true target.</p>"},{"location":"tutorials/differentiable_voxel_obs/#2-a-weak-prior","title":"2. A weak prior","text":"<p>A prior factor encourages the voxel to be close to:</p> <pre><code>[0, 0, 0]\n</code></pre> <p>This prevents degeneracy and ensures the graph is anchored.</p>"},{"location":"tutorials/differentiable_voxel_obs/#3-a-strong-voxelpoint-observation","title":"3. A strong voxel\u2013point observation","text":"<p>A more confident factor pushes the voxel toward the point:</p> <pre><code>[1, 0, 0]\n</code></pre> <p>This simulates the effect of a real sensor producing a measurement that \u201cobserves\u201d where the voxel should be.</p>"},{"location":"tutorials/differentiable_voxel_obs/#4-registering-residuals","title":"4. Registering residuals","text":"<p>We register two residuals with the WorldModel:</p> <ul> <li><code>prior_residual</code></li> <li><code>voxel_point_observation_residual</code></li> </ul> <p>These convert factor parameters and values into residual vectors consumed by Gauss\u2013Newton.</p>"},{"location":"tutorials/differentiable_voxel_obs/#5-preparing-the-manifold-metadata","title":"5. Preparing the manifold metadata","text":"<p>Voxel cells live in (\\mathbb{R}^3), so they are Euclidean. We call <code>build_manifold_metadata</code> to generate:</p> <ul> <li>Slices for each variable inside the packed vector</li> <li>The manifold type (Euclidean in this case)</li> </ul> <p>Concretely, the setup in DSG\u2011JIT looks like this:</p> <pre><code>import jax\nimport jax.numpy as jnp\n\nfrom dsg_jit.world.model import WorldModel\nfrom dsg_jit.slam.measurements import (\n    prior_residual,\n    voxel_point_observation_residual,\n)\nfrom dsg_jit.slam.manifold import build_manifold_metadata\nfrom dsg_jit.optimization.solvers import gauss_newton_manifold, GNConfig\n\n# 1) Construct the WorldModel\nwm = WorldModel()\n\n# Register residuals at the WorldModel level\nwm.register_residual(\"prior\", prior_residual)\nwm.register_residual(\"voxel_point_obs\", voxel_point_observation_residual)\n\n# 2) Add a single voxel variable (incorrect initial position)\nvoxel_id = wm.add_variable(\n    var_type=\"voxel_cell3d\",\n    value=jnp.array([-0.5, 0.2, 0.0], dtype=jnp.float32),\n)\n\n# 3) Add a weak prior pulling toward [0, 0, 0]\nwm.add_factor(\n    f_type=\"prior\",\n    var_ids=(voxel_id,),\n    params={\n        \"target\": jnp.array([0.0, 0.0, 0.0], dtype=jnp.float32),\n        \"weight\": 0.1,\n    },\n)\n\n# 4) Add a strong voxel\u2013point observation toward [1, 0, 0]\ntarget = jnp.array([1.0, 0.0, 0.0], dtype=jnp.float32)\nwm.add_factor(\n    f_type=\"voxel_point_obs\",\n    var_ids=(voxel_id,),\n    params={\n        \"point_world\": target,\n        \"weight\": 10.0,\n    },\n)\n\n# 5) Pack state and build manifold metadata\nx0, index = wm.pack_state()             # x0 is the flat voxel state\npacked_state = (x0, index)\nblock_slices, manifold_types = build_manifold_metadata(\n    packed_state=packed_state,\n    fg=wm.fg,                           # underlying factor graph structure\n)\n\n# 6) Build the residual function from the WorldModel registry\nresidual_fn = wm.build_residual()\n\n# Convenience: slice for the voxel inside x\nvoxel_slice = slice(*index[voxel_id])\ncfg = GNConfig(max_iters=10, damping=1e-3, max_step_norm=1.0)\n</code></pre>"},{"location":"tutorials/differentiable_voxel_obs/#running-differentiable-gaussnewton","title":"Running Differentiable Gauss\u2013Newton","text":"<pre><code>def solve_and_loss(x0):\n    \"\"\"\n    x0 is the packed initial voxel state (a 3\u2011vector in this example).\n    We treat it as differentiable input to the Gauss\u2013Newton solve.\n    \"\"\"\n    x_opt = gauss_newton_manifold(\n        residual_fn,\n        x0,\n        block_slices,\n        manifold_types,\n        cfg,\n    )\n\n    # Extract the optimized voxel from the flat state\n    v_opt = x_opt[voxel_slice]\n    return jnp.sum((v_opt - target) ** 2)\n</code></pre> <p>This function:</p> <ol> <li>Runs Gauss\u2013Newton on the WorldModel\u2011backed residual function  </li> <li>Retrieves the optimized voxel from the packed state  </li> <li>Computes its squared error from the target</li> </ol> <p>Because everything inside is written in pure JAX, we can do:</p> <pre><code>loss_jit = jax.jit(solve_and_loss)\ngrad_fn = jax.jit(jax.grad(solve_and_loss))\n</code></pre> <p>This allows: - JIT\u2011compiled optimization - Automatic differentiation through solver steps - True end\u2011to\u2011end differentiability</p>"},{"location":"tutorials/differentiable_voxel_obs/#taking-a-gradient-step","title":"Taking a Gradient Step","text":"<p>We evaluate:</p> <ul> <li>The initial loss</li> <li>The gradient of the loss with respect to the initial voxel value</li> <li>A gradient step on the initial voxel estimate</li> </ul> <p>This demonstrates how learning\u2011based systems could adapt voxel initializations, sensor models, or even entire map representations through backpropagation.</p>"},{"location":"tutorials/differentiable_voxel_obs/#comparing-optimized-states","title":"Comparing Optimized States","text":"<p>We solve:</p> <ul> <li>Once from the original initial state</li> <li>Once from the gradient\u2011updated initial state</li> </ul> <p>Because Gauss\u2013Newton is now embedded inside a gradient flow, we observe:</p> <ul> <li>Lower loss when using the gradient\u2011refined initialization</li> <li>Optimized voxel positions moving closer to the target</li> </ul> <p>This is the core idea behind: - meta\u2011learning initial conditions, - differentiable mapping, - amortized optimization.</p>"},{"location":"tutorials/differentiable_voxel_obs/#summary","title":"Summary","text":"<p>In this tutorial, you learned how to:</p> <ul> <li>Construct a minimal WorldModel\u2011backed factor graph with voxel variables</li> <li>Add priors and voxel-to-point observation factors</li> <li>Use the manifold Gauss\u2013Newton solver</li> <li>Make the entire optimization differentiable</li> <li>Compute gradients of SLAM solutions with respect to initial variables</li> </ul> <p>This unlocks powerful capabilities for future DSG\u2011JIT modules such as: - differentiable mapping pipelines, - neural field refinement, - learned Jacobians, - and self\u2011supervised perception systems.</p> <p>You now have the foundation for building advanced differentiable SLAM systems in DSG\u2011JIT using the WorldModel residual architecture.</p>"},{"location":"tutorials/dynamic_scenegraph_demo/","title":"Tutorial: Dynamic Scene Graph Demo","text":"<p>Categories: Dynamic Scene Graphs, SE(3) &amp; SLAM, 3D Visualization</p>"},{"location":"tutorials/dynamic_scenegraph_demo/#overview","title":"Overview","text":"<p>This tutorial presents Experiment 19 \u2014 Dynamic Scene Graph Demo, a fully featured multi\u2011agent, multi\u2011room 3D dynamic scene\u2011graph pipeline. You will learn how DSG\u2011JIT constructs and optimizes a hierarchical semantic + metric scene graph, fusing:</p> <ul> <li>Multiple rooms, places, and named objects</li> <li>Multi\u2011agent pose trajectories over time</li> <li>Odometry constraints between time steps</li> <li>Place attachments that ground agent poses within the scene structure</li> <li>Joint optimization over SE(3) and Euclidean manifolds</li> <li>Full 3D rendering of both the static world and temporal trajectories</li> </ul> <p>This experiment showcases the complete end\u2011to\u2011end workflow of Dynamic Scene Graphs in the DSL\u2011JIT framework.</p>"},{"location":"tutorials/dynamic_scenegraph_demo/#dynamic-scene-graph-construction","title":"Dynamic Scene Graph Construction","text":"<p>We build two layers:</p>"},{"location":"tutorials/dynamic_scenegraph_demo/#1-static-world-layer-scenegraphworld","title":"1. Static World Layer \u2014 <code>SceneGraphWorld</code>","text":"<p>This contains: - Rooms (A, B, C) arranged spatially along the x\u2011axis - Places within rooms, using the updated API <code>add_place3d(room_id, rel_xyz)</code> - Named objects (chair, table, plant) anchored to places via semantic factors - Place attachments linking object/pose nodes to their associated places</p>"},{"location":"tutorials/dynamic_scenegraph_demo/#2-dynamic-layer-dynamicscenegraph","title":"2. Dynamic Layer \u2014 <code>DynamicSceneGraph</code>","text":"<p>This contains: - Multiple agents (robot0 and robot1) - SE(3) agent poses over time - Odometry edges for temporal consistency: <code>add_odom_tx(agent, t0, t1, dx)</code> - Place attachments grounding agents to relevant places at selected timestamps  </p> <p>This hybrid structure creates a multi\u2011layer, multi\u2011agent dynamic spatial model.</p>"},{"location":"tutorials/dynamic_scenegraph_demo/#optimization","title":"Optimization","text":"<p>Once the scene graph is built, the full WorldModel-backed factor graph (owned by <code>SceneGraphWorld.wm</code>) is:</p> <p><pre><code># Access the WorldModel from the static scene graph\nwm = sg.wm\n\n# 1) Pack the full state from the WorldModel\nx0, index = wm.pack_state()\npacked_state = (x0, index)\n\n# 2) Build manifold metadata (SE(3) + Euclidean) from the packed state\nblock_slices, manifold_types = build_manifold_metadata(\n    packed_state=packed_state,\n    fg=wm.fg,  # underlying factor graph structure\n)\n\n# 3) Build the residual function from the WorldModel residual registry\nresidual_fn = wm.build_residual()\n\n# 4) Run manifold Gauss-Newton\ncfg = GNConfig(max_iters=20, damping=1e-3, max_step_norm=1.0)\nx_opt = gauss_newton_manifold(\n    residual_fn,\n    x0,\n    block_slices,\n    manifold_types,\n    cfg,\n)\n</code></pre> Here, the WorldModel is responsible for packing/unpacking the state and owning the residual registry, while the underlying factor graph <code>wm.fg</code> provides the structure needed for manifold metadata.</p> <p>This solves simultaneously for: - Room centers - Place positions - Object positions - All agent trajectories  </p>"},{"location":"tutorials/dynamic_scenegraph_demo/#3d-visualization","title":"3D Visualization","text":"<p>The tutorial renders two visualizations:</p>"},{"location":"tutorials/dynamic_scenegraph_demo/#1-full-static-dynamic-3d-scene-graph","title":"1. Full Static + Dynamic 3D Scene Graph","text":"<p><pre><code>plot_scenegraph_3d(\n    sg,\n    x_opt,\n    index,\n    title=\"Experiment 19 \u2014 Dynamic 3D Scene Graph\",\n    dsg=dsg,\n)\n</code></pre> This renders: - Rooms (semantic layer) - Places - Named objects - Optimized agent poses - Semantic and metric edges</p>"},{"location":"tutorials/dynamic_scenegraph_demo/#2-timecolored-agent-trajectories","title":"2. Time\u2011Colored Agent Trajectories","text":"<pre><code>plot_dynamic_trajectories_3d(\n    dsg,\n    x_opt,\n    index,\n    title=\"Experiment 19 \u2014 Dynamic 3D Scene Graph (time-colored)\",\n    color_by_time=True,\n)\n</code></pre> <p>The result is a clear dynamic\u2011spatiotemporal map of the entire scene.</p>"},{"location":"tutorials/dynamic_scenegraph_demo/#summary","title":"Summary","text":"<p>This tutorial walked through the full Dynamic Scene Graph (DSG) pipeline:</p> <ol> <li>Building a multi-room, multi-place semantic scene  </li> <li>Adding named objects  </li> <li>Creating multi-agent temporal trajectories  </li> <li>Linking poses to places with semantic factors  </li> <li>Optimizing the entire system over SE(3) + Euclidean manifolds  </li> <li>Rendering high\u2011quality 3D visualizations of the scene and trajectories  </li> </ol> <p>Experiment 19 demonstrates the power of DSG\u2011JIT for robotics, SLAM, and semantic mapping applications where agents, objects, and environments evolve together over time.</p>"},{"location":"tutorials/dynamic_trajectories/","title":"Tutorial: Dynamic Trajectories","text":"<p>Categories: Static Scene Graphs, SE(3) &amp; SLAM</p>"},{"location":"tutorials/dynamic_trajectories/#overview","title":"Overview","text":"<p>This tutorial is based on Experiment 6: Dynamic Trajectories, which demonstrates how DSG\u2011JIT represents and optimizes robot motion over time. You will learn:</p> <ul> <li>What dynamic trajectories are within the context of a Scene Graph World  </li> <li>How DSG\u2011JIT represents time\u2011indexed SE(3) robot poses  </li> <li>How to add odometry, priors, and other motion constraints  </li> <li>How to run Gauss\u2011Newton optimization over a full trajectory  </li> <li>How the dynamic aspect fits into the larger DSG pipeline</li> </ul> <p>This tutorial shows why trajectories matter, how DSG\u2011JIT builds them, and what tools the experiment uses. Under the hood, trajectories are represented in a WorldModel-backed factor graph, where residuals are registered with the WorldModel and all state packing/unpacking happens at the WorldModel layer.</p>"},{"location":"tutorials/dynamic_trajectories/#understanding-dynamic-trajectories","title":"Understanding Dynamic Trajectories","text":"<p>Robots do not exist at a single fixed pose\u2014they move through time. A dynamic trajectory is simply a sequence of SE(3) poses:</p> <p>[ T_0,\\; T_1,\\; T_2,\\; ..., T_N ]</p> <p>In DSG\u2011JIT:</p> <ul> <li>Each pose corresponds to a node in the SceneGraphWorld  </li> <li>Consecutive poses are connected using odometry SE(3) factors </li> <li>Optional priors help constrain drift  </li> <li>All poses participate in joint optimization, allowing the solver to refine the entire trajectory at once</li> </ul> <p>Experiment 6 walks through a minimal version of this workflow.</p>"},{"location":"tutorials/dynamic_trajectories/#tutorial-body","title":"Tutorial Body","text":""},{"location":"tutorials/dynamic_trajectories/#1-initialize-a-scenegraphworld","title":"1. Initialize a SceneGraphWorld","text":"<p>The experiment begins by constructing a fresh scene\u2011graph world model:</p> <pre><code>from dsg_jit.world.scene_graph import SceneGraphWorld\n\nsg = SceneGraphWorld()\n</code></pre> <p>This world model will hold:</p> <ul> <li>Robot trajectories  </li> <li>Landmarks  </li> <li>Rooms / Places (later experiments)  </li> <li>Factors &amp; residuals for optimization  </li> </ul>"},{"location":"tutorials/dynamic_trajectories/#2-add-a-robot-node-and-trajectory","title":"2. Add a Robot Node and Trajectory","text":"<p>We introduce a robot agent:</p> <pre><code>robot_id = sg.add_agent(\"robot0\")\n</code></pre> <p>Then create a sequence of pose nodes:</p> <pre><code>pose_ids = []\nfor t in range(T):\n    pid = sg.add_robot_pose_se3(\"robot0\", t)\n    pose_ids.append(pid)\n</code></pre> <p>Each pose is a node of type <code>\"pose\"</code> with 6\u2011DOF parameters.</p>"},{"location":"tutorials/dynamic_trajectories/#3-add-odometry-factors-core-of-dynamic-trajectories","title":"3. Add Odometry Factors (Core of Dynamic Trajectories)","text":"<p>Motion between pose i and pose i+1 is encoded with:</p> <pre><code>sg.add_odom_se3_additive(\n    pose_ids[i], pose_ids[i+1],\n    dx=1.0,  # unit step  \n    sigma=0.1\n)\n</code></pre> <p>This creates a Factor(type='odom_se3_additive') connecting the two poses. The solver uses these constraints to \u201cpull\u201d the poses into alignment.</p>"},{"location":"tutorials/dynamic_trajectories/#4-add-a-prior-to-anchor-the-trajectory","title":"4. Add a Prior to Anchor the Trajectory","text":"<p>Without a prior, trajectories float freely. We typically fix pose 0:</p> <pre><code>sg.add_prior_se3(pose_ids[0], value=jnp.zeros(6), sigma=1e-6)\n</code></pre> <p>This stabilizes optimization.</p>"},{"location":"tutorials/dynamic_trajectories/#5-solve-the-trajectory","title":"5. Solve the Trajectory","text":"<p>Experiment 6 uses the standard DSG\u2011JIT Gauss\u2011Newton solver on the WorldModel\u2011backed factor graph:</p> <pre><code>from dsg_jit.optimization.solvers import gauss_newton_manifold, GNConfig\nfrom dsg_jit.slam.manifold import build_manifold_metadata\n\n# Access the WorldModel from the SceneGraphWorld\nwm = sg.wm\n\n# 1) Pack the full state from the WorldModel\nx0, index = wm.pack_state()\npacked_state = (x0, index)\n\n# 2) Build manifold metadata (SE(3) + Euclidean) from the packed state\nblock_slices, manifold_types = build_manifold_metadata(\n    packed_state=packed_state,\n    fg=wm.fg,  # underlying factor graph structure\n)\n\n# 3) Build the residual function from the WorldModel residual registry\nresidual_fn = wm.build_residual()\n\n# 4) Run manifold Gauss\u2013Newton\ncfg = GNConfig(max_iters=20, damping=1e-3, max_step_norm=1.0)\nx_opt = gauss_newton_manifold(\n    residual_fn,\n    x0,\n    block_slices,\n    manifold_types,\n    cfg,\n)\n</code></pre> <p>After optimization:</p> <pre><code>values = wm.unpack_state(x_opt, index)\n</code></pre> <p>Here, the WorldModel is responsible for packing/unpacking the trajectory state and owning the residual registry, while the underlying factor graph <code>wm.fg</code> provides the structure needed for manifold metadata.</p>"},{"location":"tutorials/dynamic_trajectories/#6-visualize-the-trajectory","title":"6. Visualize the Trajectory","text":"<p>Experiment 6 ends by plotting the 3\u2011D path:</p> <pre><code>from dsg_jit.world.visualization import plot_factor_graph_3d\n\nplot_factor_graph_3d(\n    sg.wm.fg, values,\n    title=\"Dynamic Trajectory Optimization\"\n)\n</code></pre> <p>You should see a straight or slightly corrected path depending on the synthetic odometry.</p>"},{"location":"tutorials/dynamic_trajectories/#summary","title":"Summary","text":"<p>This experiment demonstrates the most essential concept in robot SLAM:</p> <p>A trajectory is a sequence of time\u2011indexed poses connected by motion constraints.</p> <p>In DSG\u2011JIT:</p> <ul> <li>Trajectories live inside a unified SceneGraphWorld </li> <li>Each pose is an SE(3) variable  </li> <li>Odometry builds the WorldModel\u2011backed factor graph structure  </li> <li>Gauss\u2011Newton refines the entire trajectory jointly  </li> <li>The system scales naturally into full SLAM with landmarks and sensor fusion  </li> </ul> <p>Dynamic trajectories are the backbone of DSG\u2011JIT\u2019s mapping capabilities, and later tutorials build on this by adding LiDAR, cameras, landmarks, and dynamic scene updates.</p>"},{"location":"tutorials/hybrid_dsg/","title":"Tutorial: Hybrid Differentiable Scene Graphs","text":"<p>Categories: SE(3) &amp; SLAM, Voxel Grids &amp; Spatial Fields, Dynamic Scene Graphs, Learning &amp; Hybrid Modules</p>"},{"location":"tutorials/hybrid_dsg/#overview","title":"Overview","text":"<p>This tutorial walks through the HERO hybrid experiment\u2014a large\u2011scale differentiable factor\u2011graph example that combines:</p> <ul> <li>6 SE(3) poses</li> <li>6 voxel centers</li> <li>Odometry factors (odom_se3)</li> <li>Voxel point observations (voxel_point_obs)</li> <li>Learnable odometry measurements</li> <li>Learnable voxel observation points</li> <li>A fully differentiable inner optimization loop  </li> <li>A fully differentiable outer learning loop</li> </ul> <p>This experiment demonstrates how to jointly learn: 1. The correct odometry increments between poses. 2. The correct observed 3D points associated with voxels. 3. The optimal state configuration of both poses and voxels.</p> <p>It represents one of the most complete examples of hybrid SE(3) + voxel learning in this repository. Under the hood, this experiment uses a WorldModel\u2011backed factor graph, where residuals are registered with the WorldModel and all state packing/unpacking happens at the WorldModel layer.</p>"},{"location":"tutorials/hybrid_dsg/#tutorial-hybrid-joint-learning-with-se3-poses-voxels","title":"Tutorial: Hybrid Joint Learning With SE(3) Poses + Voxels","text":""},{"location":"tutorials/hybrid_dsg/#1-what-we-build","title":"1. What We Build","text":"<p>We construct a hybrid WorldModel\u2011backed factor graph with:</p>"},{"location":"tutorials/hybrid_dsg/#6-se3-poses","title":"6 SE(3) Poses","text":"<p>Ground\u2011truth conceptual targets: <pre><code>pose0: [0, 0, 0, 0, 0, 0]\npose1: [1, 0, 0, 0, 0, 0]\n...\npose5: [5, 0, 0, 0, 0, 0]\n</code></pre></p> <p>Each pose has a small initial perturbation.</p>"},{"location":"tutorials/hybrid_dsg/#6-voxel-centers","title":"6 Voxel Centers","text":"<p>Ground\u2011truth conceptual targets: <pre><code>voxel0: [0, 0, 0]\nvoxel1: [1, 0, 0]\n...\nvoxel5: [5, 0, 0]\n</code></pre></p> <p>Each voxel is initialized with positional errors in x and y.</p>"},{"location":"tutorials/hybrid_dsg/#2-factor-types-in-the-graph","title":"2. Factor Types in the Graph","text":"<p>We incorporate the following factors:</p>"},{"location":"tutorials/hybrid_dsg/#prior-factors","title":"Prior Factors","text":"<ul> <li>A strong prior on <code>pose0</code> \u2192 anchors the absolute frame.</li> <li>A weak prior on <code>voxel0</code>.</li> </ul>"},{"location":"tutorials/hybrid_dsg/#odom-factors-pose_i-pose_i1","title":"Odom Factors (pose_i \u2192 pose_{i+1})","text":"<p>These are learnable: - Each odometry measurement is a 6\u2011vector SE3 increment. - Initial measurements are intentionally biased.</p>"},{"location":"tutorials/hybrid_dsg/#voxel-observation-factors-pose_j-voxel_i","title":"Voxel Observation Factors (pose_j, voxel_i)","text":"<p>These are also learnable: - Each factor uses one 3D point (world coordinate). - These 3D points become the learnable parameters <code>theta[\"obs\"]</code>.</p>"},{"location":"tutorials/hybrid_dsg/#3-parameterization","title":"3. Parameterization","text":"<p>We learn two parameter sets:</p> <pre><code>theta = {\n    \"odom\": (n_odom, 6)   # learned SE(3) increments\n    \"obs\":  (n_obs, 3)   # learned 3D observation points\n}\n</code></pre> <p>Both are jointly optimized during the outer loop.</p>"},{"location":"tutorials/hybrid_dsg/#4-inner-optimization-loop-gradient-descent","title":"4. Inner Optimization Loop (Gradient Descent)","text":"<p>We optimize the state vector (all poses + all voxels) using:</p> <ul> <li>A differentiable objective  </li> <li>Based on 0.5 * || residuals ||\u00b2  </li> <li>Gradient descent (small learning rate, 80 iterations)  </li> </ul> <p>Because the inner loop is differentiable, we can backpropagate through it to update <code>theta</code>.</p>"},{"location":"tutorials/hybrid_dsg/#5-outer-optimization-loop-learn-parameters","title":"5. Outer Optimization Loop (Learn Parameters)","text":"<p>We optimize <code>theta</code> to minimize:</p>"},{"location":"tutorials/hybrid_dsg/#pose-supervision","title":"Pose supervision","text":"<p>Encourage: <pre><code>pose5.tx \u2192 5.0\n</code></pre></p>"},{"location":"tutorials/hybrid_dsg/#voxel-supervision","title":"Voxel supervision","text":"<p>Encourage: <pre><code>voxel_i.x \u2192 i\nvoxel_i.y \u2192 0\n</code></pre></p> <p>We compute gradients using JAX: <pre><code>grad_theta = jax.grad(supervised_loss)(theta)\ntheta \u2190 theta - lr * grad_theta\n</code></pre></p> <p>This is effectively a hybrid differentiable SLAM + mapping system.</p>"},{"location":"tutorials/hybrid_dsg/#full-code-with-explanations","title":"Full Code (With Explanations)","text":""},{"location":"tutorials/hybrid_dsg/#build-the-hybrid-factor-graph","title":"Build the Hybrid Factor Graph","text":"<pre><code>def build_hybrid_graph():\n    ...\n</code></pre> <p>This constructs a WorldModel, adds all SE(3) poses, voxels, and factors described above, and returns the WorldModel (and associated pose/voxel ids) used by the rest of the experiment.</p>"},{"location":"tutorials/hybrid_dsg/#build-the-parametric-residual-function","title":"Build the Parametric Residual Function","text":"<pre><code>from dsg_jit.world.model import WorldModel\n\ndef build_param_residual(wm: WorldModel):\n    ...\n</code></pre> <ul> <li>A <code>residual(x, theta)</code> function built on top of the WorldModel residual registry  </li> <li>That injects learned odom &amp; voxel obs parameters into each corresponding factor  </li> <li>While using <code>wm.pack_state()</code> / <code>wm.unpack_state()</code> to manage the stacked state</li> </ul> <p>This keeps the graph structure, residual definitions, and packed state layout centralized in the WorldModel.</p>"},{"location":"tutorials/hybrid_dsg/#inner-solve-differentiate-through-gd","title":"Inner Solve (Differentiate Through GD)","text":"<pre><code>def inner_solve(theta):\n    x_opt = gradient_descent(objective, x0, cfg)\n</code></pre> <p>The inner optimization updates all pose/voxel states.</p>"},{"location":"tutorials/hybrid_dsg/#outer-supervised-loss","title":"Outer Supervised Loss","text":"<pre><code>def supervised_loss(theta):\n    ...\n</code></pre> <p>This controls learning behavior: - Move last pose toward 5.0 along x - Move voxels to correct x positions - Penalize y drift</p>"},{"location":"tutorials/hybrid_dsg/#training-loop","title":"Training Loop","text":"<pre><code>for it in range(steps):\n    g = grad_fn(theta)\n    theta = {\n        \"odom\": theta[\"odom\"] - lr * g[\"odom\"],\n        \"obs\":  theta[\"obs\"] - lr * g[\"obs\"],\n    }\n</code></pre>"},{"location":"tutorials/hybrid_dsg/#summary","title":"Summary","text":"<p>In this tutorial you learned how to:</p> <ul> <li>Construct a hybrid SE(3) + voxel WorldModel\u2011backed factor graph</li> <li>Parameterize both odometry and 3D point observations</li> <li>Build a differentiable residual function with parameter injection</li> <li>Implement a differentiable inner solver</li> <li>Implement an outer learning loop to optimize parameters  </li> <li>Achieve a complete end\u2011to\u2011end differentiable SLAM + mapping system</li> </ul> <p>This HERO experiment is one of the most advanced examples in the project and serves as a blueprint for (implemented on top of the WorldModel residual architecture):</p> <ul> <li>Joint pose + map learning  </li> <li>Robust SLAM systems  </li> <li>Hybrid neural\u2011symbolic optimization  </li> <li>Differentiable scene\u2011graph reasoning  </li> </ul>"},{"location":"tutorials/hybrid_se3_voxel_joint_learning/","title":"Tutorial Hybrid SE(3) + Voxel Joint Parameter Learning","text":"<p>Categories: Dynamic Scene Graphs, SE(3) &amp; SLAM, Voxel Grids &amp; Spatial Fields, Learning &amp; Hybrid Modules</p>"},{"location":"tutorials/hybrid_se3_voxel_joint_learning/#overview","title":"Overview","text":"<p>This tutorial explores joint optimization over SE(3) poses and voxel states, where both the SE(3) odometry parameters and voxel observation points are themselves learnable. The experiment demonstrates: Under the hood, this experiment uses a WorldModel-backed factor graph, where residuals are registered with the WorldModel and all state packing/unpacking happens at the WorldModel layer.</p> <ul> <li>Hybrid WorldModel-backed factor graphs mixing SE(3) trajectory variables and voxel-grid geometry.</li> <li>Building a parametric residual function that depends on both odometry and voxel-observation parameters.</li> <li>Differentiable inner\u2013outer loops: optimizing state variables in the inner loop, and optimizing sensor parameters in the outer loop.</li> <li>How DSG-JIT enables dense gradient\u2011based learning across geometric and spatial structures.</li> </ul> <p>This hybrid setup underpins modern neural\u2011SLAM models and differentiable mapping pipelines.</p>"},{"location":"tutorials/hybrid_se3_voxel_joint_learning/#hybrid-se3-voxel-joint-parameter-learning-exp15","title":"Hybrid SE3 + Voxel Joint Parameter Learning (exp15)","text":""},{"location":"tutorials/hybrid_se3_voxel_joint_learning/#1-building-the-hybrid-factor-graph","title":"1. Building the Hybrid Factor Graph","text":"<p>We create a WorldModel-backed factor graph containing:</p> <ul> <li>3 SE3 poses (each in R\u2076)</li> <li>3 voxel centers (each in R\u00b3)</li> <li>priors over pose0 and voxels 0\u20132</li> <li>2 odometry factors whose <code>measurement</code> vectors will be replaced by learnable parameters</li> <li>3 voxel_point_obs factors whose <code>point_world</code> values will also be replaced by learnable parameters</li> </ul> <p>This mirrors a mobile robot moving through an environment while simultaneously observing voxelized structure.</p>"},{"location":"tutorials/hybrid_se3_voxel_joint_learning/#2-hybrid-parametric-residual-function","title":"2. Hybrid Parametric Residual Function","text":"<p>We build:</p> <pre><code>r(x, theta)\n</code></pre> <p>Where: - <code>theta[\"odom\"]</code> provides learned odometry increments - <code>theta[\"obs\"]</code> provides learned voxel observation points</p> <p>Each factor reads its parameters from <code>theta</code> during runtime, enabling full differentiability. Concretely, this is implemented via a helper like <code>build_param_residual(wm)</code>, which iterates over the WorldModel's factors, uses the residuals registered in the WorldModel's registry, and relies on <code>wm.pack_state()</code> / <code>wm.unpack_state()</code> to manage the stacked state.</p>"},{"location":"tutorials/hybrid_se3_voxel_joint_learning/#3-inner-optimization","title":"3. Inner Optimization","text":"<p>For fixed parameters <code>theta</code>, we solve the state optimization problem:</p> <pre><code>x* = argmin_x 0.5 * || r(x, theta) ||\u00b2\n</code></pre> <p>We use first\u2011order gradient descent for stability.</p>"},{"location":"tutorials/hybrid_se3_voxel_joint_learning/#4-outer-optimization","title":"4. Outer Optimization","text":"<p>We define a supervised loss combining:</p> <ul> <li>Pose supervision (pose2.tx \u2192 2.0)</li> <li>Voxel supervision (v0\u21920, v1\u21921, v2\u21922 along x)</li> </ul> <p>We differentiate through the inner optimization to update <code>theta</code>:</p> <pre><code>theta \u2190 theta \u2212 \u03b7 \u2207_theta L(theta)\n</code></pre> <p>This jointly learns odometry increments and voxel observations.</p>"},{"location":"tutorials/hybrid_se3_voxel_joint_learning/#full-experiment-code","title":"Full Experiment Code","text":"<pre><code># See `experiments/exp15_hybrid_se3_voxel_joint_learning.py` for the full WorldModel-based\n# implementation, which:\n#   - Builds the hybrid SE(3) + voxel WorldModel-backed factor graph\n#   - Uses `build_param_residual(wm)` to construct r(x, theta)\n#   - Runs inner/outer optimization loops using JAX and the WorldModel residual registry.\n</code></pre>"},{"location":"tutorials/hybrid_se3_voxel_joint_learning/#summary","title":"Summary","text":"<p>In this tutorial, you learned how to:</p> <ul> <li>Construct a hybrid SE(3) + voxel WorldModel-backed factor graph.</li> <li>Create parametric residuals that depend on both odometry and voxel observations.</li> <li>Perform nested optimization: inner state\u2011solving and outer parameter\u2011learning.</li> <li>Build learnable calibration and mapping systems using DSG\u2011JIT with JAX.</li> </ul> <p>This pattern forms the core of differentiable SLAM, neural mapping, and hybrid geometric\u2011learning pipelines.</p> <p>```</p>"},{"location":"tutorials/learn_type_weights/","title":"Tutorial: Learning Factor-Type Weights","text":"<p>Category: Learning &amp; Hybrid Modules</p>"},{"location":"tutorials/learn_type_weights/#overview","title":"Overview","text":"<p>In modern SLAM and scene-graph optimization systems, not all measurement types are equally reliable. For example:</p> <ul> <li>Wheel odometry may drift.</li> <li>Visual place detections may produce false positives.</li> <li>GPS may be noisy in urban canyons.</li> </ul> <p>DSG\u2011JIT supports learnable factor\u2011type weighting: you can jointly optimize the scene variables and learn confidence scalings for entire classes of factors, such as <code>\"odom_se3\"</code> or <code>\"loop_closure\"</code>.</p> <p>Under the hood, this example uses a WorldModel-backed factor graph, where residuals are registered with the WorldModel and state packing/unpacking happen at the WorldModel layer.</p> <p>This tutorial is based on Experiment 11 (<code>exp11_learn_type_weights.py</code>), which demonstrates:</p> <ol> <li>A tiny factor graph combining SE(3) robot poses and a 1\u2011D \u201cplace\u201d variable.</li> <li>Competing constraints:</li> <li>Odometry wants <code>pose1.tx = 0.7</code></li> <li>A semantic \u201cattachment\u201d and a prior want <code>pose1.tx = 1.0</code></li> <li>Learning a type-level weight for <code>odom_se3</code> to reduce its influence.</li> </ol> <p>This is a fully differentiable bilevel optimization example.</p>"},{"location":"tutorials/learn_type_weights/#problem-setup","title":"Problem Setup","text":"<p>We construct a minimal WorldModel-backed factor graph:</p> <p>Variables</p> Name Type Dimension Meaning pose0 pose_se3 6 Robot start pose pose1 pose_se3 6 Robot second pose place0 place1d 1 A 1\u2011D anchor point in the world <p>Factors</p> <ol> <li> <p><code>prior(pose0)</code>    Enforces <code>pose0 = 0</code>.</p> </li> <li> <p><code>odom_se3(pose0, pose1)</code>    A biased odometry measurement wanting <code>pose1.tx = 0.7</code>.</p> </li> <li> <p><code>pose_place_attachment(pose1, place0)</code>    Enforces that <code>place0</code> should be near <code>pose1.tx</code>.</p> </li> <li> <p><code>prior(place0)</code>    Trusted semantic clue: <code>place0 = 1.0</code>.</p> </li> </ol> <p>The ground\u2011truth configuration is:</p> <ul> <li><code>pose0.tx = 0</code></li> <li><code>pose1.tx = 1</code></li> <li><code>place0 = 1</code></li> </ul> <p>But odometry tries to pull the system away from this.</p>"},{"location":"tutorials/learn_type_weights/#learning-a-type-weight","title":"Learning a Type Weight","text":"<p>We introduce a single log\u2011scale parameter for the factor type <code>\"odom_se3\"</code>:</p> <pre><code>log_scale[\"odom_se3\"]  -&gt;  scale = exp(log_scale)\n</code></pre> <p>The residual function becomes:</p> <pre><code>r_w(x, log_scales) = concat_over_factors( scale[f.type] * r_f(x) )\n</code></pre> <p>We then solve the bi\u2011level objective:</p> <ol> <li>Inner optimization (solve for x):</li> </ol> <pre><code>x*(log) = argmin_x || r_w(x, log) ||\u00b2\n</code></pre> <ol> <li>Outer optimization (learn log):</li> </ol> <pre><code>L(log) = (pose1_tx(x*(log)) - 1.0)\u00b2\n</code></pre> <p>We differentiate through the entire inner optimization using JAX and SGD.</p>"},{"location":"tutorials/learn_type_weights/#code-walkthrough","title":"Code Walkthrough","text":""},{"location":"tutorials/learn_type_weights/#building-the-problem","title":"Building the Problem","text":"<pre><code>import jax.numpy as jnp\nfrom dsg_jit.world.model import WorldModel\n\nwm = WorldModel()\n\n# Variables are stored inside the WorldModel's factor graph\npose0_id = wm.add_variable(\n    var_type=\"pose_se3\",\n    value=jnp.zeros(6, dtype=jnp.float32),\n)\npose1_id = wm.add_variable(\n    var_type=\"pose_se3\",\n    value=jnp.zeros(6, dtype=jnp.float32),\n)\nplace0_id = wm.add_variable(\n    var_type=\"place1d\",\n    value=jnp.zeros(1, dtype=jnp.float32),\n)\n</code></pre>"},{"location":"tutorials/learn_type_weights/#adding-factors","title":"Adding Factors","text":"<pre><code># Prior on pose0: pose0 = 0\nwm.add_factor(\n    f_type=\"prior\",\n    var_ids=(pose0_id,),\n    params={\"target\": jnp.zeros(6, dtype=jnp.float32)},\n)\n\n# Biased odometry: wants pose1.tx \u2248 0.7\nwm.add_factor(\n    f_type=\"odom_se3\",\n    var_ids=(pose0_id, pose1_id),\n    params={\"measurement\": biased_meas},\n)\n\n# Attachment between pose1 and place0\nwm.add_factor(\n    f_type=\"pose_place_attachment\",\n    var_ids=(pose1_id, place0_id),\n    params={...},  # e.g. a weight or scale parameter\n)\n\n# Prior on place0: place0 = 1.0\nwm.add_factor(\n    f_type=\"prior\",\n    var_ids=(place0_id,),\n    params={\"target\": jnp.array([1.0], dtype=jnp.float32)},\n)\n</code></pre>"},{"location":"tutorials/learn_type_weights/#register-residuals","title":"Register Residuals","text":"<pre><code>wm.register_residual(\"prior\", prior_residual)\nwm.register_residual(\"odom_se3\", odom_se3_residual)\nwm.register_residual(\"pose_place_attachment\", pose_place_attachment_residual)\n</code></pre>"},{"location":"tutorials/learn_type_weights/#building-the-weighted-residual-function","title":"Building the Weighted Residual Function","text":"<pre><code>factor_type_order = [\"odom_se3\"]  # we only learn a weight for odometry\n\n# WorldModel provides a helper that builds a type-weighted residual:\nresidual_w = wm.build_residual_function_with_type_weights(factor_type_order)\n</code></pre> <p>This produces a callable:</p> <pre><code>residual_w(x, log_scales)\n</code></pre> <p>where <code>log_scales</code> is a vector of shape <code>(1,)</code>, and internally the WorldModel:</p> <ul> <li>packs/unpacks the state using its own index map, and</li> <li>scales each factor's residual according to its type and the provided <code>log_scales</code>.</li> </ul>"},{"location":"tutorials/learn_type_weights/#outer-loss-function","title":"Outer Loss Function","text":"<pre><code>from dsg_jit.optimization.gradient_descent import gradient_descent\n\n# Initial stacked state from the WorldModel\nx_init, index = wm.pack_state()\n\ndef solve_and_loss(log_scales):\n    \"\"\"\n    Bi-level objective:\n      - inner: minimize weighted residuals over x\n      - outer: penalize deviation of pose1.tx from 1.0\n    \"\"\"\n    def objective_for_x(x):\n        r = residual_w(x, log_scales)\n        return jnp.sum(r * r)\n\n    x_opt = gradient_descent(objective_for_x, x_init, gd_cfg)\n\n    # Unpack optimized state via the WorldModel\n    values = wm.unpack_state(x_opt, index)\n    pose1_vec = values[pose1_id]   # 6-vector se(3)\n    pose1_tx = pose1_vec[0]        # x-translation component\n\n    return (pose1_tx - 1.0) ** 2\n</code></pre> <p>We JIT\u2011compile and differentiate it:</p> <pre><code>loss_val = solve_and_loss_jit(log_scale_odom)\ngrad     = grad_log_jit(log_scale_odom)\n</code></pre> <p>Here, the WorldModel is responsible for managing the packed state and residual registry, while the learnable type weight enters only through the scaled residuals in <code>residual_w</code>.</p>"},{"location":"tutorials/learn_type_weights/#interpretation","title":"Interpretation","text":"<ul> <li>If <code>\"odom_se3\"</code> is too influential, the estimate for <code>pose1.tx</code> will stick near 0.7.</li> <li>The learning step adjusts <code>log_scale_odom</code>, effectively down\u2011weighting odometry.</li> <li>After several iterations, <code>pose1.tx</code> moves toward 1.0, aligning with the semantic prior and attachment constraint.</li> </ul> <p>This mechanism mirrors techniques used in:</p> <ul> <li>Adaptive SLAM</li> <li>Robust back\u2011end optimization</li> <li>Meta\u2011learning measurement confidences</li> <li>Learning M\u2011estimators or robust kernels</li> </ul>"},{"location":"tutorials/learn_type_weights/#summary","title":"Summary","text":"<p>In this tutorial, you learned:</p> <ul> <li>How DSG\u2011JIT composes small multi\u2011variable SLAM problems on top of a WorldModel\u2011backed factor graph.</li> <li>How to introduce learnable per\u2011factor\u2011type weights.</li> <li>How to differentiate through optimization itself (bilevel learning).</li> <li>How semantic constraints can correct biased odometry when the system learns the appropriate weight schedule.</li> </ul> <p>This pattern generalizes to:</p> <ul> <li>Loop closures</li> <li>Landmark observations</li> <li>IMU residual weights</li> <li>Multi\u2011sensor fusion reliability learning</li> <li>Large\u2011scale SLAM backends with meta\u2011learned noise models</li> </ul> <p>You now have the core foundation for building adaptive, differentiable SLAM pipelines in DSG\u2011JIT.</p>"},{"location":"tutorials/manifold_geometry_se3/","title":"Tutorial: Understanding SE(3) Manifold Geometry","text":"<p>Category: Manifolds &amp; Geometry  </p>"},{"location":"tutorials/manifold_geometry_se3/#overview","title":"Overview","text":"<p>This tutorial introduces the SE(3) manifold, the mathematical space underlying robotics, 3D mapping, SLAM, and all pose\u2011graph optimization in DSG\u2011JIT.</p> <p>The goal is to deeply understand: - What SE(3) is - How rotations + translations combine - Why SE(3) is not a vector space - How tangent vectors, exponential maps, and geodesics work - How SE(3) is implemented inside DSG\u2011JIT  </p> <p>Under the hood, SE(3) operations in DSG\u2011JIT are used inside a WorldModel\u2011backed factor graph, where pose variables live in the WorldModel and residuals are built on top of SE(3) manifold geometry.</p>"},{"location":"tutorials/manifold_geometry_se3/#1-what-is-se3","title":"1. What is SE(3)?","text":"<p>The Special Euclidean group in 3D, SE(3), represents 3D poses consisting of: - A rotation in SO(3) - A translation in \u211d\u00b3</p> <p>Mathematically:</p> <p>[ T = \\begin{bmatrix} R &amp; t \\ 0 &amp; 1 \\end{bmatrix}, \\quad R \\in SO(3),\\ t \\in \\mathbb{R}^3 ]</p> <p>SE(3) is a Lie Group, meaning: - It is smooth and differentiable - It has an associated Lie algebra, se(3) - The exponential and logarithm maps connect the two</p> <p>This structure enables gradient\u2011based optimization on poses.</p>"},{"location":"tutorials/manifold_geometry_se3/#2-why-se3-is-not-a-vector-space","title":"2. Why SE(3) Is Not a Vector Space","text":"<p>Unlike \u211d\u2076: - You cannot add two poses. - A geodesic (shortest path) between two poses is not a straight line. - Interpolating rotations requires spherical geometry (SO(3)).</p> <p>Therefore, DSG\u2011JIT (and modern robotics libraries such as GTSAM, Kimera, Sophus, etc.) treat SE(3) as a manifold.</p>"},{"location":"tutorials/manifold_geometry_se3/#3-the-lie-algebra-se3","title":"3. The Lie Algebra se(3)","text":"<p>A tangent vector in se(3) is a 6D twist:</p> <p>[ \\xi = (\\omega_x, \\omega_y, \\omega_z, v_x, v_y, v_z) ]</p> <ul> <li>First 3 = angular velocity (axis\u2011angle)</li> <li>Last 3 = linear velocity</li> </ul> <p>We map twists \u2192 poses using the exponential map:</p> <pre><code>T = exp_se3(xi)\n</code></pre> <p>And poses \u2192 twists with the logarithm map:</p> <pre><code>xi = log_se3(T)\n</code></pre> <p>DSG\u2011JIT\u2019s SE(3) class implements both.</p>"},{"location":"tutorials/manifold_geometry_se3/#4-exponential-and-logarithm-maps","title":"4. Exponential and Logarithm Maps","text":"<p>These are essential for: - Pose integration - Backpropagation through motion models - Gauss\u2011Newton / Levenberg\u2011Marquardt - Creating geodesics (used heavily in SLAM)</p> <p>The exponential map integrates a twist:</p> <pre><code>T = exp_se3([wx, wy, wz, vx, vy, vz])\n</code></pre> <p>The log map extracts the tangent displacement from one pose to another:</p> <pre><code>xi = log_se3(inv(T1) * T2)\n</code></pre>"},{"location":"tutorials/manifold_geometry_se3/#5-se3-geodesics","title":"5. SE(3) Geodesics","text":"<p>A geodesic between two poses is a smooth curve obtained by:</p> <pre><code>T(s) = T0 * exp_se3(s * log_se3(inv(T0) * T1))\n</code></pre> <p>Where: - s \u2208 [0, 1] - T(0) = T0 - T(1) = T1  </p> <p>This is implemented in exp02_mini_world_se3_geodesic.py.</p>"},{"location":"tutorials/manifold_geometry_se3/#6-how-dsgjit-implements-se3","title":"6. How DSG\u2011JIT Implements SE(3)","text":"<p>Key functions:</p> Operation Location Description <code>exp_se3</code> <code>slam/se3_ops.py</code> Twist \u2192 Pose <code>log_se3</code> <code>slam/se3_ops.py</code> Pose \u2192 Twist <code>se3_mul</code> <code>slam/se3_ops.py</code> Pose composition <code>se3_inv</code> <code>slam/se3_ops.py</code> Pose inverse <code>se3_geodesic</code> <code>experiments/exp02_mini_world_se3_geodesic.py</code> Generates geodesic path <p>Internally, JAX is used for differentiability and vectorization. These SE(3) primitives are then consumed by the WorldModel and its residual functions to perform manifold\u2011aware SLAM and scene\u2011graph optimization.</p>"},{"location":"tutorials/manifold_geometry_se3/#7-example-computing-a-geodesic","title":"7. Example \u2013 Computing a Geodesic","text":"<pre><code>from dsg_jit.slam.se3_ops import SE3, se3_geodesic\nimport jax.numpy as jnp\n\nT0 = SE3.from_xyz_rpy(0,0,0, 0,0,0)\nT1 = SE3.from_xyz_rpy(1,0,0, 0,0,jnp.pi/2)\n\npath = se3_geodesic(T0, T1, steps=20)\n</code></pre> <p>This yields 20 poses transitioning smoothly from T0 \u2192 T1.</p>"},{"location":"tutorials/manifold_geometry_se3/#8-visualizing-the-result","title":"8. Visualizing the Result","text":"<p>Experiment <code>exp02_mini_world_se3_geodesic</code> shows: - Trajectories of SE(3) poses - Smooth rotational interpolation - How DSG\u2011JIT handles manifold navigation</p>"},{"location":"tutorials/manifold_geometry_se3/#9-summary","title":"9. Summary","text":"<p>SE(3) is the mathematical backbone of: - SLAM - Motion planning - Robot localization - Scene\u2011graph optimization in a WorldModel\u2011backed factor graph - Multisensor fusion</p> <p>Understanding manifold geometry ensures: - Stable solvers - Correct interpolation - Proper WorldModel\u2011backed factor graph construction  </p> <p>This tutorial prepares you for upcoming lessons involving: - Odometry factors - Range &amp; bearing factors - Full SLAM back\u2011ends - Dynamic scene graphs  </p>"},{"location":"tutorials/mini_world/","title":"Tutorial: Building a Mini-World Scene Graph (exp01)","text":"<p>This tutorial walks through Experiment 1 of DSG\u2011JIT: constructing a tiny static scene graph using the core <code>SceneGraphWorld</code> and <code>WorldModel</code> APIs. The goal is to explain what is being built, why each component exists, and how the engine interprets the resulting factor graph.</p>"},{"location":"tutorials/mini_world/#what-you-will-learn","title":"\ud83e\udde0 What You Will Learn","text":"<ul> <li>What a SceneGraphWorld is and why DSG\u2011JIT uses it  </li> <li>The difference between semantic nodes and geometric nodes </li> <li>How to add rooms, places, and objects </li> <li>How the underlying WorldModel stores factor graph variables  </li> <li>How to visualize the resulting scene  </li> </ul> <p>This tutorial assumes no prior SLAM knowledge \u2014 explanations are provided inline wherever new terminology appears.</p>"},{"location":"tutorials/mini_world/#1-what-is-a-scene-graph","title":"1. What is a Scene Graph?","text":"<p>A Scene Graph is a hierarchical representation of an environment. DSG\u2011JIT uses an adaptation of MIT\u2019s Dynamic Scene Graph (DSG), but this tutorial focuses on the simplest static case:</p> <pre><code>Room\n \u251c\u2500\u2500 Place A\n \u2502     \u251c\u2500\u2500 Object A1\n \u2502     \u2514\u2500\u2500 Object A2\n \u2514\u2500\u2500 Place B\n       \u2514\u2500\u2500 Object B1\n</code></pre> <ul> <li>Room = large-scale region of space  </li> <li>Place = a physically meaningful sub\u2011location  </li> <li>Object = something contained inside a place  </li> <li>Pose = geometric position/orientation stored internally as an SE(3) vector  </li> </ul> <p>In Experiment 1, each of these nodes is represented by an entry in the <code>WorldModel</code>\u2019s factor graph, meaning they have geometric variables assigned to them.</p>"},{"location":"tutorials/mini_world/#2-the-code-structure","title":"2. The Code Structure","text":"<p>Below is the annotated version of the experiment\u2019s logic. You can paste this into a Jupyter notebook or run directly.</p> <pre><code>from dsg_jit.world.scene_graph import SceneGraphWorld\nfrom dsg_jit.world.visualization import plot_factor_graph_2d\nimport jax.numpy as jnp\n\n# Create a new world\nsg = SceneGraphWorld()\n\n# Add a single room at the origin\nroomA = sg.add_room3d(jnp.array([0.0, 0.0, 0.0]))\n\n# Add two places inside the room\nplaceA = sg.add_place3d(roomA, jnp.array([1.0, 0.0, 0.0]))\nplaceB = sg.add_place3d(roomA, jnp.array([-1.0, 0.0, 0.0]))\n\n# Add objects inside each place\nobjA1 = sg.add_object3d(placeA, jnp.array([1.2, 0.1, 0.0]))\nobjA2 = sg.add_object3d(placeA, jnp.array([0.8, -0.2, 0.0]))\nobjB1 = sg.add_object3d(placeB, jnp.array([-1.2, 0.2, 0.0]))\n\n# Access the underlying WorldModel (factor graph + residual architecture)\nwm = sg.wm\n\n# Visualize the factor graph structure\nplot_factor_graph_2d(wm.fg, title=\"Mini-World Scene Graph\")\n</code></pre>"},{"location":"tutorials/mini_world/#3-why-is-this-useful","title":"3. Why Is This Useful?","text":"<p>This small example illustrates:</p>"},{"location":"tutorials/mini_world/#the-semantic-hierarchy","title":"\u2714 The semantic hierarchy","text":"<p>Rooms \u2192 Places \u2192 Objects form the backbone of DSG\u2011JIT.</p>"},{"location":"tutorials/mini_world/#object-and-place-geometry","title":"\u2714 Object and place geometry","text":"<p>Every node gets an SE(3) variable (pose), allowing downstream: - SLAM optimization - Range/bearing factor creation - Sensor alignment - Dynamic scene graph motion  </p>"},{"location":"tutorials/mini_world/#factor-graph-integration","title":"\u2714 Factor graph integration","text":"<p>Even though this example uses simple priors, all nodes are treated as optimizable geometric variables inside the factor graph.</p>"},{"location":"tutorials/mini_world/#4-how-dsg-jit-represents-geometry","title":"4. How DSG-JIT Represents Geometry","text":"<p>Each call such as:</p> <pre><code>sg.add_place3d(roomA, xyz)\n</code></pre> <p>creates:</p> <ol> <li>A semantic node (place) in the scene graph  </li> <li>A geometric variable (SE(3) pose) in the factor graph  </li> <li>A parent\u2011child semantic edge linking the place to its region  </li> </ol> <p>You can inspect all nodes with:</p> <pre><code>print(sg.wm.fg.variables)\n</code></pre>"},{"location":"tutorials/mini_world/#5-final-visualization","title":"5. Final Visualization","text":"<p>The 2D plot generated at the end shows:</p> <ul> <li>Blue points = pose nodes  </li> <li>Red lines = factor constraints  </li> <li>Clusters around the room \u2192 places \u2192 objects  </li> </ul> <p>This view is minimal but immediately useful: it shows how the world model stores and interprets the relationships between semantic and geometric elements.</p>"},{"location":"tutorials/mini_world/#summary","title":"\ud83c\udf89 Summary","text":"<p>In this tutorial you learned:</p> <ul> <li>How to build a minimal scene graph  </li> <li>How DSG-JIT connects semantic and geometric layers  </li> <li>How factor graph variables back the scene graph nodes  </li> <li>How to visualize the resulting structure  </li> </ul> <p>You are now ready for Tutorial 2, where we extend this into a temporal scene graph with robot poses and odometry constraints.</p>"},{"location":"tutorials/multi_voxel_param/","title":"Tutorial: Multi\u2011Voxel Parameter Optimization","text":"<p>Categories: Voxel Grids &amp; Spatial Fields, Learning &amp; Hybrid Modules</p>"},{"location":"tutorials/multi_voxel_param/#overview","title":"Overview","text":"<p>This tutorial demonstrates multi\u2011voxel differentiable optimization using DSG\u2011JIT. It is based on Experiment 09 and shows how to:</p> <ul> <li>Construct a chain of voxel_cell variables.</li> <li>Add priors, voxel smoothness, and voxel\u2192point observation factors.</li> <li>Build a parameterized residual function that uses an external learnable parameter <code>theta</code>.</li> <li>Run Gauss\u2013Newton (GN) optimization on the voxel variables.</li> <li>Compute gradients w.r.t. theta, enabling hybrid learning+optimization pipelines.</li> </ul> <p>The core idea:  </p> <p>We treat certain factor parameters (here, observation points) as differentiable learnable parameters and compute gradients through Gauss\u2013Newton inference.</p> <p>This is foundational for learning\u2011based SLAM, neural fields, and probabilistic mapping.</p>"},{"location":"tutorials/multi_voxel_param/#building-the-multivoxel-chain","title":"Building the Multi\u2011Voxel Chain","text":"<p>We build a simple 1D chain:</p> <pre><code>v0 \u2014 v1 \u2014 v2\n</code></pre> <p>Their ground\u2011truth positions are:</p> <pre><code>v0 = [0, 0, 0]\nv1 = [1, 0, 0]\nv2 = [2, 0, 0]\n</code></pre> <p>To make the problem interesting, the initial values are perturbed.</p> <p>The factor graph includes:</p>"},{"location":"tutorials/multi_voxel_param/#1-priors-on-the-endpoints","title":"1. Priors on the endpoints","text":"<p>These anchor the chain:</p> <ul> <li><code>v0 ~ [0,0,0]</code></li> <li><code>v2 ~ [2,0,0]</code></li> </ul>"},{"location":"tutorials/multi_voxel_param/#2-voxel-smoothness-factors","title":"2. Voxel Smoothness factors","text":"<p>These encourage:</p> <pre><code>v1 - v0 \u2248 [1,0,0]\nv2 - v1 \u2248 [1,0,0]\n</code></pre> <p>This enforces a regular grid structure.</p>"},{"location":"tutorials/multi_voxel_param/#3-voxel_point_obs-factors","title":"3. voxel_point_obs factors","text":"<p>Each voxel observes a point in the world frame:</p> <pre><code>point_world = theta[i]\n</code></pre> <p>But instead of fixing these observations, we treat the vector:</p> <pre><code>theta \u2208 R^(3\u00d73)\n</code></pre> <p>as a differentiable parameter that will affect the final voxel estimates.</p>"},{"location":"tutorials/multi_voxel_param/#parametric-residual-function","title":"Parametric Residual Function","text":"<p>The factor graph constructs:</p> <pre><code>residual_param_fn(x, theta)\n</code></pre> <p>This allows the Gauss\u2013Newton solver to optimize voxel positions conditional on the learnable parameters.</p>"},{"location":"tutorials/multi_voxel_param/#objective-function","title":"Objective Function","text":"<p>We define:</p> <pre><code>loss = \u03a3_i || v_i_opt(theta) \u2013 gt_i ||\u00b2\n</code></pre> <p>Then compute:</p> <pre><code>\u2202loss/\u2202theta\n</code></pre> <p>allowing gradient\u2011based learning of observation parameters.</p> <p>This is useful for:</p> <ul> <li>Calibrating sensors  </li> <li>Learning correction offsets  </li> <li>Optimizing geometric structures  </li> <li>Hybrid neural inference loops</li> </ul>"},{"location":"tutorials/multi_voxel_param/#running-optimization-and-computing-gradients","title":"Running Optimization and Computing Gradients","text":"<p>We JIT\u2011compile:</p> <ul> <li><code>loss(theta)</code></li> <li><code>grad(loss)(theta)</code></li> </ul> <p>Key operations:</p> <ul> <li>Perform GN optimization starting from initial state.</li> <li>Compute loss from optimized voxel positions.</li> <li>Take a gradient step in theta.</li> <li>Re\u2011run optimization to show improved voxel estimates.</li> </ul>"},{"location":"tutorials/multi_voxel_param/#summary","title":"Summary","text":"<p>This tutorial illustrates:</p> <ul> <li>How to construct voxel grids with geometric priors.</li> <li>How to integrate smoothness and observation factors.</li> <li>How to construct parametric residual functions.</li> <li>How to differentiate through Gauss\u2013Newton optimization.</li> <li>How DSG\u2011JIT supports hybrid optimization + learning pipelines.</li> </ul> <p>This forms the foundation for:</p> <ul> <li>Neural SLAM  </li> <li>Learnable spatial networks  </li> <li>Self\u2011supervised map refinement  </li> <li>Joint inference\u2011learning systems</li> </ul> <p>In the next tutorials, we will extend this to multi\u2011voxel fields, semantic voxels, and deep\u2011learned observation models.</p>"},{"location":"tutorials/multi_voxel_param_weight/","title":"Tutorial: Joint Learning of Voxel Observation Parameters &amp; Type Weights","text":"<p>Categories: Learning &amp; Hybrid Modules, Voxel Grids &amp; Spatial Fields</p>"},{"location":"tutorials/multi_voxel_param_weight/#overview","title":"Overview","text":"<p>This tutorial demonstrates a powerful capability of DSG-JIT: learning both 1. Low-level observation parameters (the world-space points used by voxel observation factors), and 2. High-level factor-type weights (the global scale applied to all <code>voxel_point_obs</code> residuals).</p> <p>This experiment shows how DSG-JIT supports nested optimization:</p> <ul> <li>Inner loop: solve voxel positions using gradient descent on the factor graph.  </li> <li>Outer loop: optimize observation parameters + weight scales to minimize supervised loss.</li> </ul> <p>The key takeaway is that entire factor graphs (including their factor types) can be made differentiable, enabling gradient-based meta-learning.</p>"},{"location":"tutorials/multi_voxel_param_weight/#the-experiment","title":"The Experiment","text":"<p>This experiment mirrors <code>exp14_multi_voxel_param_and_weight.py</code>.</p> <p>We construct a small graph with:</p> <ul> <li>Three voxel_cell3d variables: <code>v0, v1, v2</code> </li> <li>Weak voxel priors (pulling voxels toward <code>[0,1,2]</code> on x-axis)  </li> <li>Three voxel_point_obs factors with biased initial observation points  </li> <li>Learnable parameters:</li> <li><code>\u03b8[k]</code> \u2192 world-space point for voxel k  </li> <li><code>log_scale_obs</code> \u2192 global learned weight for all observation factors</li> </ul> <p>The goal is to learn both correct observation positions and appropriate weighting so that solving the factor graph recovers:</p> <pre><code>v0 \u2192 [0,0,0]\nv1 \u2192 [1,0,0]\nv2 \u2192 [2,0,0]\n</code></pre>"},{"location":"tutorials/multi_voxel_param_weight/#how-it-works","title":"How It Works","text":""},{"location":"tutorials/multi_voxel_param_weight/#1-build-the-graph","title":"1. Build the Graph","text":"<p>Each voxel is initialized slightly incorrectly:</p> <pre><code>v0 = Variable(NodeId(0), \"voxel_cell3d\", jnp.array([-0.2, 0.1, 0.0], dtype=jnp.float32))\nv1 = Variable(NodeId(1), \"voxel_cell3d\", jnp.array([0.8, -0.3, 0.0], dtype=jnp.float32))\nv2 = Variable(NodeId(2), \"voxel_cell3d\", jnp.array([2.3, 0.2, 0.0], dtype=jnp.float32))\n</code></pre> <p>Weak priors pull these toward ground truth, but the observations carry most of the corrective force.</p> <p>The observation parameters <code>theta_init</code> contain incorrect measurements:</p> <pre><code>theta_init = jnp.array([\n    [-0.5, 0.1, 0.0],\n    [0.7, -0.2, 0.0],\n    [2.4, 0.3, 0.0],\n])\n</code></pre> <p>These are the values we want to learn.</p>"},{"location":"tutorials/multi_voxel_param_weight/#2-residual-function-with-learnable-type-weight","title":"2. Residual Function With Learnable Type Weight","text":"<p>We construct:</p> <pre><code>r(x, \u03b8, log_scale_obs)\n</code></pre> <p>Where:</p> <ul> <li><code>\u03b8[k]</code> overrides each observation\u2019s <code>point_world</code></li> <li><code>log_scale_obs</code> acts as a learned intensity on all observation residuals</li> </ul> <p>Scaling is applied as:</p> <pre><code>scale_obs = jnp.exp(log_scale_obs)\nr = scale_obs * r\n</code></pre> <p>This allows the system to learn whether observation factors should be trusted more or less.</p>"},{"location":"tutorials/multi_voxel_param_weight/#3-inner-optimization-solving-for-voxels","title":"3. Inner Optimization (Solving for Voxels)","text":"<p>For fixed <code>\u03b8</code> and <code>log_scale_obs</code>, we solve:</p> <pre><code>x_opt = gradient_descent(objective, x0, cfg_inner)\n</code></pre> <p>Where:</p> <pre><code>objective(x) = 0.5 * || r(x, \u03b8, log_scale_obs) ||\u00b2\n</code></pre> <p>This yields voxel positions that reflect the current parameterization.</p>"},{"location":"tutorials/multi_voxel_param_weight/#4-outer-optimization-learning-and-log_scale","title":"4. Outer Optimization (Learning \u03b8 and log_scale)","text":"<p>We pack parameters:</p> <pre><code>p = [theta.flatten(), log_scale_obs]\n</code></pre> <p>Then compute the supervised loss:</p> <pre><code>Loss = MSE(v_opt, ground_truth) + small_regularizer_on_log_scale\n</code></pre> <p>We differentiate w.r.t. <code>p</code>:</p> <pre><code>g = grad(loss_fn)(p)\np = p - lr * g\n</code></pre> <p>With gradient clipping + explicit clamping on <code>log_scale</code>.</p>"},{"location":"tutorials/multi_voxel_param_weight/#5-results","title":"5. Results","text":"<p>At the end, we print:</p> <ul> <li>Learned \u03b8[k] for each voxel observation  </li> <li>Learned log_scale_obs </li> <li>Final voxel positions </li> <li>Comparison to ground truth  </li> </ul> <p>Typically, the system:</p> <ul> <li>Moves \u03b8[k] closer to actual voxel centers  </li> <li>Adjusts log_scale_obs to balance priors vs. observations  </li> <li>Achieves voxel positions very close to <code>[0,1,2]</code> </li> </ul>"},{"location":"tutorials/multi_voxel_param_weight/#summary","title":"Summary","text":"<p>This tutorial demonstrated:</p> <ul> <li>How to jointly learn observation parameters and global factor weights</li> <li>How DSG-JIT supports differentiable nested optimization</li> <li>How voxel-based sensor models can be refined through gradient-based meta-learning</li> </ul> <p>This capability allows DSG-JIT to serve as a foundation for:</p> <ul> <li>Self-calibrating SLAM systems  </li> <li>Learnable sensor models  </li> <li>Hybrid analytic/learned mapping pipelines  </li> <li>End-to-end differentiable robotics optimization  </li> </ul> <p>Experiment 14 shows how factors themselves can be learned, not just state variables \u2014 a key feature distinguishing DSG-JIT from traditional SLAM libraries.</p>"},{"location":"tutorials/range_sensor_dsg/","title":"Tutorial: Range Sensor Dynamic Scene Graph","text":"<p>Categories: Sensors &amp; Fusion, Dynamic Scene Graphs</p>"},{"location":"tutorials/range_sensor_dsg/#overview","title":"Overview","text":"<p>This tutorial walks through a small but complete example of using a range sensor inside a Dynamic Scene Graph (DSG) built with <code>SceneGraphWorld</code> and <code>DynamicSceneGraph</code>.</p> <p>We will:</p> <ul> <li>Build a simple world with one room and one place in 3D.</li> <li>Add a single robot agent that moves along the x-axis.</li> <li>Attach noisy range measurements from each robot pose to the fixed place.</li> <li>Let the <code>WorldModel</code> automatically convert these measurements into factors.</li> <li>Run manifold Gauss\u2013Newton to jointly refine the robot trajectory and place position.</li> <li>Visualize the resulting factor graph in 3D.</li> </ul> <p>Conceptually, this is a minimal example of range-based SLAM in the DSG-JIT engine.</p>"},{"location":"tutorials/range_sensor_dsg/#1-what-this-experiment-sets-up","title":"1. What this experiment sets up","text":"<p>The experiment in <code>expXX_range_sensor_dsg.py</code> (or similar) constructs:</p> <ul> <li>A static layer with:</li> <li>One room (1D representation) at x = 0.</li> <li>One place <code>place_A</code> in 3D at some fixed coordinate (e.g., <code>[2.0, 1.0, 0.0]</code>).</li> <li>A dynamic layer with:</li> <li>One agent <code>\"robot0\"</code>.</li> <li>A short pose chain for <code>robot0</code> along the x-axis: <code>x = 0, 1, 2, ...</code>.</li> <li>Range observations from each pose to <code>place_A</code>, with small synthetic noise.</li> </ul> <p>During optimization, the factor graph tries to reconcile:</p> <ul> <li>Odometry constraints between consecutive robot poses.</li> <li>Range constraints between each pose and the place.</li> </ul> <p>The result is a joint estimate of robot trajectory and place position that best explains all the measurements.</p>"},{"location":"tutorials/range_sensor_dsg/#2-building-the-range-sensor-dsg","title":"2. Building the range sensor DSG","text":"<p>The main construction happens in <code>build_range_dsg</code>:</p> <pre><code>import jax.numpy as jnp\n\nfrom dsg_jit.world.scene_graph import SceneGraphWorld\nfrom dsg_jit.world.dynamic_scene_graph import DynamicSceneGraph\n\n\ndef build_range_dsg(num_steps: int = 5):\n    \"\"\"Build a simple dynamic scene graph with:\n      - One robot 'robot0'\n      - A short pose chain along +x\n      - A single place at a fixed location\n      - Range measurements from each pose to that place.\n    \"\"\"\n    sg = SceneGraphWorld()\n    dsg = DynamicSceneGraph(world=sg)\n\n    # --- Create static structure: one room + one place ---\n    roomA = sg.add_room1d(x=jnp.array([0.0], dtype=jnp.float32))\n\n    place_center = jnp.array([2.0, 1.0, 0.0], dtype=jnp.float32)\n    placeA = sg.add_place3d(\"place_A\", xyz=place_center)\n    sg.add_room_place_edge(roomA, placeA)\n\n    # ... more to come (agent and range obs)\n    return sg, dsg, placeA\n</code></pre>"},{"location":"tutorials/range_sensor_dsg/#21-static-world","title":"2.1 Static world","text":"<ul> <li><code>SceneGraphWorld()</code> creates a container for the WorldModel (variables, factors) plus semantic nodes.</li> <li><code>add_room1d</code> builds a minimal room node parameterized by a 1D coordinate (here just x). It is mostly semantic and gives the place a higher-level parent.</li> <li><code>add_place3d</code> creates a 3D place node at <code>place_center</code>. This is the range sensor target.</li> <li><code>add_room_place_edge</code> connects the room and place in the scene graph.</li> </ul> <p>The static layer now represents \"room A\" with a single place <code>place_A</code> floating somewhere in front of the robot.</p>"},{"location":"tutorials/range_sensor_dsg/#3-adding-a-robot-agent-and-odometry","title":"3. Adding a robot agent and odometry","text":"<p>Next, we add a single agent and give it a short trajectory along the x-axis:</p> <pre><code>    agent = \"robot0\"\n    dsg.add_agent(agent)\n\n    # Pose 0 at origin, then move +1m each step along x\n    for t in range(num_steps):\n        x = float(t)  # ground-truth x\n        pose_vec = jnp.array([x, 0.0, 0.0, 0.0, 0.0, 0.0], dtype=jnp.float32)\n        dsg.add_agent_pose(agent, t, pose_vec)\n\n    # Odometry edges between consecutive poses\n    for t in range(num_steps - 1):\n        dsg.add_odom_tx(agent, t, t + 1, dx=1.0)\n</code></pre>"},{"location":"tutorials/range_sensor_dsg/#31-pose-representation","title":"3.1 Pose representation","text":"<p>Each pose is a 6D <code>pose_se3</code> vector:</p> <ul> <li><code>[tx, ty, tz, wx, wy, wz]</code>, where <code>t*</code> is translation and <code>w*</code> is a minimal rotation vector.</li> <li>For this toy example, we keep rotations zero and only change <code>tx</code>.</li> </ul>"},{"location":"tutorials/range_sensor_dsg/#32-odometry-edges","title":"3.2 Odometry edges","text":"<ul> <li><code>add_odom_tx(agent, t_from, t_to, dx)</code> creates an odometry factor between consecutive poses.</li> <li>Here we use a simple 1D translation <code>dx = 1.0</code> along x.</li> <li>These factors encourage <code>pose[t+1].x \u2248 pose[t].x + 1</code>.</li> </ul> <p>This gives us a tiny odom chain that the optimizer will refine.</p>"},{"location":"tutorials/range_sensor_dsg/#4-injecting-range-measurements","title":"4. Injecting range measurements","text":"<p>The interesting part of this experiment is range-only sensing.</p> <p>For each pose at time <code>t</code>, we:</p> <ol> <li>Compute the ground-truth position of the robot in world coordinates.</li> <li>Compute the true Euclidean distance to the place center.</li> <li>Add small synthetic noise.</li> <li>Call <code>add_range_obs</code> to attach a range observation factor.</li> </ol> <pre><code>    # --- Add range measurements to placeA from each pose ---\n    for t in range(num_steps):\n        x = float(t)\n        pose_pos = jnp.array([x, 0.0, 0.0], dtype=jnp.float32)\n        true_range = float(jnp.linalg.norm(place_center - pose_pos))\n\n        # Add small synthetic noise that varies with t\n        noisy_range = true_range + 0.05 * (2.0 * (t / max(1, num_steps - 1)) - 1.0)\n\n        dsg.add_range_obs(\n            agent=agent,\n            t=t,\n            target_nid=placeA,\n            measured_range=noisy_range,\n            sigma=0.1,\n        )\n</code></pre>"},{"location":"tutorials/range_sensor_dsg/#41-range-factors-in-the-worldmodel","title":"4.1 Range factors in the WorldModel","text":"<p>When you call <code>dsg.add_range_obs</code>, the <code>DynamicSceneGraph</code>:</p> <ul> <li>Looks up the pose node <code>(agent, t)</code> in the underlying <code>WorldModel</code>.</li> <li>Adds a range factor between that pose and the static place node <code>placeA</code>.</li> <li>Encodes the noisy scalar range and its uncertainty <code>sigma</code>.</li> </ul> <p>You do not need to manipulate the factor graph directly\u2014the DSG helpers create the correct variables and factors for you.</p>"},{"location":"tutorials/range_sensor_dsg/#5-optimizing-the-world","title":"5. Optimizing the world","text":"<p>Once the scene graph and dynamic layer are constructed, we can optimize the underlying factor graph using manifold Gauss\u2013Newton.</p> <p>The helper <code>optimize_world</code> encapsulates this step:</p> <pre><code>from dsg_jit.optimization.solvers import gauss_newton_manifold, GNConfig\nfrom dsg_jit.slam.manifold import build_manifold_metadata\n\n\ndef optimize_world(sg: SceneGraphWorld):\n    wm = sg.wm           # WorldModel\n    fg = wm.fg           # Underlying FactorGraph\n\n    x0, index = wm.pack_state()\n    block_slices, manifold_types = build_manifold_metadata(packed_state=wm.pack_state(), fg=fg)\n    residual_fn = wm.build_residual()\n\n    cfg = GNConfig(max_iters=20, damping=1e-3, max_step_norm=1.0)\n    x_opt = gauss_newton_manifold(\n        residual_fn,\n        x0,\n        block_slices,\n        manifold_types,\n        cfg,\n    )\n\n    values = wm.unpack_state(x_opt, index)\n\n    # Update the world variables in-place for visualization and printing\n    for nid, v in values.items():\n        wm.fg.variables[nid].value = v\n\n    return values\n</code></pre>"},{"location":"tutorials/range_sensor_dsg/#51-manifold-metadata","title":"5.1 Manifold metadata","text":"<ul> <li><code>build_manifold_metadata(fg)</code> inspects each variable type and builds:</li> <li><code>block_slices</code>: how each variable lives in the flat state vector.</li> <li><code>manifold_types</code>: whether a block is Euclidean or SE(3).</li> <li><code>gauss_newton_manifold</code> uses this metadata to:</li> <li>Compute tangent-space updates.</li> <li>Retract updates back to the correct manifold (SE(3) for poses, R^n for places).</li> </ul>"},{"location":"tutorials/range_sensor_dsg/#52-updating-the-world","title":"5.2 Updating the world","text":"<p>By writing the optimized values back into <code>fg.variables[nid].value</code>, the scene graph and visualization code see the refined state automatically.</p>"},{"location":"tutorials/range_sensor_dsg/#6-running-the-experiment-and-visualizing","title":"6. Running the experiment and visualizing","text":"<p>The <code>main()</code> function wires everything together:</p> <pre><code>from dsg_jit.world.visualization import plot_factor_graph_3d\n\n\ndef main():\n    sg, dsg, placeA = build_range_dsg(num_steps=6)\n    values = optimize_world(sg)\n\n    print(\"=== Optimized poses and place (range sensor DSG) ===\")\n    # Print poses for robot0\n    for (agent, t), nid in sorted(\n        dsg.world.pose_trajectory.items(), key=lambda kv: kv[0][1]\n    ):\n        pose = values[nid]\n        print(f\"pose[{agent}, t={t}]: {pose}\")\n\n    place_val = values[placeA]\n    print(f\"\\nOptimized place_A: {place_val}\")\n\n    # Visualize factor graph in 3D (poses and the place).\n    plot_factor_graph_3d(sg.wm.fg)\n</code></pre>"},{"location":"tutorials/range_sensor_dsg/#61-inspecting-the-result","title":"6.1 Inspecting the result","text":"<ul> <li>The printed poses should lie roughly along the x-axis, consistent with odometry and range.</li> <li><code>place_A</code> should be close to its true position (e.g., <code>[2.0, 1.0, 0.0]</code>), adjusted slightly to best fit all noisy ranges.</li> <li>The 3D plot shows:</li> <li>Robot poses as SE(3) nodes.</li> <li>The place node.</li> <li>Factors connecting them.</li> </ul>"},{"location":"tutorials/range_sensor_dsg/#7-how-this-fits-into-the-bigger-picture","title":"7. How this fits into the bigger picture","text":"<p>This range-sensor DSG experiment illustrates several key DSG-JIT concepts:</p> <ul> <li>Dynamic Scene Graphs: <code>DynamicSceneGraph</code> manages agents and time-indexed poses while delegating factor creation to the <code>WorldModel</code>.</li> <li>Sensor-Level APIs: High-level calls like <code>add_range_obs</code> let you think in terms of measurements rather than low-level factor wiring.</li> <li>Manifold Optimization: The same Gauss\u2013Newton machinery used for SLAM also refines semantic nodes (like places) when they are linked to sensor data.</li> </ul> <p>You can build on this pattern to:</p> <ul> <li>Add multiple places and multiple range targets.</li> <li>Combine range with other modalities (camera, LiDAR, IMU) in a single DSG.</li> <li>Integrate real dataset loaders that stream range measurements from logs or ROS2.</li> </ul>"},{"location":"tutorials/range_sensor_dsg/#summary","title":"Summary","text":"<p>In this tutorial, we:</p> <ul> <li>Constructed a range-sensor-aware Dynamic Scene Graph with one agent, one room, and one place.</li> <li>Attached noisy range observations from each pose to the place via <code>add_range_obs</code>.</li> <li>Used manifold-aware Gauss\u2013Newton to jointly optimize robot trajectory and place location.</li> <li>Visualized the resulting factor graph in 3D.</li> </ul> <p>This experiment is a clean starting point for range-based SLAM in DSG-JIT and shows how easily sensor modalities can be integrated via the <code>SceneGraphWorld</code> / <code>DynamicSceneGraph</code> interface.</p>"},{"location":"tutorials/scene_graph_objects/","title":"Tutorial: Working with Objects in a Scene Graph","text":"<p>Categories: Static Scene Graphs, World Modeling</p>"},{"location":"tutorials/scene_graph_objects/#overview","title":"Overview","text":"<p>In this tutorial, we expand on earlier scene-graph examples by adding semantic objects into a <code>SceneGraphWorld</code>. Objects such as chairs or tables are represented as nodes with 3D geometry (positions), and they can be linked to rooms, places, or agents through relational edges.</p> <p>This tutorial corresponds to Experiment 04 from the project and explains:</p> <ul> <li>How objects are created in DSG\u2011JIT  </li> <li>How they relate to other scene\u2011graph elements (rooms, places, agents)  </li> <li>How optimization adjusts their positions  </li> <li>How to visualize a small static scene containing semantic objects  </li> </ul>"},{"location":"tutorials/scene_graph_objects/#tutorial","title":"Tutorial","text":""},{"location":"tutorials/scene_graph_objects/#1-create-the-world-model","title":"1. Create the World Model","text":"<p>Every scene graph begins with a <code>WorldModel</code>, the optimization backend:</p> <pre><code>cfg = GNConfig(max_iters=20)\nwm = WorldModel(config=cfg)\n</code></pre>"},{"location":"tutorials/scene_graph_objects/#2-create-the-scene-graph-world","title":"2. Create the Scene Graph World","text":"<pre><code>sg = SceneGraphWorld(wm)\n</code></pre>"},{"location":"tutorials/scene_graph_objects/#3-add-a-room","title":"3. Add a Room","text":"<p>We create a room centered at the origin:</p> <pre><code>room_id = sg.add_room3d(center=jnp.array([0.0, 0.0, 0.0]))\n</code></pre> <p>Rooms serve as high\u2011level spatial partitions for grouping places and objects.</p>"},{"location":"tutorials/scene_graph_objects/#4-add-places-inside-the-room","title":"4. Add Places Inside the Room","text":"<pre><code>place_ids = [\n    sg.add_place3d(jnp.array([1.0, 0.0, 0.0])),\n    sg.add_place3d(jnp.array([0.0, 1.0, 0.0])),\n]\n</code></pre> <p>Places act as anchor points for navigation or semantic structure.</p>"},{"location":"tutorials/scene_graph_objects/#5-add-objects","title":"5. Add Objects","text":"<p>Objects are full 3D nodes that may be associated with places or rooms.</p> <pre><code>obj1 = sg.add_object3d(jnp.array([1.2, 0.1, 0.0]))   # Chair\nobj2 = sg.add_object3d(jnp.array([-0.5, -0.3, 0.0])) # Table\nobj3 = sg.add_object3d(jnp.array([0.3, 1.4, 0.0]))   # Lamp\n</code></pre>"},{"location":"tutorials/scene_graph_objects/#6-connect-objects-to-room-places","title":"6. Connect Objects to Room / Places","text":"<p>This establishes the semantic structure:</p> <pre><code>sg.add_room_object_edge(room_id, obj1)\nsg.add_room_object_edge(room_id, obj2)\nsg.add_place_object_edge(place_ids[0], obj1)\nsg.add_place_object_edge(place_ids[1], obj3)\n</code></pre> <p>These edges allow the optimizer to reason about object\u2013room and object\u2013place relations.</p>"},{"location":"tutorials/scene_graph_objects/#7-add-simple-priors","title":"7. Add Simple Priors","text":"<p>A mild prior prevents variables from drifting:</p> <pre><code>sg.add_prior_point(obj1, jnp.array([1.2, 0.1, 0.0]), sigma=0.1)\nsg.add_prior_point(obj2, jnp.array([-0.5, -0.3, 0.0]), sigma=0.1)\nsg.add_prior_point(obj3, jnp.array([0.3, 1.4, 0.0]), sigma=0.1)\n</code></pre>"},{"location":"tutorials/scene_graph_objects/#8-optimize","title":"8. Optimize","text":"<pre><code>x_opt = wm.optimize()\nvals = wm.unpack_state(x_opt)\n</code></pre>"},{"location":"tutorials/scene_graph_objects/#9-inspect-the-result","title":"9. Inspect the Result","text":"<pre><code>print(\"Room:\", vals[room_id])\nfor pid in place_ids:\n    print(\"Place:\", vals[pid])\nfor oid in [obj1, obj2, obj3]:\n    print(\"Object:\", vals[oid])\n</code></pre>"},{"location":"tutorials/scene_graph_objects/#10-visualize-the-objectlevel-scene-graph","title":"10. Visualize the Object\u2011Level Scene Graph","text":"<pre><code>plot_scenegraph_3d(\n    sg,\n    title=\"Scene Graph with Objects\",\n    show=True,\n)\n</code></pre> <p>This produces a 3D plot showing rooms, places, and objects connected by semantic edges.</p>"},{"location":"tutorials/scene_graph_objects/#summary","title":"Summary","text":"<p>In this tutorial, you learned how to:</p> <ul> <li>Create a semantic scene graph with objects</li> <li>Attach objects to rooms and places</li> <li>Add geometric priors for stability</li> <li>Visualize the resulting structure</li> </ul> <p>Objects are foundational for building rich semantic environments. Future tutorials will extend this to dynamic scene graphs and multi\u2011sensor perception.</p>"},{"location":"tutorials/scene_graph_objects_jit/","title":"Tutorial: Scene Graph Objects (JIT)","text":"<p>Categories: Static Scene Graphs, JAX &amp; JIT, Core Concepts Based on: <code>exp05_scene_graph_objects_jit.py</code></p>"},{"location":"tutorials/scene_graph_objects_jit/#overview","title":"Overview","text":"<p>This tutorial demonstrates how Dynamic Scene Graphs (DSGs) interact with JAX and <code>jit</code> compilation, using DSG\u2011JIT\u2019s optimized architecture. You will learn:</p> <ul> <li>How object nodes (e.g., places, rooms, agents) are represented.</li> <li>How edges encode structural and semantic relations.</li> <li>How DSG\u2011JIT uses JAX structures internally.</li> <li>How to construct and manipulate objects while keeping everything JAX\u2011friendly.</li> <li>The difference between standard Python execution and JIT\u2011compiled execution.</li> </ul> <p>This is a continuation of the earlier Scene Graph tutorials, now showing how these components behave under lightweight compilation.</p>"},{"location":"tutorials/scene_graph_objects_jit/#scene-graph-objects-with-jit","title":"Scene Graph Objects with JIT","text":""},{"location":"tutorials/scene_graph_objects_jit/#1-importing-required-modules","title":"1. Importing required modules","text":"<p>We begin by importing the scene graph and any JAX utilities needed for jit-friendly updates.</p> <pre><code>import jax\nimport jax.numpy as jnp\n\nfrom dsg_jit.world.scene_graph import SceneGraphWorld\n</code></pre> <p>The <code>SceneGraphWorld</code> class wraps the dynamic scene graph and world model, providing unified access to nodes, edges, and SLAM structures.</p>"},{"location":"tutorials/scene_graph_objects_jit/#2-creating-the-world-and-graph","title":"2. Creating the world and graph","text":"<p>We initialize a new SceneGraphWorld instance and extract its scene graph:</p> <pre><code>sgw = SceneGraphWorld()\nsg = sgw.sg\n</code></pre> <p>This <code>sg</code> object will host rooms, places, objects, agents, and their relational edges.</p>"},{"location":"tutorials/scene_graph_objects_jit/#3-adding-nodes-rooms-places-objects","title":"3. Adding Nodes (Rooms, Places, Objects)","text":"<p>DSG\u2011JIT organizes spatial/semantic data hierarchically:</p> <pre><code>room = sg.add_room1d(x=jnp.array([0.0]))\nplace = sg.add_place1d(room, x=jnp.array([1.0]))\nobj = sg.add_object(place, x=jnp.array([1.0]))\n</code></pre> <ul> <li>Rooms represent larger areas (topology).</li> <li>Places represent navigational nodes within rooms.</li> <li>Objects are local semantic entities attached to places.</li> </ul> <p>All positions are expressed as JAX arrays to ensure compatibility with compiled computation.</p>"},{"location":"tutorials/scene_graph_objects_jit/#4-adding-edges","title":"4. Adding Edges","text":"<p>Edges encode structural and navigational relationships:</p> <pre><code>sg.add_edge(room, place)\nsg.add_edge(place, obj)\n</code></pre> <p>These edges are stored in JAX\u2011friendly containers internally, allowing the graph to be updated or rolled into optimization stages.</p>"},{"location":"tutorials/scene_graph_objects_jit/#5-jitcompiling-graph-functions","title":"5. JIT\u2011Compiling Graph Functions","text":"<p>To demonstrate JIT compatibility, the experiment defines a simple JIT\u2011compiled function that reads node positions:</p> <pre><code>@jax.jit\ndef read_node_position(nid, node_table):\n    return node_table[nid].x\n</code></pre> <p>You can now use:</p> <pre><code>pos = read_node_position(obj, sg.nodes)\nprint(pos)\n</code></pre> <p>This confirms the nodes and their attributes are accessible inside compiled JAX functions.</p>"},{"location":"tutorials/scene_graph_objects_jit/#summary","title":"Summary","text":"<p>In this tutorial, you learned how to:</p> <ul> <li>Create scenes using DSG\u2011JIT's node primitives (rooms, places, objects).</li> <li>Add edges encoding spatial/semantic relationships.</li> <li>Work with JAX arrays for all positions.</li> <li>Use JIT\u2011compiled functions to interact with DSG internal structures.</li> </ul> <p>This experiment illustrates a foundational principle of DSG\u2011JIT: scene graphs remain fully JAX\u2011compatible, enabling high\u2011performance optimization and real\u2011time robotics applications.</p>"},{"location":"tutorials/scene_graph_world/","title":"Tutorial: SceneGraphWorld: Building a Simple Semantic World","text":"<p>Categories: Static Scene Graphs, Core Concepts, SE(3) &amp; SLAM</p> <p>This tutorial walks through Experiment 3 (<code>exp03_scene_graph_world.py</code>) and shows how to:</p> <ul> <li>Build a small WorldModel with SE(3) poses and landmark-like variables.</li> <li>Wrap it in a SceneGraphWorld to get semantic layers (poses, places, rooms).</li> <li>Add high\u2011level factors using scene\u2011graph helpers instead of wiring residuals by hand.</li> <li>Run Gauss\u2013Newton and interpret the optimized scene.</li> </ul> <p>We will stay in 1D along the x\u2011axis for clarity, but everything generalizes to full 3D.</p>"},{"location":"tutorials/scene_graph_world/#1-imports-and-setup","title":"1. Imports and setup","text":"<p>The experiment starts by importing the core world + scene\u2011graph wrappers:</p> <pre><code>import jax.numpy as jnp\n\nfrom dsg_jit.world.model import WorldModel\nfrom dsg_jit.world.scene_graph import SceneGraphWorld\n</code></pre> <ul> <li><code>WorldModel</code> wraps a low\u2011level <code>FactorGraph</code> and knows how to pack/unpack the optimization state.</li> <li><code>SceneGraphWorld</code> adds semantic structure (rooms, places, objects, agents) and high\u2011level helpers   that internally add the right variables and factors to the <code>WorldModel</code>.</li> </ul> <p>We also define a small helper to print vectors as plain Python arrays for readability.</p>"},{"location":"tutorials/scene_graph_world/#2-constructing-a-minimal-scenegraphworld","title":"2. Constructing a minimal SceneGraphWorld","text":"<p>The experiment uses a convenience constructor that builds a 1D SE(3) pose chain:</p> <pre><code>def build_scenegraph_world() -&gt; SceneGraphWorld:\n    # Create a WorldModel with a small SE(3) chain\n    wm = WorldModel.make_se3_chain(num_poses=3, dx=1.0)\n\n    # Wrap it in a SceneGraphWorld for semantic layers\n    sg = SceneGraphWorld(wm)\n    return sg\n</code></pre> <p>Conceptually:</p> <ul> <li><code>WorldModel.make_se3_chain(num_poses=3, dx=1.0)</code> creates 3 pose variables   <code>pose0, pose1, pose2</code> with initial guesses approximately at x = 0, 1, 2.</li> <li><code>SceneGraphWorld(wm)</code> does not change the underlying <code>FactorGraph</code>,   but adds bookkeeping so that each variable can also live in a semantic layer   (e.g., pose layer, place layer, room layer).</li> </ul>"},{"location":"tutorials/scene_graph_world/#3-adding-places-and-a-room-in-1d","title":"3. Adding places and a room in 1D","text":"<p>Next, we add place nodes (landmarks) and a room node along the same 1D axis:</p> <pre><code>def add_places_and_room(sg: SceneGraphWorld):\n    # Three 1D places near the poses\n    place0 = sg.add_place1d(0.1)\n    place1 = sg.add_place1d(1.2)\n    place2 = sg.add_place1d(2.1)\n\n    # One 1D room center farther out\n    room = sg.add_room1d(5.0)\n\n    return place0, place1, place2, room\n</code></pre> <p>Here:</p> <ul> <li><code>add_place1d(x)</code> creates a landmark\u2011like variable constrained to a 1D position along x.</li> <li><code>add_room1d(x)</code> creates a higher\u2011level node representing a room center in the same 1D space.</li> </ul> <p>These calls both:</p> <ol> <li>Allocate a new variable in the underlying <code>WorldModel</code>.</li> <li>Register the node in the appropriate semantic layer inside <code>SceneGraphWorld</code>.</li> </ol>"},{"location":"tutorials/scene_graph_world/#4-wiring-semantic-factors-via-helpers","title":"4. Wiring semantic factors via helpers","text":"<p>Instead of directly using low\u2011level residual functions, the tutorial uses high\u2011level helpers provided by <code>SceneGraphWorld</code>. They internally add correctly\u2011typed factors to the <code>WorldModel</code>.</p> <pre><code>def add_factors(sg: SceneGraphWorld, pose0: int, pose1: int, pose2: int,\n                place0: int, place1: int, place2: int, room: int) -&gt; None:\n    # 1) Fix the first pose at the origin (identity prior)\n    sg.add_prior_pose_identity(pose0)\n\n    # 2) SE(3) odometry chain: pose0 -&gt; pose1 -&gt; pose2, each +1m along x\n    sg.add_odom_se3_additive(pose0, pose1, dx=1.0)\n    sg.add_odom_se3_additive(pose1, pose2, dx=1.0)\n\n    # 3) Attach each pose to a nearby place along x\n    sg.attach_pose_to_place_x(pose0, place0)\n    sg.attach_pose_to_place_x(pose1, place1)\n    sg.attach_pose_to_place_x(pose2, place2)\n\n    # 4) Attach one pose to the room center along x\n    sg.attach_pose_to_room_x(pose1, room)\n</code></pre> <p>What each helper means:</p> <ul> <li><code>add_prior_pose_identity(pose0)</code></li> <li>Adds a prior factor that anchors <code>pose0</code> to the identity SE(3) transform.</li> <li> <p>This prevents the system from sliding as a whole and fixes the global frame.</p> </li> <li> <p><code>add_odom_se3_additive(i, j, dx)</code></p> </li> <li>Adds an SE(3) odometry factor between poses <code>i</code> and <code>j</code>.</li> <li> <p>In this 1D experiment, <code>dx=1.0</code> means we expect pose <code>j</code> to sit 1 meter ahead of pose <code>i</code> along x.</p> </li> <li> <p><code>attach_pose_to_place_x(pose, place)</code></p> </li> <li> <p>Adds a factor enforcing that the x\u2011coordinate of a pose and a place are consistent     (up to noise). This is like saying \u201cthis pose is currently near this place.\u201d</p> </li> <li> <p><code>attach_pose_to_room_x(pose, room)</code></p> </li> <li>Adds a factor tying a pose\u2019s x\u2011position to a room center\u2019s x\u2011position.</li> <li>This gives a soft notion of \u201cthe robot is inside this room.\u201d</li> </ul> <p>All these helpers ultimately call into <code>slam.measurements</code> residuals and register <code>Factor</code> objects with the underlying <code>FactorGraph</code>, but you don\u2019t have to wire those details manually.</p>"},{"location":"tutorials/scene_graph_world/#5-solving-the-world","title":"5. Solving the world","text":"<p>Once variables and factors are in place, we can optimize the world:</p> <pre><code>def solve_and_print(sg: SceneGraphWorld) -&gt; None:\n    # Run Gauss\u2013Newton through WorldModel\n    values = sg.wm.solve()\n\n    # Retrieve optimized SE(3) poses as 6\u2011vectors (x, y, z, rx, ry, rz)\n    pose0 = sg.wm.get_se3(0, values)\n    pose1 = sg.wm.get_se3(1, values)\n    pose2 = sg.wm.get_se3(2, values)\n\n    # Retrieve optimized places and room (as 3D vectors, but only x is meaningful here)\n    place0 = sg.wm.get_landmark(3, values)\n    place1 = sg.wm.get_landmark(4, values)\n    place2 = sg.wm.get_landmark(5, values)\n    room   = sg.wm.get_landmark(6, values)\n\n    print(\"=== Optimized Scene ===\")\n    print(f\"pose0: {pose0}\")\n    print(f\"pose1: {pose1}\")\n    print(f\"pose2: {pose2}\")\n    print(f\"place0: {place0}\")\n    print(f\"place1: {place1}\")\n    print(f\"place2: {place2}\")\n    print(f\"room:   {room}\")\n</code></pre> <p>(Exact variable IDs may differ depending on how your world was constructed; in the original experiment they are chosen to match the creation order.)</p> <p>Running this prints an optimized 1D scene where:</p> <ul> <li>The poses sit near x \u2248 0, 1, 2.</li> <li>The places are close to their associated poses.</li> <li>The room is anchored via its attachment to <code>pose1</code>.</li> </ul>"},{"location":"tutorials/scene_graph_world/#6-putting-it-all-together","title":"6. Putting it all together","text":"<p>A minimal <code>main()</code> in the experiment looks like this:</p> <pre><code>def main() -&gt; None:\n    sg = build_scenegraph_world()\n\n    # In this tiny example we know that the first three world variables\n    # are the SE(3) poses created by make_se3_chain.\n    pose0, pose1, pose2 = 0, 1, 2\n\n    place0, place1, place2, room = add_places_and_room(sg)\n    add_factors(sg, pose0, pose1, pose2, place0, place1, place2, room)\n\n    solve_and_print(sg)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>This is already a mini scene graph:</p> <ul> <li>SE(3) poses form a trajectory layer.</li> <li>Places and rooms form semantic layers on top.</li> <li>Factors express odometry, attachments, and room membership.</li> </ul> <p>All optimization is still done by the same Gauss\u2013Newton engine used everywhere else in DSG\u2011JIT.</p>"},{"location":"tutorials/scene_graph_world/#summary","title":"Summary","text":"<p>In this tutorial you learned how to:</p> <ul> <li>Construct a 1D <code>SceneGraphWorld</code></li> <li>Populate it with poses, places, and a room</li> <li>Add priors and odometry factors</li> <li>Attach semantic relationships between poses and world elements</li> <li>Run optimizations and interpret results</li> </ul> <p>This provides the foundation for creating more complex 2D/3D static and dynamic scene graphs.</p>"},{"location":"tutorials/scenegraph_3d/","title":"Tutorial: 3D Scene Graph Construction &amp; Visualization","text":"<p>Category: Dynamic Scene Graphs, SE(3) &amp; SLAM, Visualization</p>"},{"location":"tutorials/scenegraph_3d/#overview","title":"Overview","text":"<p>This tutorial demonstrates how to build, solve, and visualize a 3D Dynamic Scene Graph (DSG) using DSG\u2011JIT. We walk through:</p> <ul> <li>Constructing a SE(3) odometry factor graph </li> <li>Solving it with manifold Gauss\u2011Newton </li> <li>Exporting the optimized graph to VisNode / VisEdge structures  </li> <li>Adding a semantic layer (rooms, places, objects)  </li> <li>Rendering a layered 3D scene graph with both metric and semantic edges  </li> </ul> <p>This is a full pipeline example combining SLAM, semantics, and DSG visualization.</p>"},{"location":"tutorials/scenegraph_3d/#3d-scene-graph-tutorial-based-on-exp18_scenegraph_3dpy","title":"3D Scene Graph Tutorial (Based on <code>exp18_scenegraph_3d.py</code>)","text":""},{"location":"tutorials/scenegraph_3d/#1-build-the-se3-odometry-factor-graph","title":"1. Build the SE(3) Odometry Factor Graph","text":"<p>We construct a simple 1D pose chain:</p> <pre><code>pose0 \u2192 pose1 \u2192 pose2 \u2192 pose3 \u2192 pose4\n</code></pre> <p>Each pose is a 6\u2011vector se(3) state, and each edge is an odom_se3 geodesic residual.</p> <p>Key components: - <code>pose_se3</code> variables (<code>[tx, ty, tz, wx, wy, wz]</code>) - A strong prior on <code>pose0</code> - Consecutive odom constraints set to <code>[1, 0, 0, 0, 0, 0]</code></p> <pre><code>wm.register_residual(\"odom_se3\", odom_se3_geodesic_residual)\nwm.register_residual(\"prior\", prior_residual)\n</code></pre> <p>After adding variables and factors, we pack the state and prepare it for optimization.</p>"},{"location":"tutorials/scenegraph_3d/#2-solve-using-manifold-gaussnewton","title":"2. Solve Using Manifold Gauss\u2011Newton","text":"<p>We solve with the DSG-JIT manifold-aware solver:</p> <pre><code>cfg = GNConfig(max_iters=20, damping=1e-3, max_step_norm=1.0)\nx_opt = gauss_newton_manifold(residual_fn, x0, block_slices, manifold_types, cfg)\n</code></pre> <p>Each pose converges to an SE(3) configuration roughly aligned with:</p> <pre><code>pose_i.x \u2248 i\n</code></pre>"},{"location":"tutorials/scenegraph_3d/#3-convert-slam-graph-visnode-visedge","title":"3. Convert SLAM Graph \u2192 VisNode / VisEdge","text":"<p>DSG-JIT provides:</p> <pre><code>nodes_fg, edges_fg = export_factor_graph_for_vis(wm.fg)\n</code></pre> <p>This generates visualization-friendly structures:</p> <ul> <li>VisNode: id, type (\"pose\"), position \u2208 R\u00b3</li> <li>VisEdge: var_ids, factor_type</li> </ul> <p>These form the metric layer of the final scene graph.</p>"},{"location":"tutorials/scenegraph_3d/#4-add-semantic-structure-rooms-places-objects","title":"4. Add Semantic Structure (Rooms, Places, Objects)","text":"<p>We introduce additional node types:</p> <ul> <li>Rooms (semantic level 0)</li> <li>Places (semantic level 1)</li> <li>Objects (semantic level 2)</li> </ul> <p>We place them relative to optimized poses to simulate a building layout.</p> <p>Example:</p> <pre><code>room0 = VisNode(... type=\"room\")\nplace1 = VisNode(... type=\"place\")\nobj2 = VisNode(... type=\"object\")\n</code></pre> <p>Semantic edges are also inserted:</p> <ul> <li><code>room \u2192 place</code></li> <li><code>place \u2192 object</code></li> <li><code>pose \u2192 place</code> (robot\u2011at\u2011place)</li> </ul> <p>This creates a hierarchical spatial graph with mixed metric + semantic structure.</p>"},{"location":"tutorials/scenegraph_3d/#5-render-the-full-3d-scene-graph","title":"5. Render the Full 3D Scene Graph","text":"<p>The renderer supports:</p> <ul> <li>Layered Z\u2011offsets per type  </li> <li>Metric edges (solid black)  </li> <li>Semantic edges (dashed colored)  </li> <li>Node labels and color\u2011coding  </li> </ul> <p>Example invocation:</p> <pre><code>plot_scene_graph_3d_from_nodes(\n    all_nodes,\n    metric_edges=metric_edges,\n    semantic_edges=semantic_edges,\n    z_by_type={\"room\":0.0, \"place\":0.5, \"pose\":1.0, \"object\":1.5},\n    show_labels=True,\n)\n</code></pre> <p>This yields a clear 3D layered diagram showing:</p> <ul> <li>Pose chain (trajectory)</li> <li>Semantic structure (rooms, places, objects)</li> <li>All edges across layers</li> </ul>"},{"location":"tutorials/scenegraph_3d/#summary","title":"Summary","text":"<p>This tutorial demonstrated:</p> <ul> <li>Building and solving a manifold SE(3) SLAM factor graph</li> <li>Exporting it into DSG visualization structures</li> <li>Adding a hierarchical semantic graph</li> <li>Rendering a 3D dynamic scene graph with layered organization</li> </ul> <p>This experiment shows how DSG\u2011JIT can fuse geometry + semantics into unified 3D scene graphs suitable for robotics, SLAM, and spatial AI.</p>"},{"location":"tutorials/scenegraph_demo/","title":"Tutorial: Scene Graph Demo: Rooms, Places, Poses, and Objects","text":"<p>Categories: Static Scene Graphs, Core Concepts</p>"},{"location":"tutorials/scenegraph_demo/#overview","title":"Overview","text":"<p>This tutorial walks through a small static scene graph built directly as a <code>FactorGraph</code> in DSG\u2011JIT. Instead of running SLAM or optimization, we focus purely on structure and visualization:</p> <ul> <li>We create rooms, a shared place (corridor), robot poses, and objects.</li> <li>We connect them with semantic edges (room\u2013place, place\u2013object) and structural edges (pose chain, pose\u2013place attachment).</li> <li>We then render both a top\u2011down 2D view and a 3D scene graph view using the built\u2011in visualization utilities.</li> </ul> <p>This experiment is a good way to understand how DSG\u2011JIT can represent semantic structure on top of a metric world, even when no optimization is involved.</p>"},{"location":"tutorials/scenegraph_demo/#building-a-scene-graph-inside-a-factorgraph","title":"Building a Scene Graph Inside a FactorGraph","text":"<p>The experiment constructs a <code>FactorGraph</code> and then uses it as a structural scene graph:</p> <pre><code>from dsg_jit.core.types import NodeId, FactorId, Variable, Factor\nfrom dsg_jit.core.factor_graph import FactorGraph\nfrom dsg_jit.world.visualization import plot_factor_graph_3d, plot_factor_graph_2d\n</code></pre> <p>We start by creating the graph and defining two small helper functions:</p> <ul> <li><code>add_var</code> \u2013 creates a <code>Variable</code> with a given id, type, and value.</li> <li><code>add_edge</code> \u2013 creates a <code>Factor</code> that acts as a pure edge (no residuals) between nodes.</li> </ul> <pre><code>def build_scenegraph_factor_graph() -&gt; FactorGraph:\n    fg = FactorGraph()\n\n    # --- Helpers ------------------------------------------------------------\n    def add_var(idx: int, vtype: str, value) -&gt; NodeId:\n        nid = NodeId(idx)\n        fg.add_variable(\n            Variable(\n                id=nid,\n                type=vtype,\n                value=jnp.asarray(value, dtype=jnp.float32),\n            )\n        )\n        return nid\n\n    def add_edge(fid: int, var_indices, ftype: str = \"scene_edge\") -&gt; None:\n        fg.add_factor(\n            Factor(\n                id=FactorId(fid),\n                type=ftype,\n                var_ids=tuple(NodeId(i) for i in var_indices),\n                params={},  # purely structural, no residuals used\n            )\n        )\n</code></pre> <p>Notice that the <code>params</code> dictionary is empty. These factors are not used in any optimization; they simply encode connectivity between nodes so that visualization tools can draw edges.</p>"},{"location":"tutorials/scenegraph_demo/#step-1-adding-rooms-and-a-shared-place","title":"Step 1 \u2013 Adding Rooms and a Shared Place","text":"<p>We first create room nodes and a shared corridor place. Conceptually, you can think of them as semantic landmarks in a building.</p> <pre><code>    # --- Rooms (high-level) -------------------------------------------------\n    # Positions are (x, y, z) in \"world\" coordinates\n    room_a = add_var(100, \"room1d\", [2.0, 2.0, 1.2])   # Room A up/right\n    room_b = add_var(101, \"room1d\", [4.5, 2.0, 1.0])   # Room B further right\n\n    # --- Shared place (hallway / doorway) -----------------------------------\n    place_corridor = add_var(200, \"place1d\", [1.0, 0.0, 0.0])\n</code></pre> <p>Here:</p> <ul> <li><code>room_a</code> and <code>room_b</code> live at higher <code>y</code> coordinates, as if they are up above the robot corridor.</li> <li><code>place_corridor</code> is a shared place node (e.g., doorway or hallway intersection).</li> </ul> <p>We then connect these nodes with semantic \u201croom_place\u201d edges:</p> <pre><code>    # Connect rooms to shared place\n    eid = 0\n    add_edge(eid, [room_a, place_corridor], ftype=\"room_place\")\n    eid += 1\n    add_edge(eid, [room_b, place_corridor], ftype=\"room_place\")\n    eid += 1\n</code></pre> <p>These edges express that both rooms are accessible via the same corridor place.</p>"},{"location":"tutorials/scenegraph_demo/#step-2-robot-trajectory-poses","title":"Step 2 \u2013 Robot Trajectory Poses","text":"<p>Next, we add a small chain of robot poses near the corridor and connect them with a \u201cpose_chain\u201d edge type:</p> <pre><code>    # --- Robot trajectory (poses near the place) ----------------------------\n    pose_ids = []\n    for i, x in enumerate([-1.0, -0.2, 0.6, 1.4, 2.2]):\n        # pose_se3: [tx, ty, tz, roll, pitch, yaw]\n        p = add_var(10 + i, \"pose_se3\", [x, 0.0, 0.5, 0.0, 0.0, 0.0])\n        pose_ids.append(p)\n\n    # Link poses in a chain (visual odometry edges)\n    for i in range(len(pose_ids) - 1):\n        add_edge(eid, [pose_ids[i], pose_ids[i + 1]], ftype=\"pose_chain\")\n        eid += 1\n</code></pre> <p>Key ideas:</p> <ul> <li>Each <code>pose_se3</code> is a 6\u2011DoF pose, but here we keep everything flat (only <code>tx</code> and <code>z=0.5</code> change).</li> <li>The <code>pose_chain</code> factors represent odometry-style connectivity, but again, they are purely structural in this demo.</li> </ul> <p>We also connect every pose back to the corridor place with a <code>pose_place_attachment</code> edge type:</p> <pre><code>    # Attach all poses to the corridor place (like a localization prior)\n    for pid in pose_ids:\n        add_edge(eid, [pid, place_corridor], ftype=\"pose_place_attachment\")\n        eid += 1\n</code></pre> <p>Conceptually, this says: the robot\u2019s trajectory is localized around this shared corridor place.</p>"},{"location":"tutorials/scenegraph_demo/#step-3-objects-attached-to-the-place","title":"Step 3 \u2013 Objects Attached to the Place","text":"<p>We then add a few object nodes\u2014represented as small \u201cvoxel_cell\u201d variables\u2014near the corridor, and attach them to the place:</p> <pre><code>    # --- Objects near the place ---------------------------------------------\n    obj_chair = add_var(300, \"voxel_cell\", [0.7, 0.4, 0.6])\n    obj_table = add_var(301, \"voxel_cell\", [1.3, 0.5, 0.7])\n    obj_plant = add_var(302, \"voxel_cell\", [0.9, 0.9, 0.9])\n\n    # Attach objects to the place (semantic containment)\n    add_edge(eid, [place_corridor, obj_chair], ftype=\"place_object\")\n    eid += 1\n    add_edge(eid, [place_corridor, obj_table], ftype=\"place_object\")\n    eid += 1\n    add_edge(eid, [place_corridor, obj_plant], ftype=\"place_object\")\n    eid += 1\n</code></pre> <p>These \u201cvoxel_cell\u201d entries stand in for localized 3D objects (e.g., the centroid of a chair point cloud). The edges with type <code>\"place_object\"</code> encode a simple containment or \u201clocated at\u201d relationship:</p> <ul> <li>The chair, table, and plant all \u201clive\u201d at the corridor place.</li> </ul> <p>At this point, the <code>FactorGraph</code> encodes a complete layered scene graph:</p> <ul> <li>Rooms (high-level regions)</li> <li>Place (corridor) connecting the rooms</li> <li>Robot trajectory poses moving through the corridor</li> <li>Objects attached to the place</li> </ul> <p>No optimization has been run; it is purely a hand\u2011crafted scene.</p>"},{"location":"tutorials/scenegraph_demo/#visualizing-the-scene-graph-2d-and-3d","title":"Visualizing the Scene Graph (2D and 3D)","text":"<p>The <code>main()</code> function of the experiment simply builds the graph and calls the visualization helpers:</p> <pre><code>def main() -&gt; None:\n    fg = build_scenegraph_factor_graph()\n\n    # Just visualize \u2013 no optimization in this hero scene graph demo.\n    print(\"=== DSG-JIT Scene Graph Demo (exp18) ===\")\n    print(f\"Num variables: {len(fg.variables)}\")\n    print(f\"Num factors:   {len(fg.factors)}\")\n\n    # 2D top-down\n    plot_factor_graph_2d(fg, show_labels=True)\n\n    # 3D view\n    plot_factor_graph_3d(fg, show_labels=True)\n</code></pre> <ul> <li><code>plot_factor_graph_2d</code> gives a top\u2011down view (e.g., x\u2013y plane) with nodes and edges.</li> <li><code>plot_factor_graph_3d</code> renders the full 3D layout, including the vertical separation between rooms, place, and objects if encoded in the positions.</li> </ul> <p>You can run this experiment from the repository root (after setting <code>PYTHONPATH=src</code>) to see both visualizations:</p> <pre><code>export PYTHONPATH=src\npython3 experiments/expXX_scenegraph_demo.py  # use the actual filename in your repo\n</code></pre> <p>(Replace <code>expXX_scenegraph_demo.py</code> with the real experiment filename if it differs.)</p>"},{"location":"tutorials/scenegraph_demo/#summary","title":"Summary","text":"<p>In this tutorial, we:</p> <ul> <li>Built a static scene graph inside a <code>FactorGraph</code> using <code>Variable</code> and <code>Factor</code> objects.</li> <li>Created rooms, a shared corridor place, robot poses, and objects with simple numeric positions.</li> <li>Connected them with semantic edge types (<code>room_place</code>, <code>pose_place_attachment</code>, <code>place_object</code>) and structural edges (<code>pose_chain</code>).</li> <li>Visualized the resulting structure using <code>plot_factor_graph_2d</code> and <code>plot_factor_graph_3d</code>.</li> </ul> <p>Even without running any optimization, this experiment demonstrates how DSG\u2011JIT can serve as a unified representation for metric (positions) and semantic (rooms, places, objects) information. In later tutorials, you can combine these ideas with SLAM, sensor fusion, and learning to build fully dynamic, optimized scene graphs.</p>"},{"location":"tutorials/scenegraph_type_weights/","title":"Tutorial: Learnable Factor-Type Weights in a Scene Graph","text":"<p>Categories: Dynamic Scene Graphs, Learning &amp; Hybrid Modules, SE(3) &amp; SLAM</p>"},{"location":"tutorials/scenegraph_type_weights/#overview","title":"Overview","text":"<p>In many robotics and SLAM systems, factor graphs contain multiple types of constraints\u2014priors, odometry, attachments, and others. Typically, each factor type is assigned a fixed weight reflecting its reliability. However, in modern differentiable SLAM, we can learn optimal per-type weights by differentiating through the optimization process itself.</p> <p>This tutorial demonstrates:</p> <ul> <li>How to construct a minimal SceneGraphWorld with SE(3) poses.</li> <li>How to integrate factors such as priors and odometry.</li> <li>How to use DSGTrainer, which performs differentiable inner-loop optimization.</li> <li>How to define a supervised loss on the final scene graph state.</li> <li>How to backpropagate through the entire factor graph to learn factor-type weights.</li> </ul> <p>This experiment corresponds to <code>exp12_scenegraph_learnable_type_weights.py</code>.</p>"},{"location":"tutorials/scenegraph_type_weights/#1-problem-setup","title":"1. Problem Setup","text":"<p>We consider a tiny SceneGraph containing:</p> <ul> <li>Two SE(3) robot poses (<code>pose0</code>, <code>pose1</code>, <code>pose2</code>)</li> <li>A prior on the first pose (fixing it at the origin)</li> <li>Odometry factors connecting the poses, but with biased measurements</li> </ul> <p>The goal is to learn a scalar weight for the <code>\"odom_se3\"</code> factor type such that the optimized <code>pose2.tx</code> matches its ground truth value of 2.0.</p> <p>If odometry has too much weight, the graph pulls toward biased odometry. If we learn to down-weight odometry, the solution aligns with ground-truth priors.</p>"},{"location":"tutorials/scenegraph_type_weights/#2-building-the-scenegraph","title":"2. Building the SceneGraph","text":"<pre><code>sg = SceneGraphWorld()\nwm = sg.wm\nfg = wm.fg\n\nwm.register_residual(\"prior\", prior_residual)\nwm.register_residual(\"odom_se3\", odom_se3_residual)\n\np0 = sg.add_pose_se3(jnp.array([0.1, 0.0, 0.0, 0.0, 0.0, 0.0], dtype=jnp.float32))\np1 = sg.add_pose_se3(jnp.array([0.8, 0.0, 0.0, 0.0, 0.0, 0.0], dtype=jnp.float32))\np2 = sg.add_pose_se3(jnp.array([1.7, 0.0, 0.0, 0.0, 0.0, 0.0], dtype=jnp.float32))\n</code></pre> <p>We insert:</p> <ul> <li>Weak prior on <code>p0</code></li> <li>Additive SE(3) odometry from <code>p0 \u2192 p1</code> and <code>p1 \u2192 p2</code></li> </ul> <pre><code>sg.add_prior_pose_identity(p0)\nsg.add_odom_se3_additive(p0, p1, dx=0.5)\nsg.add_odom_se3_additive(p1, p2, dx=0.5)\n</code></pre>"},{"location":"tutorials/scenegraph_type_weights/#3-using-dsgtrainer-for-differentiable-optimization","title":"3. Using DSGTrainer for Differentiable Optimization","text":"<p><code>DSGTrainer</code> wraps an inner-loop optimizer (gradient descent), allowing us to differentiate through:</p> <pre><code>solve_state(log_scales) = argmin_x || residuals(x, log_scales) ||\u00b2\n</code></pre> <p>We configure the trainer as follows:</p> <pre><code>factor_type_order = [\"prior\", \"odom_se3\"]\ninner_cfg = InnerGDConfig(learning_rate=0.02, max_iters=40, max_step_norm=0.5)\ntrainer = DSGTrainer(wm, factor_type_order, inner_cfg)\n</code></pre> <p>This gives us a function:</p> <pre><code>x_opt = trainer.solve_state(log_scales)\n</code></pre> <p>where <code>log_scales</code> has one entry per factor type.</p>"},{"location":"tutorials/scenegraph_type_weights/#4-supervised-objective","title":"4. Supervised Objective","text":"<p>We define the supervised loss:</p> <pre><code>L = (pose2.tx - 2.0)\u00b2\n</code></pre> <p>This lets the system learn a log-weight for <code>\"odom_se3\"</code> that moves the odometry-consistent solution toward the ground-truth position.</p> <pre><code>def supervised_loss_scalar(log_scale_odom):\n    log_scales = jnp.array([0.0, log_scale_odom], dtype=jnp.float32)\n    x_opt = trainer.solve_state(log_scales)\n    values = trainer.unpack_state(x_opt)\n    pose2 = values[p2]\n    return (pose2[0] - 2.0)**2\n</code></pre>"},{"location":"tutorials/scenegraph_type_weights/#5-outer-optimization-loop","title":"5. Outer Optimization Loop","text":"<p>We compute the gradient with respect to the odometry type\u2019s log-scale and update it manually:</p> <pre><code>grad_fn = jax.grad(supervised_loss_scalar)\nlog_scale_odom = jnp.array(0.0)\n\nfor it in range(50):\n    g = grad_fn(log_scale_odom)\n    log_scale_odom -= 5.0 * g\n</code></pre> <p>A large learning rate exaggerates the update, making the effect obvious.</p>"},{"location":"tutorials/scenegraph_type_weights/#6-results-and-interpretation","title":"6. Results and Interpretation","text":"<p>After several iterations:</p> <ul> <li>The learned weight for <code>\"odom_se3\"</code> decreases.</li> <li>The system trusts odometry less.</li> <li><code>pose1</code> and <code>pose2</code> shift closer to their ground-truth positions.</li> <li>The supervised loss decreases.</li> </ul> <p>This illustrates a powerful capability of DSG-JIT:</p> <p>You can differentiate through the entire SLAM system, allowing factors to learn reliability from data.</p>"},{"location":"tutorials/scenegraph_type_weights/#summary","title":"Summary","text":"<p>In this tutorial you learned:</p> <ul> <li>How factor-type weights influence the resulting SceneGraph.</li> <li>How to wrap the factor graph into a differentiable trainer.</li> <li>How to define outer-loop supervision.</li> <li>How to learn per-factor-type log-weights with gradients.</li> <li>How to build differentiable SLAM-style pipelines in DSG-JIT.</li> </ul> <p>This completes Tutorial 12 and demonstrates how DSG-JIT supports gradient-based learning on top of dynamic scene graphs.</p>"},{"location":"tutorials/sensor_dsg_mapping/","title":"Tutorial: Sensor DSG Mapping (End-to-End)","text":"<p>Category: Sensors &amp; Fusion, Dynamic Scene Graphs</p>"},{"location":"tutorials/sensor_dsg_mapping/#overview","title":"Overview","text":"<p>This tutorial demonstrates the complete pipeline for taking synthetic camera, LiDAR, and IMU data streams \u2192 converting them into typed measurements \u2192 constructing factors \u2192 inserting them into a WorldModel + FactorGraph \u2192 optimizing with Gauss\u2013Newton \u2192 and visualizing the resulting DSG-driven map.</p> <p>This is intentionally lightweight and synthetic \u2014 the goal is to show the interfaces, not build a full SLAM system.</p>"},{"location":"tutorials/sensor_dsg_mapping/#key-concepts","title":"Key Concepts","text":"<ul> <li> <p>Sensor Streams <code>FunctionStream</code> generates synthetic camera, LiDAR, and IMU data.</p> </li> <li> <p>Measurement Conversion   We convert raw dictionaries into:</p> </li> <li><code>CameraMeasurement</code></li> <li><code>LidarMeasurement</code></li> <li> <p><code>IMUMeasurement</code></p> </li> <li> <p>IMU Integration <code>integrate_imu_delta()</code> produces SE(3) increments from IMU acceleration.</p> </li> <li> <p>Range Mapping   LiDAR ranges are converted to prior factors that constrain a landmark.</p> </li> <li> <p>World Modeling <code>SceneGraphWorld</code> + <code>WorldModel</code> store robot poses, odometry, and landmarks.</p> </li> <li> <p>Optimization <code>gauss_newton_manifold()</code> optimizes SE(3) + Euclidean variables.</p> </li> <li> <p>Visualization <code>plot_factor_graph_3d()</code> renders the final DSG-driven factor graph.</p> </li> </ul>"},{"location":"tutorials/sensor_dsg_mapping/#1-building-the-world-model","title":"1. Building the World Model","text":"<p>We create a simple SE(3) pose chain:</p> <ul> <li>Pose0 = [0,0,0]</li> <li>Pose1 = [1,0,0]</li> <li>Pose2 = [2,0,0]</li> <li>\u2026 Each step is connected by additive odometry.</li> </ul> <p>A static landmark is placed at <code>x = 5.0</code>.</p>"},{"location":"tutorials/sensor_dsg_mapping/#2-creating-synthetic-sensor-streams","title":"2. Creating Synthetic Sensor Streams","text":"<p>We simulate three independent sensors:</p>"},{"location":"tutorials/sensor_dsg_mapping/#camera-stream","title":"Camera Stream","text":"<p>Produces a dummy (1 \\times 1) grayscale image and timestamp.</p>"},{"location":"tutorials/sensor_dsg_mapping/#lidar-stream","title":"LiDAR Stream","text":"<p>Simulates a single-beam scanner with a fixed range (default 5.0 m).</p>"},{"location":"tutorials/sensor_dsg_mapping/#imu-stream","title":"IMU Stream","text":"<p>Constant acceleration in +x; enough to generate SE(3) deltas via:</p> <pre><code>dxi = integrate_imu_delta(imu_meas, dt=imu_meas.dt)\n</code></pre>"},{"location":"tutorials/sensor_dsg_mapping/#3-converting-raw-samples-to-measurement-types","title":"3. Converting Raw Samples to Measurement Types","text":"<p>We parse raw dictionaries into typed messages:</p> <pre><code>cam_meas   = raw_sample_to_camera_measurement(raw_cam)\nlidar_meas = raw_sample_to_lidar_measurement(raw_lidar)\nimu_meas   = raw_sample_to_imu_measurement(raw_imu)\n</code></pre> <p>IMU deltas accumulate into:</p> <pre><code>fused_delta = sum(dxi)\n</code></pre>"},{"location":"tutorials/sensor_dsg_mapping/#4-lidar-range-priors-landmark-constraints","title":"4. LiDAR \u2192 Range Priors (Landmark Constraints)","text":"<p>LiDAR ranges become priors on the landmark:</p> <pre><code>target = [mean_range, 0, 0]  # in world frame\nwm.add_factor(\n    f_type=\"prior\",\n    var_ids=[landmark_id],\n    params={\"target\": target, \"weight\": 1/sigma^2}\n)\n</code></pre> <p>One prior is added per pose (demonstration only), all constraining the same landmark.</p>"},{"location":"tutorials/sensor_dsg_mapping/#5-solving-with-manifold-gaussnewton","title":"5. Solving with Manifold Gauss\u2013Newton","text":"<p>We pack the state and build manifold metadata:</p> <pre><code>x0, index = wm.pack_state()\nblock_slices, manifold_types = build_manifold_metadata(packed_state=wm.pack_state(),fg=wm.fg)\n</code></pre> <p>Then solve:</p> <pre><code>x_opt = gauss_newton_manifold(\n    residual_fn,\n    x0,\n    block_slices,\n    manifold_types,\n    cfg,\n)\n</code></pre> <p>The resulting poses and landmark are printed.</p>"},{"location":"tutorials/sensor_dsg_mapping/#6-visualizing-the-result","title":"6. Visualizing the Result","text":"<p>The factor graph is rendered in 3D:</p> <pre><code>plot_factor_graph_3d(fg, show_labels=True)\n</code></pre> <p>This shows: - SE(3) pose chain - Landmark node - LiDAR\u2013derived prior factors</p>"},{"location":"tutorials/sensor_dsg_mapping/#full-code-from-exp22_sensor_dsg_mappingpy","title":"Full Code (From <code>exp22_sensor_dsg_mapping.py</code>)","text":"<pre><code>&lt;the user-provided full experiment code should be shown here if desired&gt;\n</code></pre> <p>(You may embed the full code or link to the file in your repo.)</p>"},{"location":"tutorials/sensor_dsg_mapping/#summary","title":"Summary","text":"<p>This experiment demonstrates the full pipeline for turning synthetic sensor data into DSG constraints:</p> <ol> <li>Generate raw sensor samples  </li> <li>Convert to structured measurements  </li> <li>Build factors  </li> <li>Inject into a live WorldModel  </li> <li>Solve with manifold GN  </li> <li>Visualize the optimized 3D structure  </li> </ol> <p>This tutorial establishes the template for true full-stack SLAM in DSG\u2011JIT, connecting sensors \u2192 factors \u2192 optimization \u2192 visualization.</p>"},{"location":"tutorials/sensor_fusion_demo/","title":"Tutorial: Sensor Fusion Sandbox - Camera, LiDAR, and IMU Streams","text":"<p>Categories: Sensors &amp; Fusion</p>"},{"location":"tutorials/sensor_fusion_demo/#overview","title":"Overview","text":"<p>This tutorial walks through a minimal sensor\u2013fusion sandbox built on top of DSG\u2011JIT\u2019s <code>sensors.*</code> layer. The goal is to show how to:</p> <ul> <li>Define simple synthetic sensor streams for a camera, LiDAR, and IMU.</li> <li>Wrap them in <code>FunctionStream</code> objects so they look like real hardware.</li> <li>Register each stream with a <code>SensorFusionManager</code>.</li> <li>Attach a callback (<code>ToyImuIntegrator</code>) that consumes IMU measurements and produces a toy 1D fused pose.</li> <li>Inspect the fused pose and visualize the integrated trajectory.</li> </ul> <p>This experiment focuses purely on the sensor layer; it does not yet create SLAM factors or update a <code>WorldModel</code> / <code>SceneGraphWorld</code>. Think of it as a clean sandbox for getting comfortable with DSG\u2011JIT\u2019s sensor APIs before wiring them into the rest of the stack.</p>"},{"location":"tutorials/sensor_fusion_demo/#1-synthetic-sensor-hardware","title":"1. Synthetic Sensor \u201cHardware\u201d","text":"<p>Instead of reading from real devices or log files, the experiment defines three generator-style read functions:</p> <ul> <li><code>make_camera_read_fn(landmark_ids)</code></li> <li><code>make_lidar_read_fn()</code></li> <li><code>make_imu_read_fn()</code></li> </ul> <p>Each one returns a <code>read()</code> callable that behaves like a simple hardware driver:</p> <ul> <li>Every call to <code>read()</code> returns a raw sample dictionary.</li> <li>When the underlying sequence is exhausted (for the camera), it returns <code>None</code> to signal end-of-stream.</li> </ul> <pre><code>def make_camera_read_fn(landmark_ids):\n    \"\"\"\n    Return a generator-style read() function that yields synthetic \n    bearing measurements compatible with raw_sample_to_camera_measurement.\n    \"\"\"\n    samples = [\n        {\n            \"t\": 0.0,\n            \"frame_id\": 0,\n            \"bearings\": jnp.array(\n                [\n                    [1.0, 0.0, 0.0],    # bearing to landmark 0\n                    [1.0, 0.1, 0.0],    # bearing to landmark 1\n                ],\n                dtype=jnp.float32,\n            ),\n            \"landmark_ids\": landmark_ids,\n            \"sensor_pose\": jnp.array([0, 0, 0, 0, 0, 0], dtype=jnp.float32),\n        },\n        {\n            \"t\": 1.0,\n            \"frame_id\": 1,\n            \"bearings\": jnp.array(\n                [\n                    [1.0, 0.05, 0.0],\n                    [1.0, 0.15, 0.0],\n                ],\n                dtype=jnp.float32,\n            ),\n            \"landmark_ids\": landmark_ids,\n            \"sensor_pose\": jnp.array([0.5, 0.0, 0, 0, 0, 0], dtype=jnp.float32),\n        },\n    ]\n\n    it = iter(samples)\n\n    def read():\n        try:\n            return next(it)\n        except StopIteration:\n            return None  # signals end of stream\n\n    return read\n</code></pre> <p>Key idea: the returned dictionaries are raw samples, not <code>CameraMeasurement</code> objects yet. They are shaped so that they can be handed to the camera converter:</p> <pre><code>from dsg_jit.sensors.conversion import raw_sample_to_camera_measurement\n</code></pre> <p>The LiDAR and IMU streams follow the same pattern:</p> <ul> <li>LiDAR: emits a scan at 10 Hz (<code>t += 0.1</code>) with fixed ranges \u2248 5 m and angles from \u201345 to +45 degrees.</li> <li>IMU: emits at 20 Hz (<code>t += 0.05</code>) with:</li> <li>constant acceleration <code>a = [0.5, 0, 0]</code> m/s\u00b2,</li> <li>zero angular velocity,</li> <li>and a scalar <code>dt = 0.05</code>.</li> </ul> <pre><code>def make_lidar_read_fn() -&gt; callable:\n    t = 0.0\n    def read() -&gt; Dict[str, Any]:\n        nonlocal t\n        t += 0.1  # 10 Hz\n        num_beams = 16\n        angles = jnp.linspace(-math.pi / 4, math.pi / 4, num_beams)\n        ranges = 5.0 * jnp.ones_like(angles, dtype=jnp.float32)\n        return {\n            \"t\": t,\n            \"frame_id\": \"lidar0\",\n            \"angles\": angles,\n            \"ranges\": ranges,\n            \"rays\": jnp.stack([angles, ranges], axis=1),\n        }\n    return read\n</code></pre> <pre><code>def make_imu_read_fn() -&gt; callable:\n    t = 0.0\n    def read() -&gt; Dict[str, Any]:\n        nonlocal t\n        t += 0.05  # 20 Hz\n        dt = 0.05\n        accel = jnp.array([0.5, 0.0, 0.0], dtype=jnp.float32)\n        gyro = jnp.array([0.0, 0.0, 0.0], dtype=jnp.float32)\n        return {\n            \"t\": t,\n            \"dt\": dt,\n            \"frame_id\": \"imu0\",\n            \"accel\": accel,\n            \"gyro\": gyro,\n        }\n    return read\n</code></pre> <p>These functions are deliberately simple: they isolate the stream interface (a <code>read()</code> function) from the rest of the system.</p>"},{"location":"tutorials/sensor_fusion_demo/#2-wrapping-streams-with-functionstream","title":"2. Wrapping Streams with <code>FunctionStream</code>","text":"<p>DSG\u2011JIT represents a sensor stream as an object that it can poll for new samples. For synthetic streams, the <code>FunctionStream</code> wrapper is perfect:</p> <pre><code>from dsg_jit.sensors.streams import FunctionStream\n\nlandmark_ids = [0, 1]\ncam_stream = FunctionStream(make_camera_read_fn(landmark_ids=landmark_ids))\nlidar_stream = FunctionStream(make_lidar_read_fn())\nimu_stream = FunctionStream(make_imu_read_fn())\n</code></pre> <p>Each <code>FunctionStream</code> holds onto the underlying <code>read()</code> function and exposes a standard interface that <code>SensorFusionManager</code> knows how to call.</p> <p>If you later want to replace synthetic data with recorded logs, you can swap <code>FunctionStream</code> for something like <code>FileRangeStream</code> without touching the rest of the experiment.</p>"},{"location":"tutorials/sensor_fusion_demo/#3-from-raw-samples-to-measurements","title":"3. From Raw Samples to Measurements","text":"<p>The raw dictionaries produced by the <code>read()</code> functions are converted to typed measurements via functions in <code>sensors.conversion</code>:</p> <ul> <li><code>raw_sample_to_camera_measurement</code></li> <li><code>raw_sample_to_lidar_measurement</code></li> <li><code>raw_sample_to_imu_measurement</code></li> </ul> <p>These converters know how to interpret keys like <code>\"t\"</code>, <code>\"frame_id\"</code>, <code>\"bearings\"</code>, <code>\"ranges\"</code>, <code>\"accel\"</code>, <code>\"gyro\"</code>, and <code>dt</code>, and they produce instances of:</p> <ul> <li><code>CameraMeasurement</code></li> <li><code>LidarMeasurement</code></li> <li><code>IMUMeasurement</code></li> </ul> <p>The fusion manager takes a stream + converter pair for each sensor:</p> <pre><code>from dsg_jit.sensors.fusion import SensorFusionManager\nfrom dsg_jit.sensors.conversion import (\n    raw_sample_to_camera_measurement,\n    raw_sample_to_lidar_measurement,\n    raw_sample_to_imu_measurement,\n)\n\nfusion = SensorFusionManager()\n\nfusion.register_sensor(\n    name=\"cam0\",\n    modality=\"camera\",\n    stream=cam_stream,\n    converter=raw_sample_to_camera_measurement,\n)\nfusion.register_sensor(\n    name=\"lidar0\",\n    modality=\"lidar\",\n    stream=lidar_stream,\n    converter=raw_sample_to_lidar_measurement,\n)\nfusion.register_sensor(\n    name=\"imu0\",\n    modality=\"imu\",\n    stream=imu_stream,\n    converter=raw_sample_to_imu_measurement,\n)\n</code></pre> <p>Why this step? It separates I/O concerns (reading dictionaries from a file or device) from measurement semantics (what fields are present and how to interpret them for SLAM, fusion, or learning).</p>"},{"location":"tutorials/sensor_fusion_demo/#4-sensorfusionmanager-and-callbacks","title":"4. SensorFusionManager and Callbacks","text":"<p>Once streams and converters are registered, the fusion manager becomes the hub for polling measurements and dispatching them to callbacks.</p> <pre><code># Pseudo-code shape:\nclass SensorFusionManager:\n    def register_sensor(self, name, modality, stream, converter):\n        ...\n    def register_callback(self, callback):\n        ...\n    def poll_once(self) -&gt; int:\n        # 1) poll each stream at most one sample\n        # 2) convert raw samples to measurements\n        # 3) invoke callbacks(meas) for all new measurements\n        # 4) return the total number of new measurements\n</code></pre> <p>In this experiment, we attach a single callback: <code>ToyImuIntegrator</code>.</p> <pre><code>integrator = ToyImuIntegrator(fusion)\nfusion.register_callback(integrator)\n</code></pre> <p>Every time <code>poll_once()</code> retrieves a new <code>IMUMeasurement</code>, the integrator is called and updates a toy 1D pose estimate.</p>"},{"location":"tutorials/sensor_fusion_demo/#5-toyimuintegrator-a-minimal-1d-imu-filter","title":"5. ToyImuIntegrator: A Minimal 1D IMU Filter","text":"<p>The <code>ToyImuIntegrator</code> class demonstrates how to consume IMU measurements, maintain internal state, and optionally publish a fused pose back into the fusion manager.</p> <pre><code>class ToyImuIntegrator:\n    \"\"\"\n    Very simple 1D integrator using IMU measurements.\n    This is *not* a real inertial filter; it is just a toy example.\n    \"\"\"\n    def __init__(self, fusion: SensorFusionManager) -&gt; None:\n        self.fusion = fusion\n        self.x = 0.0      # position along x\n        self.vx = 0.0     # velocity along x\n        self.history_t: List[float] = []\n        self.history_x: List[float] = []\n\n    def __call__(self, meas: BaseMeasurement) -&gt; None:\n        if isinstance(meas, IMUMeasurement):\n            a_x = float(meas.accel[0])\n            dt = float(meas.dt)\n\n            # Basic integration: v += a*dt, x += v*dt\n            self.vx += a_x * dt\n            self.x += self.vx * dt\n\n            self.history_t.append(float(meas.timestamp))\n            self.history_x.append(self.x)\n\n            pose_se3 = jnp.array(\n                [self.x, 0.0, 0.0, 0.0, 0.0, 0.0],\n                dtype=jnp.float32,\n            )\n            self.fusion.record_fused_pose(\n                t=meas.timestamp,\n                pose_se3=pose_se3,\n                covariance=None,\n                source_counts={\"imu\": 1},\n            )\n\n        elif isinstance(meas, CameraMeasurement):\n            # Log camera info (timestamp + image/bearing shape)\n            ...\n        elif isinstance(meas, LidarMeasurement):\n            # Log LiDAR mean range\n            ...\n</code></pre> <p>A few details to note:</p> <ul> <li>The callback is polymorphic: it inspects the type of <code>meas</code> and decides what to do.</li> <li>For IMU data, it performs a simplified double integration along the x-axis and appends the result to a history buffer.</li> <li>It uses <code>fusion.record_fused_pose(...)</code> to publish a fused pose so it can be retrieved later via <code>fusion.get_latest_pose()</code>.</li> </ul> <p>For camera and LiDAR measurements, this demo just prints a brief summary:</p> <ul> <li>Camera: timestamp and image (or bearing) shape.</li> <li>LiDAR: timestamp and mean range.</li> </ul> <p>In a more advanced setup, this is exactly where you would add DSG factors (e.g., range factors, bearing factors, occupancy updates) or log them for later learning.</p>"},{"location":"tutorials/sensor_fusion_demo/#6-running-the-simulation-loop","title":"6. Running the Simulation Loop","text":"<p>The main function wires everything together and runs a short simulation:</p> <pre><code>def main() -&gt; None:\n    # 1) Build streams\n    landmark_ids = [0, 1]\n    cam_stream = FunctionStream(make_camera_read_fn(landmark_ids=landmark_ids))\n    lidar_stream = FunctionStream(make_lidar_read_fn())\n    imu_stream = FunctionStream(make_imu_read_fn())\n\n    # 2) Construct fusion manager and register sensors\n    fusion = SensorFusionManager()\n    fusion.register_sensor(\"cam0\", \"camera\", cam_stream, raw_sample_to_camera_measurement)\n    fusion.register_sensor(\"lidar0\", \"lidar\", lidar_stream, raw_sample_to_lidar_measurement)\n    fusion.register_sensor(\"imu0\", \"imu\", imu_stream, raw_sample_to_imu_measurement)\n\n    # 3) Attach toy integrator\n    integrator = ToyImuIntegrator(fusion)\n    fusion.register_callback(integrator)\n\n    # 4) Run a short simulation loop\n    num_steps = 100\n    for step in range(num_steps):\n        n_meas = fusion.poll_once()\n        if n_meas == 0:\n            # In a real app, you might break when all streams are exhausted.\n            pass\n\n    # 5) Inspect latest fused pose\n    fused = fusion.get_latest_pose()\n    if fused is not None:\n        print(\"\\n=== Latest fused pose (toy IMU integrator) ===\")\n        print(f\"t = {fused.t}\")\n        print(f\"pose_se3 = {fused.pose_se3}\")\n        print(f\"source_counts = {fused.source_counts}\")\n    else:\n        print(\"No fused pose produced.\")\n</code></pre> <p>The key call here is:</p> <pre><code>n_meas = fusion.poll_once()\n</code></pre> <p>On each iteration, <code>SensorFusionManager</code>:</p> <ol> <li>Polls each registered <code>stream</code> at most once.</li> <li>Converts any new raw samples into measurement objects via the provided converters.</li> <li>Calls all registered callbacks with each measurement.</li> </ol> <p>You can control the simulated duration either by <code>num_steps</code> or by breaking when <code>n_meas == 0</code> consistently.</p>"},{"location":"tutorials/sensor_fusion_demo/#7-visualizing-the-1d-trajectory","title":"7. Visualizing the 1D Trajectory","text":"<p>The integrator stores time\u2013position pairs inside <code>history_t</code> and <code>history_x</code>. At the end of the run, the experiment uses Matplotlib to plot the estimated trajectory:</p> <pre><code>if integrator.history_t:\n    import matplotlib.pyplot as plt\n\n    ts = jnp.array(integrator.history_t)\n    xs = jnp.array(integrator.history_x)\n\n    plt.figure()\n    plt.plot(ts, xs, marker=\"o\")\n    plt.xlabel(\"time [s]\")\n    plt.ylabel(\"x position [m]\")\n    plt.title(\"Toy IMU-integrated 1D trajectory\")\n    plt.grid(True)\n    plt.show()\n</code></pre> <p>Because the acceleration is constant, the true motion would be a quadratic curve in time. The simple integrator tracks this approximate shape, giving you immediate visual feedback that the IMU callback is wired correctly.</p>"},{"location":"tutorials/sensor_fusion_demo/#8-where-to-go-next","title":"8. Where to Go Next","text":"<p>This sensor fusion sandbox is intentionally minimal. Once you are comfortable with:</p> <ul> <li>constructing streams,</li> <li>converting raw samples into measurements,</li> <li>using <code>SensorFusionManager</code>,</li> <li>and writing callbacks like <code>ToyImuIntegrator</code>,</li> </ul> <p>you are ready to:</p> <ul> <li>Attach measurement factors into a <code>WorldModel</code> (e.g., range priors, bearing factors).</li> <li>Use fused poses as the backbone for SceneGraphWorld or DynamicSceneGraph trajectories.</li> <li>Swap synthetic streams with real datasets or ROS2 bridges.</li> <li>Extend the callback to maintain a full state estimator instead of a toy 1D integrator.</li> </ul> <p>This experiment is meant to be your \u201chello world\u201d for DSG\u2011JIT\u2019s sensor fusion layer\u2014simple enough to hack on quickly, but structured in the same way you would handle real sensor data in more advanced SLAM and learning setups.</p>"},{"location":"tutorials/sliding_window/","title":"Tutorial: Sliding\u2011Window Optimization with Active Templates","text":"<p>Categories: Dynamic Scene Graphs, SLAM, JAX/JIT</p>"},{"location":"tutorials/sliding_window/#overview","title":"Overview","text":"<p>This tutorial explains how DSG\u2011JIT performs real\u2011time optimization using a sliding window (active template) while preserving a persistent global Scene Graph.</p> <p>You will learn:</p> <ul> <li>What an active window is and why it is used</li> <li>How ActiveWindowTemplate enables constant\u2011shape JIT compilation</li> <li>How SceneGraph memory and WorldModel optimization interact</li> <li>How to stream data online without recompiling</li> <li>How to visualize the final Scene Graph in the browser</li> </ul> <p>This tutorial is derived from Experiment\u00a023 but is intentionally simplified to focus on the core API concepts rather than benchmark details.</p>"},{"location":"tutorials/sliding_window/#concept-sliding-windows-vs-persistent-scene-graphs","title":"Concept: Sliding Windows vs Persistent Scene Graphs","text":"<p>In DSG\u2011JIT, memory and computation are separated:</p> <ul> <li>SceneGraphWorld stores the entire history of the environment</li> <li>WorldModel optimizes only a bounded active subset of that history</li> </ul> <p>A sliding window (also called an active window) is a fixed\u2011size subset of recent variables and factors used for online optimization.</p> <p>Older nodes are not deleted \u2014 they simply become inactive for optimization.</p> <p>This allows:</p> <ul> <li>constant problem size</li> <li>one\u2011time JIT compilation</li> <li>millisecond\u2011level solve times</li> </ul>"},{"location":"tutorials/sliding_window/#1-create-a-scenegraphworld","title":"1. Create a SceneGraphWorld","text":"<pre><code>from dsg_jit.world.scene_graph import SceneGraphWorld\n\nsg = SceneGraphWorld()\nwm = sg.wm   # WorldModel backing the scene graph\n</code></pre> <p>The SceneGraphWorld owns:</p> <ul> <li>agents, poses, rooms, objects</li> <li>semantic relationships</li> <li>a persistent memory layer</li> </ul> <p>The WorldModel owns:</p> <ul> <li>the active factor graph</li> <li>residual functions</li> <li>JIT\u2011compiled solvers</li> </ul>"},{"location":"tutorials/sliding_window/#2-register-residuals-at-the-worldmodel","title":"2. Register Residuals at the WorldModel","text":"<p>All optimization logic lives at the WorldModel level. Residuals must be registered once before optimization.</p> <pre><code>from dsg_jit.slam.measurements import prior_residual, odom_se3_residual\n\nwm.register_residual(\"prior\", prior_residual)\nwm.register_residual(\"odom_se3\", odom_se3_residual)\n</code></pre> <p>Residual registration defines what kinds of constraints the optimizer understands.</p>"},{"location":"tutorials/sliding_window/#3-define-an-active-window-template","title":"3. Define an Active Window Template","text":"<p>An ActiveWindowTemplate fixes the shape of the optimization problem. This is what enables DSG\u2011JIT to compile once and reuse indefinitely.</p> <pre><code>from dsg_jit.world.model import ActiveWindowTemplate\n\nWINDOW = 20\nPOSE_DIM = 6\n\nvariable_slots = [\n    (\"pose_se3\", i, POSE_DIM)\n    for i in range(WINDOW)\n]\n\nfactor_slots = [\n    (\"prior\", 0, ((\"pose_se3\", 0),))\n]\n\nfor k in range(1, WINDOW):\n    factor_slots.append(\n        (\"odom_se3\", k, ((\"pose_se3\", k-1), (\"pose_se3\", k)))\n    )\n\nwm.init_active_template(\n    ActiveWindowTemplate(variable_slots, factor_slots)\n)\n</code></pre> <p>Once initialized, the template never changes shape. Only values inside slots are updated.</p>"},{"location":"tutorials/sliding_window/#4-stream-poses-into-the-scene-graph","title":"4. Stream Poses into the Scene Graph","text":"<p>We now add poses over time. Only the last W poses are mapped into the active template.</p> <pre><code>pose_id = sg.add_agent_pose_se3(\n    agent=\"robot0\",\n    t=t,\n    value=pose_vector\n)\n</code></pre> <p>The SceneGraph keeps all poses forever. The WorldModel only optimizes the most recent ones.</p>"},{"location":"tutorials/sliding_window/#5-populate-active-slots-and-optimize","title":"5. Populate Active Slots and Optimize","text":"<p>At each timestep:</p> <pre><code>wm.set_variable_slot(\"pose_se3\", slot_idx, pose_value)\n\nwm.configure_factor_slot(\n    factor_type=\"odom_se3\",\n    slot_idx=k,\n    var_ids=(prev_slot, curr_slot),\n    params={\"measurement\": delta, \"weight\": 1.0},\n    active=True,\n)\n\nwm.optimize_active_template(iters=1)\n</code></pre> <p>Key points:</p> <ul> <li>Slot indices are reused</li> <li>No graph growth occurs</li> <li>JIT compilation happens once</li> <li>Optimization cost stays constant</li> </ul>"},{"location":"tutorials/sliding_window/#6-persistent-scene-graph-memory","title":"6. Persistent Scene Graph Memory","text":"<p>Even though only the active window is optimized:</p> <ul> <li>all poses</li> <li>all rooms</li> <li>all objects</li> <li>all semantic edges</li> </ul> <p>remain stored in the SceneGraphWorld.</p> <p>This allows:</p> <ul> <li>global reasoning</li> <li>offline batch optimization later</li> <li>multi\u2011agent fusion</li> </ul>"},{"location":"tutorials/sliding_window/#7-visualize-the-scene-graph-web","title":"7. Visualize the Scene Graph (Web)","text":"<p>After streaming is complete, launch the web viewer:</p> <pre><code>sg.visualize_web(port=8000)\n</code></pre> <p>This renders:</p> <ul> <li>the full pose history</li> <li>room / object hierarchy</li> <li>semantic edges</li> </ul> <p>in an interactive Three.js viewer.</p>"},{"location":"tutorials/sliding_window/#summary","title":"Summary","text":"<p>This tutorial demonstrated how DSG\u2011JIT achieves real\u2011time performance using:</p> <ul> <li>a fixed\u2011shape active optimization window</li> <li>one\u2011time JIT compilation</li> <li>persistent Scene Graph memory</li> </ul> <p>SceneGraphWorld handles what exists. WorldModel handles what is optimized.</p> <p>Together, they form a scalable architecture for:</p> <ul> <li>online SLAM</li> <li>multi\u2011agent mapping</li> <li>large\u2011scale dynamic environments</li> </ul> <p>The same pattern extends naturally to landmarks, voxels, objects, and learned factors.</p>"},{"location":"tutorials/trainer_voxel_point_multi/","title":"Tutorial: Multi-Voxel Point Observation Learning","text":"<p>Categories: Voxel Grids &amp; Spatial Fields, Learning &amp; Hybrid Modules, Dynamic Scene Graphs</p>"},{"location":"tutorials/trainer_voxel_point_multi/#overview","title":"Overview","text":"<p>In voxel-based mapping systems, observed 3D points often serve as soft constraints that pull voxel centers toward actual sensor measurements. When these observations are uncertain or biased, it becomes valuable to learn the observation parameters themselves by differentiating through the optimization process.</p> <p>This tutorial demonstrates a compact example of trainer-style learning for voxel point observations. We combine:</p> <ul> <li>A 3\u2011voxel chain in 1D-like geometry  </li> <li>Smoothness constraints (voxel\u2011to\u2011voxel)</li> <li>A prior anchor for the first voxel  </li> <li>Three learnable voxel-point observations supplied through a parameter matrix <code>theta</code> </li> <li>A Gauss\u2011Newton inner solver operating on voxel variables  </li> <li>An outer gradient descent loop updating <code>theta</code> via supervision  </li> </ul> <p>The experiment is based on <code>exp13_trainer_voxel_point_multi.py</code>.</p>"},{"location":"tutorials/trainer_voxel_point_multi/#building-the-voxel-graph","title":"Building the Voxel Graph","text":"<p>We construct a tiny world model containing three voxel variables:</p> <pre><code>v0 = Variable(NodeId(0), \"voxel_cell\", jnp.array([0.0, 0.0, 0.0]))\nv1 = Variable(NodeId(1), \"voxel_cell\", jnp.array([1.2, 0.2, 0.0]))\nv2 = Variable(NodeId(2), \"voxel_cell\", jnp.array([2.3, -0.1, 0.1]))\n</code></pre> <p>Next we register residuals used by the factors:</p> <pre><code>wm.register_residual(\"prior\", prior_residual)\nwm.register_residual(\"voxel_smoothness\", voxel_smoothness_residual)\nwm.register_residual(\"voxel_point_obs\", voxel_point_observation_residual)\n</code></pre> <p>We add:</p> <ul> <li>A strong prior on <code>v0</code></li> <li>Smoothness factors between <code>(v0, v1)</code> and <code>(v1, v2)</code></li> <li>Three voxel-point observation factors, each of which receives its real <code>point_world</code> from <code>theta</code></li> </ul> <p>This produces a compact, differentiable voxel estimation problem.</p>"},{"location":"tutorials/trainer_voxel_point_multi/#defining-the-parameterized-observation-model","title":"Defining the Parameterized Observation Model","text":"<p>Rather than storing fixed <code>point_world</code> values in factors, we use:</p> <pre><code>theta \u2208 \u211d^(K \u00d7 3)\n</code></pre> <p>where each row of <code>theta[k]</code> is injected into the corresponding <code>voxel_point_obs</code> factor. This is implemented through:</p> <pre><code>residual_fn_param, _ = wm.build_residual_function_voxel_point_param_multi()\n</code></pre> <p>This allows the residual function to depend on both the state <code>x</code> and the learnable parameters <code>theta</code>.</p>"},{"location":"tutorials/trainer_voxel_point_multi/#inner-optimization-solving-for-voxels","title":"Inner Optimization: Solving for Voxels","text":"<p>For each proposed value of <code>theta</code>, we solve for voxel positions using Gauss\u2011Newton:</p> <pre><code>def solve_inner_voxel(wm, theta):\n    residual_fn_param, _ = wm.build_residual_function_voxel_point_param_multi()\n    x0, _ = wm.pack_state()\n    def residual_x(x):\n        return residual_fn_param(x, theta)\n\n    cfg = GNConfig(max_iters=20, damping=1e-3, max_step_norm=1.0)\n    return gauss_newton(residual_x, x0, cfg)\n</code></pre> <p>This inner loop is fully differentiable.</p>"},{"location":"tutorials/trainer_voxel_point_multi/#the-supervised-learning-objective","title":"The Supervised Learning Objective","text":"<p>We specify target voxel centers:</p> <pre><code>gt_voxels = jnp.array([\n    [0.0, 0.0, 0.0],\n    [1.0, 0.0, 0.0],\n    [2.0, 0.0, 0.0]\n])\n</code></pre> <p>The supervised loss is:</p> <pre><code>L(\u03b8) = \u00bd \u03a3_i || v_i(\u03b8) \u2013 gt_i ||\u00b2\n</code></pre> <p>Implemented as:</p> <pre><code>def supervised_loss(theta):\n    x_opt = solve_inner_voxel(wm, theta)\n    ...\n    v_stack = jnp.stack([v0, v1, v2])\n    return 0.5 * jnp.sum((v_stack - gt_voxels)**2)\n</code></pre>"},{"location":"tutorials/trainer_voxel_point_multi/#outer-learning-loop","title":"Outer Learning Loop","text":"<p>We apply gradient descent to adjust <code>theta</code>:</p> <pre><code>theta = theta0\nlr = 0.1\nfor it in range(20):\n    g = grad_fn(theta)\n    theta = theta - lr * g\n</code></pre> <p>Optionally, gradient clipping avoids numerical instability.</p> <p>Over iterations, the observation points <code>theta[k]</code> become more consistent with the ground-truth voxel positions. This, in turn, drives the optimized voxel states closer to the true layout.</p>"},{"location":"tutorials/trainer_voxel_point_multi/#results","title":"Results","text":"<p>After optimization:</p> <ul> <li>The learned observation points <code>theta</code> converge toward ground truth.</li> <li>The voxel estimates <code>(v0, v1, v2)</code> align closely with their true positions.</li> <li>The supervised loss decreases significantly.</li> </ul> <p>This demonstrates one of DSG\u2011JIT\u2019s core advantages: You can differentiate through a full Gauss\u2011Newton optimization and learn parameters that influence the system.</p>"},{"location":"tutorials/trainer_voxel_point_multi/#summary","title":"Summary","text":"<p>In this tutorial, you learned how to:</p> <ul> <li>Build a voxel-based factor graph with smoothness and observation factors.</li> <li>Use parameterized voxel-point observations with differentiable residuals.</li> <li>Run a Gauss\u2011Newton inner solver to estimate voxel state.</li> <li>Define a supervised objective on voxel positions.</li> <li>Use outer-loop gradient descent to learn per-observation parameters.</li> </ul> <p>This trainer-style workflow generalizes to larger voxel grids, learned observation models, or hybrid neural feature extractors. It is a powerful pattern enabled by DSG\u2011JIT\u2019s differentiable factor graph engine.</p>"},{"location":"tutorials/visual_factor_graph/","title":"Tutorial: Visualizing a Factor Graph in 3D","text":"<p>Categories: Core Concepts, SE(3) &amp; SLAM, JAX &amp; JIT</p>"},{"location":"tutorials/visual_factor_graph/#overview","title":"Overview","text":"<p>This tutorial walks through a minimal but complete example of:</p> <ul> <li>Building a small WorldModel-backed factor graph over SE(3) poses,</li> <li>Registering a custom odometry residual,</li> <li>Solving the resulting nonlinear least\u2011squares problem with the manifold Gauss\u2013Newton solver, and</li> <li>Visualizing the optimized poses and factors in 3D.</li> </ul> <p>The code is based on the experiment <code>exp_visual_factor_graph.py</code> (the snippet below), and is meant as a first introduction to how a WorldModel-backed factor graph + residuals + solvers + visualization fit together in DSG-JIT.</p>"},{"location":"tutorials/visual_factor_graph/#1-problem-setup-a-simple-se3-odometry-chain","title":"1. Problem setup: a simple SE(3) odometry chain","text":"<p>We start from a very simple SLAM\u2011style setup: a chain of poses along the x\u2011axis, connected by odometry constraints.</p> <p>Conceptually, we want 5 poses</p> <p>[ T_0, T_1, T_2, T_3, T_4 \\in SE(3) ]</p> <p>with each consecutive pair constrained by a relative motion of 1 meter along +x. In this experiment, we represent each pose in its minimal se(3) vector form (6\u2011vector: translation + rotation), and we add one odometry factor between each pair.</p>"},{"location":"tutorials/visual_factor_graph/#building-the-demo-factor-graph","title":"Building the demo factor graph","text":"<pre><code>import jax.numpy as jnp\n\nfrom dsg_jit.world.model import WorldModel\nfrom dsg_jit.slam.measurements import se3_chain_residual\n\n\ndef build_demo_world(num_poses: int = 5) -&gt; WorldModel:\n    \"\"\"Build a simple WorldModel-backed factor graph for an SE(3) pose chain.\"\"\"\n    wm = WorldModel()\n\n    # 1. Register the residual type used by our factors\n    wm.register_residual(\"odom_se3\", se3_chain_residual)\n\n    # 2. Add pose variables: pose_se3 in R^6\n    pose_ids = []\n    for _ in range(num_poses):\n        vid = wm.add_variable(\n            var_type=\"pose_se3\",\n            value=jnp.zeros(6, dtype=jnp.float32),  # initial guess: all zeros\n        )\n        pose_ids.append(vid)\n\n    # 3. Add odometry factors between consecutive poses\n    for i in range(num_poses - 1):\n        meas = jnp.array([1.0, 0.0, 0.0, 0.0, 0.0, 0.0])  # 1 m along x\n        wm.add_factor(\n            f_type=\"odom_se3\",\n            var_ids=(pose_ids[i], pose_ids[i + 1]),\n            params={\"measurement\": meas, \"weight\": 1.0},\n        )\n\n    return wm\n</code></pre> <p>What\u2019s happening here?</p> <ul> <li><code>WorldModel</code> is the high-level container that owns:</li> <li>An underlying factor graph (<code>wm.fg</code>) storing variables and factors,</li> <li>A registry of residual functions keyed by factor type names, and</li> <li> <p>Helpers for state packing/unpacking and building residual functions for optimization.</p> </li> <li> <p>Each SE(3) pose is stored as a variable in the WorldModel-backed factor graph with:</p> </li> <li>A <code>type</code> string (<code>\"pose_se3\"</code>), and</li> <li> <p>A 6\u2011D initial value.</p> </li> <li> <p>Each odometry constraint is a factor of type <code>\"odom_se3\"</code> connecting two pose variables in the WorldModel-backed factor graph.</p> </li> <li> <p><code>wm.register_residual(\"odom_se3\", se3_chain_residual)</code> tells the WorldModel which residual function to call when evaluating factors of this type.</p> </li> </ul>"},{"location":"tutorials/visual_factor_graph/#2-packing-the-state-and-building-manifold-metadata","title":"2. Packing the state and building manifold metadata","text":"<p>Once the graph structure is built, we need to:</p> <ol> <li>Pack all variables into a single flat state vector <code>x</code>, and</li> <li>Build manifold metadata so the solver knows how to treat each variable (Euclidean vs SE(3), etc.).</li> </ol> <pre><code>from dsg_jit.slam.manifold import build_manifold_metadata\n\nwm = build_demo_world(num_poses=5)\nfg = wm.fg  # underlying factor graph structure\n\n# Pack current variable values into a flat state vector x0 via the WorldModel\nx0, index = wm.pack_state()\npacked_state = (x0, index)\n\n# Build manifold metadata for all variables\nblock_slices, manifold_types = build_manifold_metadata(\n    packed_state=packed_state,\n    fg=fg,\n)\n\n# Build the global residual function r(x) from the WorldModel registry\nresidual_fn = wm.build_residual()\n</code></pre> <ul> <li><code>build_manifold_metadata(packed_state=..., fg=fg)</code> inspects the WorldModel-backed factor graph and returns:</li> <li><code>block_slices</code>: a mapping from node ids to slices in the flat vector <code>x</code>,</li> <li> <p><code>manifold_types</code>: a mapping from node ids to a manifold tag (e.g. <code>\"se3\"</code> vs <code>\"euclidean\"</code>).</p> </li> <li> <p><code>wm.pack_state()</code> collects all variable values into one flat JAX vector <code>x0</code>, along with an <code>index</code> structure for unpacking later.</p> </li> <li> <p><code>wm.build_residual()</code> returns a JAX\u2011compatible function</p> </li> </ul> <p>[   r(x): \\mathbb{R}^n \\to \\mathbb{R}^m   ]</p> <p>that stacks all factor residuals in a consistent order.</p>"},{"location":"tutorials/visual_factor_graph/#3-running-gaussnewton-on-the-se3-chain","title":"3. Running Gauss\u2013Newton on the SE(3) chain","text":"<p>We now solve the nonlinear least\u2011squares problem</p> <p>[ x^* = \\arg\\min_x | r(x) |^2 ]</p> <p>using the manifold Gauss\u2013Newton solver. This uses the manifold metadata to update SE(3) poses properly.</p> <pre><code>from dsg_jit.optimization.solvers import gauss_newton_manifold, GNConfig\n\ncfg = GNConfig(\n    max_iters=10,\n    damping=1e-3,      # Levenberg\u2013Marquardt style diagonal damping\n    max_step_norm=1.0  # clamp step size for stability\n)\n\nx_opt = gauss_newton_manifold(\n    residual_fn,\n    x0,\n    block_slices,\n    manifold_types,\n    cfg,\n)\nvalues = wm.unpack_state(x_opt, index)\n</code></pre> <ul> <li><code>GNConfig</code> controls:</li> <li><code>max_iters</code>: how many Gauss\u2013Newton iterations to run,</li> <li><code>damping</code>: how much diagonal regularization to add,</li> <li> <p><code>max_step_norm</code>: a safety clamp on the step size.</p> </li> <li> <p><code>gauss_newton_manifold</code>:</p> </li> <li>Linearizes the residual at the current <code>x</code>,</li> <li>Solves for a step in the tangent space of each manifold block,</li> <li> <p>Retracts back onto the manifold (e.g. updates SE(3) poses correctly).</p> </li> <li> <p><code>wm.unpack_state(x_opt, index)</code> maps the optimized flat state back to a dict from node ids to arrays.</p> </li> </ul> <p>After solving, we typically push the optimized values back into the factor graph:</p> <pre><code>print(\"Optimized poses:\")\nfor nid, v in values.items():\n    print(nid, v)\n    fg.variables[nid].value = v\n</code></pre> <p>This is necessary so downstream tools (like visualization) see the updated poses.</p> <p>Here, <code>wm</code> owns the packed state and residuals, while <code>fg = wm.fg</code> stores the underlying variable objects used by the visualizer.</p>"},{"location":"tutorials/visual_factor_graph/#4-visualizing-the-factor-graph-in-3d","title":"4. Visualizing the factor graph in 3D","text":"<p>With the optimized poses stored in <code>fg.variables</code> (where <code>fg = wm.fg</code>), we can call the visualization helpers to render the graph layout.</p> <pre><code>from dsg_jit.world.visualization import plot_factor_graph_3d\n\n# Visualize optimized poses and factors\nplot_factor_graph_3d(fg)\n</code></pre> <ul> <li><code>plot_factor_graph_3d(fg)</code> inspects:</li> <li>All pose variables (e.g. <code>\"pose_se3\"</code>),</li> <li>Factors connecting them (e.g. <code>odom_se3</code> edges),</li> <li> <p>And produces a simple 3D matplotlib plot.</p> </li> <li> <p>There is also <code>plot_factor_graph_2d(fg)</code> for planar (x\u2013y) visualization when you only care about positions in a plane.</p> </li> </ul> <p>In this experiment, since the odometry measurements are all <code>[1, 0, 0, 0, 0, 0]</code>, the optimized chain should line up roughly along the x\u2011axis with unit spacing between consecutive poses.</p>"},{"location":"tutorials/visual_factor_graph/#summary","title":"Summary","text":"<p>In this tutorial you saw how to:</p> <ol> <li>Define a minimal SE(3) odometry chain as a WorldModel-backed factor graph by adding pose variables and odometry factors via the <code>WorldModel</code> API.</li> <li>Register a residual function (<code>se3_chain_residual</code>) for a factor type (<code>\"odom_se3\"</code>) with the <code>WorldModel</code>.</li> <li>Pack and unpack the state via <code>WorldModel.pack_state</code> / <code>unpack_state</code>, and build manifold metadata with <code>build_manifold_metadata(packed_state, fg)</code>.</li> <li>Solve the resulting nonlinear least squares problem with <code>gauss_newton_manifold</code> and a simple <code>GNConfig</code>.</li> <li>Visualize the final optimized poses and factors in 3D using <code>plot_factor_graph_3d</code>.</li> </ol> <p>This pattern\u2014build a graph, register residuals, pack state, run a solver, then visualize\u2014is the core workflow that many other DSG\u2011JIT experiments and higher\u2011level components build upon. In more advanced tutorials, we\u2019ll extend this to dynamic scene graphs, voxel grids, and sensor\u2011driven mapping.</p>"}]}